{"meta":{"title":"topone233","subtitle":"","description":"","author":"QSX1C","url":"https://topone233.github.io","root":"/"},"pages":[],"posts":[{"title":"Hello World！（hexo配置记录）","slug":"Hello World！（hexo配置记录）","date":"2020-07-10T09:21:24.622Z","updated":"2020-07-10T09:21:00.907Z","comments":true,"path":"2020/07/10/Hello World！（hexo配置记录）/","link":"","permalink":"https://topone233.github.io/2020/07/10/Hello%20World%EF%BC%81%EF%BC%88hexo%E9%85%8D%E7%BD%AE%E8%AE%B0%E5%BD%95%EF%BC%89/","excerpt":"","text":"Hello World！（hexo配置记录）以前在网上冲浪的时候只是不经意间发现许多让人眼前一亮的blog，由此萌生了create my blog的想法。 目前的blog搭建： CSDN/博客园平台 但我个人不是很喜欢这种，首先是太丑了（没错，就是你，CSDN）。 其次依托于平台，虽然只需要创作就行，但是感觉不是属于自己的，没有归属感 独立blog 租云服务器、买域名，还要管理维护，个人感觉略微有些费事，精力有限，还是简单点好 hexo 依托于Github，也是我目前选择的，配置相对简单快捷，主题丰富 hexo配置步骤： 安装Git 安装Node.js 安装hexo 生成ssh并添加到GitHub 部署项目 上传到GitHub 修改主题 1.安装Git下载地址 安装步骤：双击下载的exe文件，一路next就行 2.安装Node.jsHexo是基于nodeJS环境的静态博客，npm是必备的 下载地址 安装步骤：下载好msi文件后，双击打开安装，也是一路next，不过在Custom Setup这一步记得选 Add to PATH ,这样你就不用自己去配置电脑上环境变量了 3.安装hexo 创建一个源文件夹，然后cd到该文件夹下 安装hexo： npm i -g hexo hexo -v 查看版本，检查是否安装成功 hexo init 初始化，初始化完成后可在文件夹下看到文件 这里要说下，npm install出现一直停留在”fetchMetadata: sill resolveWithNewModule find-cache-dir@”解决方法，更换成淘宝的源（反正我是解决了） 123456&#x2F;&#x2F;修改为淘宝源npm config set registry https:&#x2F;&#x2F;registry.npm.taobao.org &#x2F;&#x2F;配置后可通过下面方式来验证是否成功 npm config get registry &#x2F;&#x2F;或npm info express 4.生成ssh并添加到GitHubSSH密钥可以防止其他人恶意部署文件到你的仓库 首先要有GitHub账号，没有的自行注册 创建一个仓库repository，名称为youname.github.io 在gitbash中，配置GitHub账号信息 123&#x2F;&#x2F;配置你的GitHub账号信息git config --global user.name &quot;YourName&quot;git config --global user.email &quot;YourEmail&quot; 创建ssh 12&#x2F;&#x2F;创建sshssh-keygen -t rsa -C &quot;youremail@xx.com&quot; 生成ssh，在gitbash中切换到文件目录cat读取 12&#x2F;&#x2F;读取ssh文件内容cat id_rsa.pub 全部复制（包括开头的ssh-rsa，和尾部的email）到GitHub 配置ssh，title随便起 5.部署项目修改hexo的_config.yml文件配置信息（直接复制，只需要修改url即可） 1234deploy: type: git repo: https:&#x2F;&#x2F;github.com&#x2F;YourgithubName&#x2F;YourgithubName.github.io.git branch: master 回到gitbash，进入hexo目录 123hexo cleanhexo generatehexo server 这时，在http://localhost:4000就可以看到默认页面 6.上传到GitHub1npm install hexo-deployer-git --save 将写好的文章部署到GitHub服务器，执行命令 123hexo cleanhexo generatehexo deploy 第一次deploy要输入GitHubusername和password完成后https://yourgithubname.github.io，查看即可 7.修改主题hexo官网有推荐很多很多主题，自行选择","categories":[],"tags":[]},{"title":"HashMap 剖析 (基于 jdk1.8)","slug":"HashMap 剖析 (基于 jdk1.8)","date":"2020-07-10T09:07:59.406Z","updated":"2020-07-08T07:11:31.962Z","comments":true,"path":"2020/07/10/HashMap 剖析 (基于 jdk1.8)/","link":"","permalink":"https://topone233.github.io/2020/07/10/HashMap%20%E5%89%96%E6%9E%90%20(%E5%9F%BA%E4%BA%8E%20jdk1.8)/","excerpt":"","text":"原文地址 www.cnblogs.com 本文的源码是基于 JDK1.8 版本，在学习 HashMap 之前，先了解数组和链表的知识。 数组：数组具有遍历快，增删慢的特点。数组在堆中是一块连续的存储空间，遍历时数组的首地址是知道的（首地址 = 首地址 + 元素字节数 * 下标），所以遍历快（数组遍历的时间复杂度为 O(1) ）；增删慢是因为，当在中间插入或删除元素时，会造成该元素后面所有元素地址的改变，所以增删慢（增删的时间复杂度为 O(n) ）。 链表：链表具有增删快，遍历慢的特点。链表中各元素的内存空间是不连续的，一个节点至少包含节点数据与后继节点的引用，所以在插入删除时，只需修改该位置的前驱节点与后继节点即可，链表在插入删除时的时间复杂度为 O(1)。但是在遍历时，get(n) 元素时，需要从第一个开始，依次拿到后面元素的地址，进行遍历，直到遍历到第 n 个元素（时间复杂度为 O(n) ），所以效率极低。 HashMap:Hash 表是一个数组 + 链表的结构，这种结构能够保证在遍历与增删的过程中，如果不产生 hash 碰撞，仅需一次定位就可完成，时间复杂度能保证在 O(1)。 在 jdk1.7 中，只是单纯的数组 + 链表的结构，但是如果散列表中的 hash 碰撞过多时，会造成效率的降低，所以在 JKD1.8 中对这种情况进行了控制，当一个 hash 值上的链表长度大于 8 时，该节点上的数据就不再以链表进行存储，而是转成了一个红黑树。 红黑树: 1234567static final class TreeNode&lt;K,V&gt; extends LinkedHashMap.Entry&lt;K,V&gt; &#123; TreeNode&lt;K,V&gt; parent; &#x2F;&#x2F; red-black tree links TreeNode&lt;K,V&gt; left; TreeNode&lt;K,V&gt; right; TreeNode&lt;K,V&gt; prev; &#x2F;&#x2F; needed to unlink next upon deletion boolean red;&#125; hash 碰撞：hash 是指，两个元素通过 hash 函数计算出的值是一样的，是同一个存储地址。当后面的元素要插入到这个地址时，发现已经被占用了，这时候就产生了 hash 冲突 hash 冲突的解决方法：开放定址法 (查询产生冲突的地址的下一个地址是否被占用，直到寻找到空的地址)，再散列法，链地址法等。hashmap 采用的就是链地址法，jdk1.7 中，当冲突时，在冲突的地址上生成一个链表，将冲突的元素的 key，通过 equals 进行比较，相同即覆盖，不同则添加到链表上，此时如果链表过长，效率就会大大降低，查找和添加操作的时间复杂度都为 O(n)；但是在 jdk1.8 中如果链表长度大于 8，链表就会转化为红黑树，下图就是 1.8 版本的（图片来源 https://segmentfault.com/a/1190000012926722），时间复杂度也降为了 O(logn)，性能得到了很大的优化。 下面通过源码分析一下，HashMap 的底层实现 首先，hashMap 的主干是一个 Node 数组（jdk1.7 及之前为 Entry 数组）每一个 Node 包含一个 key 与 value 的键值对，与一个 next 指向下一个 node，hashMap 由多个 Node 对象组成。 Node 是 HhaspMap 中的一个静态内部类 ： 12345678910111213141516171819static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; final K key; V value; Node&lt;K,V&gt; next; Node(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; this.hash &#x3D; hash; this.key &#x3D; key; this.value &#x3D; value; this.next &#x3D; next; &#125; public final K getKey() &#123; return key; &#125; public final V getValue() &#123; return value; &#125; public final String toString() &#123; return key + &quot;&#x3D;&quot; + value; &#125; &#x2F;&#x2F;hashCode等其他代码 &#125; 再看下 hashMap 中几个重要的字段： 123456789101112131415161718192021&#x2F;&#x2F;默认初始容量为16，0000 0001 左移4位 0001 0000为16，主干数组的初始容量为16，而且这个数组&#x2F;&#x2F;必须是2的倍数(后面说为什么是2的倍数)static final int DEFAULT_INITIAL_CAPACITY &#x3D; 1 &lt;&lt; 4; &#x2F;&#x2F; aka 16 &#x2F;&#x2F;最大容量为int的最大值除2static final int MAXIMUM_CAPACITY &#x3D; 1 &lt;&lt; 30; &#x2F;&#x2F;默认加载因子为0.75static final float DEFAULT_LOAD_FACTOR &#x3D; 0.75f; &#x2F;&#x2F;阈值，如果主干数组上的链表的长度大于8，链表转化为红黑树 static final int TREEIFY_THRESHOLD &#x3D; 8; &#x2F;&#x2F;hash表扩容后，如果发现某一个红黑树的长度小于6，则会重新退化为链表 static final int UNTREEIFY_THRESHOLD &#x3D; 6; &#x2F;&#x2F;当hashmap容量大于64时，链表才能转成红黑树 static final int MIN_TREEIFY_CAPACITY &#x3D; 64; &#x2F;&#x2F;临界值&#x3D;主干数组容量*负载因子int threshold； HashMap 的构造方法： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950&#x2F;&#x2F;initialCapacity为初始容量，loadFactor为负载因子public HashMap(int initialCapacity, float loadFactor) &#123; &#x2F;&#x2F;初始容量小于0，抛出非法数据异常 if (initialCapacity &lt; 0) throw new IllegalArgumentException(&quot;Illegal initial capacity: &quot; + initialCapacity); &#x2F;&#x2F;初始容量最大为MAXIMUM_CAPACITY if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity &#x3D; MAXIMUM_CAPACITY; &#x2F;&#x2F;负载因子必须大于0，并且是合法数字 if (loadFactor &lt;&#x3D; 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(&quot;Illegal load factor: &quot; + loadFactor); this.loadFactor &#x3D; loadFactor; &#x2F;&#x2F;将初始容量转成2次幂 this.threshold &#x3D; tableSizeFor(initialCapacity); &#125; &#x2F;&#x2F;tableSizeFor的作用就是，如果传入A，当A大于0，小于定义的最大容量时， &#x2F;&#x2F;如果A是2次幂则返回A，否则将A转化为一个比A大且差距最小的2次幂。 &#x2F;&#x2F;例如传入7返回8，传入8返回8，传入9返回16 static final int tableSizeFor(int cap) &#123; int n &#x3D; cap - 1; n |&#x3D; n &gt;&gt;&gt; 1; n |&#x3D; n &gt;&gt;&gt; 2; n |&#x3D; n &gt;&gt;&gt; 4; n |&#x3D; n &gt;&gt;&gt; 8; n |&#x3D; n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;&#x3D; MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1; &#125; &#x2F;&#x2F;调用上面的构造方法，自定义初始容量，负载因子为默认的0.75 public HashMap(int initialCapacity) &#123; this(initialCapacity, DEFAULT_LOAD_FACTOR); &#125; &#x2F;&#x2F;默认构造方法，负载因子为0.75，初始容量为DEFAULT_INITIAL_CAPACITY&#x3D;16，初始容量在第一次put时才会初始化 public HashMap() &#123; this.loadFactor &#x3D; DEFAULT_LOAD_FACTOR; &#x2F;&#x2F; all other fields defaulted &#125; &#x2F;&#x2F;传入一个MAP集合的构造方法 public HashMap(Map&lt;? extends K, ? extends V&gt; m) &#123; this.loadFactor &#x3D; DEFAULT_LOAD_FACTOR; putMapEntries(m, false); &#125; HashMap 的 put() 方法 put 方法的源码分析是本篇的一个重点，因为通过该方法我们可以窥探到 HashMap 在内部是如何进行数据存储的，所谓的数组 + 链表 + 红黑树的存储结构是如何形成的，又是在何种情况下将链表转换成红黑树来优化性能的。带着一系列的疑问，我们看这个 put 方法： 123public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true);&#125; 也就是 put 方法调用了 putVal 方法，其中传入一个参数位 hash(key)，我们首先来看看 hash() 这个方法。 1234static final int hash(Object key) &#123; int h; return (key &#x3D;&#x3D; null) ? 0 : (h &#x3D; key.hashCode()) ^ (h &gt;&gt;&gt; 16); &#125; 此处如果传入的 int 类型的值：①向一个 Object 类型赋值一个 int 的值时，会将 int 值自动封箱为 Integer。②integer 类型的 hashcode 都是他自身的值，即 h=key；h &gt;&gt;&gt; 16 为无符号右移 16 位，低位挤走，高位补 0；^ 为按位异或，即转成二进制后，相异为 1，相同为 0，由此可发现，当传入的值小于 2 的 16 次方 - 1 时，调用这个方法返回的值，都是自身的值。然后再执行 putVal 方法： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667&#x2F;&#x2F;onlyIfAbsent是true的话，不要改变现有的值&#x2F;&#x2F;evict为true的话，表处于创建模式 final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i;&#x2F;&#x2F;如果主干上的table为空，长度为0，调用resize方法，调整table的长度（resize方法在下图中） if ((tab &#x3D; table) &#x3D;&#x3D; null || (n &#x3D; tab.length) &#x3D;&#x3D; 0) &#x2F;* 这里调用resize，其实就是第一次put时，对数组进行初始化。 如果是默认构造方法会执行resize中的这几句话： newCap &#x3D; DEFAULT_INITIAL_CAPACITY; 新的容量等于默认值16 newThr &#x3D; (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); threshold &#x3D; newThr; 临界值等于16*0.75 Node&lt;K,V&gt;[] newTab &#x3D; (Node&lt;K,V&gt;[])new Node[newCap]; table &#x3D; newTab; 将新的node数组赋值给table，然后return newTab 如果是自定义的构造方法则会执行resize中的： int oldThr &#x3D; threshold; newCap &#x3D; oldThr; 新的容量等于threshold，这里的threshold都是2的倍数，原因在 于传入的数都经过tableSizeFor方法，返回了一个新值，上面解释过 float ft &#x3D; (float)newCap * loadFactor; newThr &#x3D; (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); threshold &#x3D; newThr; 新的临界值等于 (int)(新的容量*负载因子) Node&lt;K,V&gt;[] newTab &#x3D; (Node&lt;K,V&gt;[])new Node[newCap]; table &#x3D; newTab; return newTab; *&#x2F; n &#x3D; (tab &#x3D; resize()).length; &#x2F;&#x2F;将调用resize后构造的数组的长度赋值给n if ((p &#x3D; tab[i &#x3D; (n - 1) &amp; hash]) &#x3D;&#x3D; null) &#x2F;&#x2F;将数组长度与计算得到的hash值比较 tab[i] &#x3D; newNode(hash, key, value, null);&#x2F;&#x2F;位置为空，将i位置上赋值一个node对象 else &#123; &#x2F;&#x2F;位置不为空 Node&lt;K,V&gt; e; K k; if (p.hash &#x3D;&#x3D; hash &amp;&amp; &#x2F;&#x2F; 如果这个位置的old节点与new节点的key完全相同 ((k &#x3D; p.key) &#x3D;&#x3D; key || (key !&#x3D; null &amp;&amp; key.equals(k)))) e &#x3D; p; &#x2F;&#x2F; 则e&#x3D;p else if (p instanceof TreeNode) &#x2F;&#x2F; 如果p已经是树节点的一个实例，既这里已经是树了 e &#x3D; ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else &#123; &#x2F;&#x2F;p与新节点既不完全相同，p也不是treenode的实例 for (int binCount &#x3D; 0; ; ++binCount) &#123; &#x2F;&#x2F;一个死循环 if ((e &#x3D; p.next) &#x3D;&#x3D; null) &#123; &#x2F;&#x2F;e&#x3D;p.next,如果p的next指向为null p.next &#x3D; newNode(hash, key, value, null); &#x2F;&#x2F;指向一个新的节点 if (binCount &gt;&#x3D; TREEIFY_THRESHOLD - 1) &#x2F;&#x2F; 如果链表长度大于等于8 treeifyBin(tab, hash); &#x2F;&#x2F;将链表转为红黑树 break; &#125; if (e.hash &#x3D;&#x3D; hash &amp;&amp; &#x2F;&#x2F;如果遍历过程中链表中的元素与新添加的元素完全相同，则跳出循环 ((k &#x3D; e.key) &#x3D;&#x3D; key || (key !&#x3D; null &amp;&amp; key.equals(k)))) break; p &#x3D; e; &#x2F;&#x2F;将p中的next赋值给p,即将链表中的下一个node赋值给p， &#x2F;&#x2F;继续循环遍历链表中的元素 &#125; &#125; if (e !&#x3D; null) &#123; &#x2F;&#x2F;这个判断中代码作用为：如果添加的元素产生了hash冲突，那么调用 &#x2F;&#x2F;put方法时，会将他在链表中他的上一个元素的值返回 V oldValue &#x3D; e.value; if (!onlyIfAbsent || oldValue &#x3D;&#x3D; null) &#x2F;&#x2F;判断条件成立的话，将oldvalue替换 &#x2F;&#x2F;为newvalue，返回oldvalue；不成立则不替换，然后返回oldvalue e.value &#x3D; value; afterNodeAccess(e); &#x2F;&#x2F;这个方法在后面说 return oldValue; &#125; &#125; ++modCount; &#x2F;&#x2F;记录修改次数 if (++size &gt; threshold) &#x2F;&#x2F;如果元素数量大于临界值，则进行扩容 resize(); &#x2F;&#x2F;下面说 afterNodeInsertion(evict); return null; &#125; 在 Java 8 中，如果一个桶中的元素个数超过 TREEIFY_THRESHOLD(默认是 8)，就使用红黑树来替换链表，从而提高速度。上诉代码这个替换的方法叫 treeifyBin() 即树形化。 看一下 treeifyBin() 的源码: 1234567891011121314151617181920212223242526272829&#x2F;&#x2F;将桶内所有的 链表节点 替换成 红黑树节点 final void treeifyBin(Node&lt;K,V&gt;[] tab, int hash) &#123; int n, index; Node&lt;K,V&gt; e; &#x2F;&#x2F;如果当前哈希表为空，或者哈希表中元素的个数小于 进行树形化的阈值(默认为 64)，就去新建&#x2F;扩容 if (tab &#x3D;&#x3D; null || (n &#x3D; tab.length) &lt; MIN_TREEIFY_CAPACITY) resize(); else if ((e &#x3D; tab[index &#x3D; (n - 1) &amp; hash]) !&#x3D; null) &#123; &#x2F;&#x2F;如果哈希表中的元素个数超过了 树形化阈值，进行树形化 &#x2F;&#x2F; e 是哈希表中指定位置桶里的链表节点，从第一个开始 TreeNode&lt;K,V&gt; hd &#x3D; null, tl &#x3D; null; &#x2F;&#x2F;红黑树的头、尾节点 do &#123; &#x2F;&#x2F;新建一个树形节点，内容和当前链表节点 e 一致 TreeNode&lt;K,V&gt; p &#x3D; replacementTreeNode(e, null); if (tl &#x3D;&#x3D; null) &#x2F;&#x2F;确定树头节点 hd &#x3D; p; else &#123; p.prev &#x3D; tl; tl.next &#x3D; p; &#125; tl &#x3D; p; &#125; while ((e &#x3D; e.next) !&#x3D; null); &#x2F;&#x2F;让桶的第一个元素指向新建的红黑树头结点，以后这个桶里的元素就是红黑树而不是链表了 if ((tab[index] &#x3D; hd) !&#x3D; null) hd.treeify(tab); &#125; &#125; TreeNode&lt;K,V&gt; replacementTreeNode(Node&lt;K,V&gt; p, Node&lt;K,V&gt; next) &#123; return new TreeNode&lt;&gt;(p.hash, p.key, p.value, next); &#125; 注释已经很详细了，咱们说一下这个初始化的问题 123&#x2F;&#x2F;如果 table 还未被初始化，那么初始化它if ((tab &#x3D; table) &#x3D;&#x3D; null || (n &#x3D; tab.length) &#x3D;&#x3D; 0)n &#x3D; (tab &#x3D; resize()).length; resize() 扩容机制，单元素如何散列到新的数组中，链表中的元素如何散列到新的数组中，红黑树中的元素如何散列到新的数组中？ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123 &#x2F;&#x2F;上图中说了默认构造方法与自定义构造方法第一次执行resize的过程，这里再说一下扩容的过程 final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab &#x3D; table; int oldCap &#x3D; (oldTab &#x3D;&#x3D; null) ? 0 : oldTab.length; int oldThr &#x3D; threshold; int newCap, newThr &#x3D; 0; if (oldCap &gt; 0) &#123; &#x2F;&#x2F;扩容肯定执行这个分支 if (oldCap &gt;&#x3D; MAXIMUM_CAPACITY) &#123; &#x2F;&#x2F;当容量超过最大值时，临界值设置为int最大值 threshold &#x3D; Integer.MAX_VALUE; return oldTab; &#125; else if ((newCap &#x3D; oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;&#x3D; DEFAULT_INITIAL_CAPACITY) &#x2F;&#x2F;扩容容量为2倍，临界值为2倍 newThr &#x3D; oldThr &lt;&lt; 1; &#125; else if (oldThr &gt; 0) &#x2F;&#x2F; 不执行 newCap &#x3D; oldThr; else &#123; &#x2F;&#x2F; 不执行 newCap &#x3D; DEFAULT_INITIAL_CAPACITY; newThr &#x3D; (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; if (newThr &#x3D;&#x3D; 0) &#123; &#x2F;&#x2F; 不执行 float ft &#x3D; (float)newCap * loadFactor; newThr &#x3D; (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; threshold &#x3D; newThr; &#x2F;&#x2F;将新的临界值赋值赋值给threshold @SuppressWarnings(&#123;&quot;rawtypes&quot;,&quot;unchecked&quot;&#125;) Node&lt;K,V&gt;[] newTab &#x3D; (Node&lt;K,V&gt;[])new Node[newCap]; table &#x3D; newTab; &#x2F;&#x2F;新的数组赋值给table &#x2F;&#x2F;扩容后，重新计算元素新的位置 if (oldTab !&#x3D; null) &#123; &#x2F;&#x2F;原数组 for (int j &#x3D; 0; j &lt; oldCap; ++j) &#123; &#x2F;&#x2F;通过原容量遍历原数组 Node&lt;K,V&gt; e; if ((e &#x3D; oldTab[j]) !&#x3D; null) &#123; &#x2F;&#x2F;判断node是否为空，将j位置上的节点 &#x2F;&#x2F;保存到e,然后将oldTab置为空，这里为什么要把他置为空呢，置为空有什么好处吗？？ &#x2F;&#x2F;难道是吧oldTab变为一个空数组，便于垃圾回收？？ 这里不是很清楚 oldTab[j] &#x3D; null; if (e.next &#x3D;&#x3D; null) &#x2F;&#x2F;判断node上是否有链表 newTab[e.hash &amp; (newCap - 1)] &#x3D; e; &#x2F;&#x2F;无链表，确定元素存放位置， &#x2F;&#x2F;扩容前的元素地址为 (oldCap - 1) &amp; e.hash ,所以这里的新的地址只有两种可能，一是地址不变， &#x2F;&#x2F;二是变为 老位置+oldCap else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else &#123; &#x2F;&#x2F; preserve order Node&lt;K,V&gt; loHead &#x3D; null, loTail &#x3D; null; Node&lt;K,V&gt; hiHead &#x3D; null, hiTail &#x3D; null; Node&lt;K,V&gt; next; &#x2F;* 这里如果判断成立，那么该元素的地址在新的数组中就不会改变。因为oldCap的最高位的1，在e.hash对应的位上为0，所以扩容后得到的地址是一样的，位置不会改变 ，在后面的代码的执行中会放到loHead中去，最后赋值给newTab[j]；如果判断不成立，那么该元素的地址变为 原下标位置+oldCap，也就是lodCap最高位的1，在e.hash对应的位置上也为1，所以扩容后的地址改变了，在后面的代码中会放到hiHead中，最后赋值给newTab[j + oldCap] 举个栗子来说一下上面的两种情况： 设：oldCap&#x3D;16 二进制为：0001 0000 oldCap-1&#x3D;15 二进制为：0000 1111 e1.hash&#x3D;10 二进制为：0000 1010 e2.hash&#x3D;26 二进制为：0101 1010 e1在扩容前的位置为：e1.hash &amp; oldCap-1 结果为：0000 1010 e2在扩容前的位置为：e2.hash &amp; oldCap-1 结果为：0000 1010 结果相同，所以e1和e2在扩容前在同一个链表上，这是扩容之前的状态。 现在扩容后，需要重新计算元素的位置，在扩容前的链表中计算地址的方式为e.hash &amp; oldCap-1 那么在扩容后应该也这么计算呀，扩容后的容量为oldCap*2&#x3D;32 0010 0000 newCap&#x3D;32，新的计算 方式应该为 e1.hash &amp; newCap-1 即：0000 1010 &amp; 0001 1111 结果为0000 1010与扩容前的位置完全一样。 e2.hash &amp; newCap-1 即：0101 1010 &amp; 0001 1111 结果为0001 1010,为扩容前位置+oldCap。 而这里却没有e.hash &amp; newCap-1 而是 e.hash &amp; oldCap，其实这两个是等效的，都是判断倒数第五位 是0，还是1。如果是0，则位置不变，是1则位置改变为扩容前位置+oldCap。 再来分析下loTail loHead这两个的执行过程（假设(e.hash &amp; oldCap) &#x3D;&#x3D; 0成立）： 第一次执行： e指向oldTab[j]所指向的node对象，即e指向该位置上链表的第一个元素 loTail为空,所以loHead指向与e相同的node对象，然后loTail也指向了同一个node对象。 最后，在判断条件e指向next，就是指向oldTab链表中的第二个元素 第二次执行： lotail不为null，所以lotail.next指向e，这里其实是lotail指向的node对象的next指向e， 也可以说是，loHead的next指向了e，就是指向了oldTab链表中第二个元素。此时loHead指向 的node变成了一个长度为2的链表。然后lotail&#x3D;e也就是指向了链表中第二个元素的地址。 第三次执行： 与第二次执行类似，loHead上的链表长度变为3，又增加了一个node，loTail指向新增的node ...... hiTail与hiHead的执行过程与以上相同，这里就不再做解释了。 由此可以看出，loHead是用来保存新链表上的头元素的，loTail是用来保存尾元素的，直到遍 历完链表。 这是(e.hash &amp; oldCap) &#x3D;&#x3D; 0成立的时候。 (e.hash &amp; oldCap) &#x3D;&#x3D; 0不成立的情况也相同，其实就是把oldCap遍历成两个新的链表， 通过loHead和hiHead来保存链表的头结点，然后将两个头结点放到newTab[j]与 newTab[j+oldCap]上面去 *&#x2F; do &#123; next &#x3D; e.next; if ((e.hash &amp; oldCap) &#x3D;&#x3D; 0) &#123; if (loTail &#x3D;&#x3D; null) loHead &#x3D; e; else loTail.next &#x3D; e; loTail &#x3D; e; &#125; else &#123; if (hiTail &#x3D;&#x3D; null) hiHead &#x3D; e; else hiTail.next &#x3D; e; hiTail &#x3D; e; &#125; &#125; while ((e &#x3D; next) !&#x3D; null); if (loTail !&#x3D; null) &#123; loTail.next &#x3D; null; &#x2F;&#x2F;尾节点的next设置为空 newTab[j] &#x3D; loHead; &#125; if (hiTail !&#x3D; null) &#123; hiTail.next &#x3D; null; &#x2F;&#x2F;尾节点的next设置为空 newTab[j + oldCap] &#x3D; hiHead; &#125; &#125; &#125; &#125; &#125; return newTab; &#125; 有关 JDK1.7 扩容出现的死循环的问题: 123456789101112131415161718192021&#x2F;*** Transfers all entries from current table to newTable.*&#x2F;void transfer(Entry[] newTable) &#123; Entry[] src &#x3D; table; int newCapacity &#x3D; newTable.length; for (int j &#x3D; 0; j &lt; src.length; j++) &#123; Entry&lt;K,V&gt; e &#x3D; src[j]; if (e !&#x3D; null) &#123; src[j] &#x3D; null; do &#123; &#x2F;&#x2F; B线程执行到这里之后就暂停了 Entry&lt;K,V&gt; next &#x3D; e.next; int i &#x3D; indexFor(e.hash, newCapacity); e.next &#x3D; newTable[i]; newTable[i] &#x3D; e; e &#x3D; next; &#125; while (e !&#x3D; null); &#125; &#125;&#125; 并发下的 Rehash 1）假设我们有两个线程。我用红色和浅蓝色标注了一下。我们再回头看一下我们的 transfer 代码中的这个细节： 12345678910111213do &#123; Entry&lt;K,V&gt; next &#x3D; e.next; &#x2F;&#x2F; &lt;--假设线程一执行到这里就被调度挂起了 int i &#x3D; indexFor(e.hash, newCapacity); e.next &#x3D; newTable[i]; newTable[i] &#x3D; e; e &#x3D; next;&#125; while (e !&#x3D; null); 而我们的线程二执行完成了。于是我们有下面的这个样子。 注意，因为 Thread1 的 e 指向了 key(3)，而 next 指向了 key(7)，其在线程二 rehash 后，指向了线程二重组后的链表。我们可以看到链表的顺序被反转后。 2）线程一被调度回来执行。 先是执行 newTalbe[i] = e; 然后是 e = next，导致了 e 指向了 key(7)， 而下一次循环的 next = e.next 导致了 next 指向了 key(3) 3）一切安好。 线程一接着工作。把 key(7) 摘下来，放到 newTable[i] 的第一个，然后把 e 和 next 往下移。 4）环形链接出现。 e.next = newTable[i] 导致 key(3).next 指向了 key(7) 注意：此时的 key(7).next 已经指向了 key(3)， 环形链表就这样出现了。 于是，当我们的线程一调用到，HashTable.get(11) 时，悲剧就出现了——Infinite Loop。 因为 HashMap 本来就不支持并发。要并发就用 ConcurrentHashmap HashMap 的 get() 方法 12345public V get(Object key) &#123; Node&lt;K,V&gt; e; &#x2F;&#x2F;直接调用了getNode() return (e &#x3D; getNode(hash(key), key)) &#x3D;&#x3D; null ? null : e.value;&#125; 1234567891011121314151617181920212223final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; &#x2F;&#x2F;先判断数组是否为空，长度是否大于0，那个node节点是否存在 if ((tab &#x3D; table) !&#x3D; null &amp;&amp; (n &#x3D; tab.length) &gt; 0 &amp;&amp; (first &#x3D; tab[(n - 1) &amp; hash]) !&#x3D; null) &#123; &#x2F;&#x2F;如果找到，直接返回 if (first.hash &#x3D;&#x3D; hash &amp;&amp; &#x2F;&#x2F; always check first node ((k &#x3D; first.key) &#x3D;&#x3D; key || (key !&#x3D; null &amp;&amp; key.equals(k)))) return first; if ((e &#x3D; first.next) !&#x3D; null) &#123; &#x2F;&#x2F;如果是红黑树，去红黑树找 if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); &#x2F;&#x2F;链表找 do &#123; if (e.hash &#x3D;&#x3D; hash &amp;&amp; ((k &#x3D; e.key) &#x3D;&#x3D; key || (key !&#x3D; null &amp;&amp; key.equals(k)))) return e; &#125; while ((e &#x3D; e.next) !&#x3D; null); &#125; &#125; return null; &#125; 这里关于first = tab[(n - 1) &amp; hash] 这里通过(n - 1)&amp; hash即可算出桶的在桶数组中的位置，可能有的朋友不太明白这里为什么这么做，这里简单解释一下。HashMap 中桶数组的大小 length 总是 2 的幂，此时，(n - 1) &amp; hash 等价于对 length 取余。但取余的计算效率没有位运算高，所以(n - 1) &amp; hash也是一个小的优化。举个例子说明一下吧，假设 hash = 185，n = 16。计算过程示意图如下 在上面源码中，除了查找相关逻辑，还有一个计算 hash 的方法。这个方法源码如下： 1234567&#x2F;** * 计算键的 hash 值 *&#x2F;static final int hash(Object key) &#123; int h; return (key &#x3D;&#x3D; null) ? 0 : (h &#x3D; key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125; 看这个方法的逻辑好像是通过位运算重新计算 hash，那么这里为什么要这样做呢？为什么不直接用键的 hashCode 方法产生的 hash 呢？大家先可以思考一下，我把答案写在下面。 这样做有两个好处，我来简单解释一下。我们再看一下上面求余的计算图，图中的 hash 是由键的 hashCode 产生。计算余数时，由于 n 比较小，hash 只有低 4 位参与了计算，高位的计算可以认为是无效的。这样导致了计算结果只与低位信息有关，高位数据没发挥作用。为了处理这个缺陷，我们可以上图中的 hash 高 4 位数据与低 4 位数据进行异或运算，即 hash ^ (hash &gt;&gt;&gt; 4)。通过这种方式，让高位数据与低位数据进行异或，以此加大低位信息的随机性，变相的让高位数据参与到计算中。此时的计算过程如下： 在 Java 中，hashCode 方法产生的 hash 是 int 类型，32 位宽。前 16 位为高位，后 16 位为低位，所以要右移 16 位。 上面所说的是重新计算 hash 的一个好处，除此之外，重新计算 hash 的另一个好处是可以增加 hash 的复杂度。当我们覆写 hashCode 方法时，可能会写出分布性不佳的 hashCode 方法，进而导致 hash 的冲突率比较高。通过移位和异或运算，可以让 hash 变得更复杂，进而影响 hash 的分布性。这也就是为什么 HashMap 不直接使用键对象原始 hash 的原因了。 由于个人能力问题, 先学习这些, 数据结构这个大山, 我一定要刨平它。 基于 jdk1.7 版本的 HashMap https://www.jianshu.com/p/dde9b12343c1 参考博客: https://www.cnblogs.com/wenbochang/archive/2018/02/22/8458756.html https://segmentfault.com/a/1190000012926722 https://blog.csdn.net/pange1991/article/details/82377980","categories":[],"tags":[]},{"title":"HashMap 面试必问的数据结构相关知识总结","slug":"HashMap 面试必问的数据结构相关知识总结","date":"2020-07-10T09:07:59.400Z","updated":"2020-07-08T08:00:28.805Z","comments":true,"path":"2020/07/10/HashMap 面试必问的数据结构相关知识总结/","link":"","permalink":"https://topone233.github.io/2020/07/10/HashMap%20%E9%9D%A2%E8%AF%95%E5%BF%85%E9%97%AE%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/","excerpt":"","text":"原文地址 www.cnblogs.com 1：HashMap 的数据结构？ ​ 哈希表结构（链表散列：数组 + 链表）实现，结合数组和链表的优点。当链表长度超过 8 时，链表转换为红黑树。transient Node&lt;K,V&gt;[] table; 2：HashMap 的工作原理？ HashMap 底层是 hash 数组和单向链表实现，数组中的每个元素都是链表，由 Node 内部类（实现 Map.Entry&lt;K,V&gt; 接口）实现，HashMap 通过 put &amp; get 方法存储和获取。 存储对象时，将 K/V 键值传给 put() 方法： ​ ①、调用 hash(K) 方法计算 K 的 hash 值，然后结合数组长度，计算得数组下标； ​ ②、调整数组大小（当容器中的元素个数大于 capacity * loadfactor 时，容器会进行扩容 resize 为 2n）； ​ ③、如果 K 的 hash 值在 HashMap 中不存在，则执行插入，若存在，则发生碰撞； 如果 K 的 hash 值在 HashMap 中存在，且它们两者 equals 返回 true，则更新键值对； 如果 K 的 hash 值在 HashMap 中存在，且它们两者 equals 返回 false，则插入链表的尾部（尾插法）或者红黑树中。 （JDK 1.7 之前使用头插法、JDK 1.8 使用尾插法）（注意：当碰撞导致链表大于 TREEIFY_THRESHOLD = 8 时，就把链表转换成红黑树） 获取对象时，将 K 传给 get() 方法： ①、调用 hash(K) 方法（计算 K 的 hash 值）从而获取该键值所在链表的数组下标； ②、顺序遍历链表，equals() 方法查找相同 Node 链表中 K 值对应的 V 值。 hashCode 是定位的，找到存储位置；equals 是定性的，比较两者是否相等。 3. 当两个对象的 hashCode 相同会发生什么？ 因为 hashCode 相同，不一定就是相等的（equals 方法比较），如果两个对象所在数组的下标相同，”碰撞” 就此发生。又因为 HashMap 使用链表存储对象，这个 Node 会存储到链表中。 4. 你知道 hash 的实现吗？为什么要这样实现？ JDK 1.8 中，是通过 hashCode() 的高 16 位异或低 16 位实现的：(h = k.hashCode()) ^ (h &gt;&gt;&gt; 16)，主要是从速度，功效和质量来考虑的，减少系统的开销，也不会造成因为高位没有参与下标的计算，从而引起的碰撞。 5. 为什么要用异或运算符？ ​ 保证了对象的 hashCode 的 32 位值只要有一位发生改变，整个 hash() 返回值就会改变。尽可能的减少碰撞。 6. HashMap 的 table 的容量如何确定？loadFactor 是什么？ 该容量如何变化？这种变化会带来什么问题？ ​ ①、table 数组大小是由capacity这个参数确定的，默认是 16，也可以构造时传入，最大限制是 1&lt;&lt;30； ​ ②、loadFactor 是装载因子，主要目的是用来确认 table 数组是否需要动态扩展，默认值是 0.75，比如 table 数组大小为 16，装载 因子为 0.75 时，threshold 就是 12，当 table 的实际大小超过 12 时，table 就需要动态扩容； ​ ③、扩容时，调用 resize() 方法，将 table 长度变为原来的两倍（注意是 table 长度，而不是 threshold） ​ ④、如果数据很大的情况下，扩展时将会带来性能的损失，在性能要求很高的地方，这种损失很可能很致命。 7.HashMap 中 put 方法的过程？ 答：“调用哈希函数获取 Key 对应的 hash 值，再计算其数组下标； 如果没有出现哈希冲突，则直接放入数组；如果出现哈希冲突，则以链表的方式放在链表后面； 如果链表长度超过阀值 (TREEIFY THRESHOLD==8)，就把链表转成红黑树，链表长度低于 6，就把红黑树转回链表; 如果结点的 key 已经存在，则替换其 value 即可； 如果集合中的键值对大于 12，调用 resize 方法进行数组扩容。” 8. 数组扩容的过程？ 创建一个新的数组，其容量为旧数组的两倍，并重新计算旧数组中结点的存储位置。结点在新数组中的位置只有两种，原下标位置或原下标 + 旧数组的大小。 9. 拉链法导致的链表过深问题为什么不用二叉查找树代替，而选择红黑树？为什么不一直使用红黑树？ ​ 之所以选择红黑树是为了解决二叉查找树的缺陷，二叉查找树在特殊情况下会变成一条线性结构（这就跟原来使用链表结构一样了，造成很深的问题），遍历查找会非常慢。而红黑树在插入新数据后可能需要通过左旋，右旋、变色这些操作来保持平衡，引入红黑树就是为了查找数据快，解决链表查询深度的问题，我们知道红黑树属于平衡二叉树，但是为了保持 “平衡” 是需要付出代价的，但是该代价所损耗的资源要比遍历线性链表要少，所以当长度大于 8 的时候，会使用红黑树，如果链表长度很短的话，根本不需要引入红黑树，引入反而会慢。 10. 说说你对红黑树的见解？ 1、每个节点非红即黑 2、根节点总是黑色的 3、如果节点是红色的，则它的子节点必须是黑色的（反之不一定） 4、每个叶子节点都是黑色的空节点（NIL 节点） 5、从根节点到叶节点或空子节点的每条路径，必须包含相同数目的黑色节点（即相同的黑色高度） 11.jdk8 中对 HashMap 做了哪些改变？ 在 java 1.8 中，如果链表的长度超过了 8，那么链表将转换为红黑树。（桶的数量必须大于 64，小于 64 的时候只会扩容） 发生 hash 碰撞时，java 1.7 会在链表的头部插入，而 java 1.8 会在链表的尾部插入 在 java 1.8 中，Entry 被 Node 替代 (换了一个马甲)。 12.HashMap，LinkedHashMap，TreeMap 有什么区别？ HashMap 参考其他问题： LinkedHashMap 保存了记录的插入顺序，在用 Iterator 遍历时，先取到的记录肯定是先插入的；遍历比 HashMap 慢； TreeMap 实现 SortMap 接口，能够把它保存的记录根据键排序（默认按键值升序排序，也可以指定排序的比较器） 13.HashMap &amp; TreeMap &amp; LinkedHashMap 使用场景？ 一般情况下，使用最多的是 HashMap。 HashMap：在 Map 中插入、删除和定位元素时； TreeMap：在需要按自然顺序或自定义顺序遍历键的情况下； LinkedHashMap：在需要输出的顺序和输入的顺序相同的情况下。 14.HashMap 和 HashTable 有什么区别？ ①、HashMap 是线程不安全的，HashTable 是线程安全的； ②、由于线程安全，所以 HashTable 的效率比不上 HashMap； ③、HashMap 最多只允许一条记录的键为 null，允许多条记录的值为 null，而 HashTable 不允许； ④、HashMap 默认初始化数组的大小为 16，HashTable 为 11，前者扩容时，扩大两倍，后者扩大两倍 + 1； ⑤、HashMap 需要重新计算 hash 值，而 HashTable 直接使用对象的 hashCode 15.Java 中的另一个线程安全的与 HashMap 极其类似的类是什么？同样是线程安全，它与 HashTable 在线程同步上有什么不同？ ConcurrentHashMap 类（是 Java 并发包 java.util.concurrent 中提供的一个线程安全且高效的 HashMap 实现）。 HashTable 是使用 synchronize 关键字加锁的原理（就是对对象加锁）； 而针对 ConcurrentHashMap，在 JDK 1.7 中采用 分段锁的方式；JDK 1.8 中直接采用了 CAS（无锁算法）+ synchronized。 16.HashMap &amp; ConcurrentHashMap 的区别？ 除了加锁，原理上无太大区别。另外，HashMap 的键值对允许有 null，但是 ConCurrentHashMap 都不允许。 17. 为什么 ConcurrentHashMap 比 HashTable 效率要高？ HashTable 使用一把锁（锁住整个链表结构）处理并发问题，多个线程竞争一把锁，容易阻塞； ConcurrentHashMap JDK 1.7 中使用分段锁（ReentrantLock + Segment + HashEntry），相当于把一个 HashMap 分成多个段，每段分配一把锁，这样支持多线程访问。锁粒度：基于 Segment，包含多个 HashEntry。 JDK 1.8 中使用 CAS + synchronized + Node + 红黑树。锁粒度：Node（首结点）（实现 Map.Entry&lt;K,V&gt;）。锁粒度降低了。 18. 针对 ConcurrentHashMap 锁机制具体分析（JDK 1.7 VS JDK 1.8）？ JDK 1.7 中，采用分段锁的机制，实现并发的更新操作，底层采用数组 + 链表的存储结构，包括两个核心静态内部类 Segment 和 HashEntry。 ①、Segment 继承 ReentrantLock（重入锁） 用来充当锁的角色，每个 Segment 对象守护每个散列映射表的若干个桶； ②、HashEntry 用来封装映射表的键 - 值对； ③、每个桶是由若干个 HashEntry 对象链接起来的链表 JDK 1.8 中，采用 Node + CAS + Synchronized 来保证并发安全。取消类 Segment，直接用 table 数组存储键值对；当 HashEntry 对象组成的链表长度超过 TREEIFY_THRESHOLD 时，链表转换为红黑树，提升性能。底层变更为数组 + 链表 + 红黑树。 19.ConcurrentHashMap 在 JDK 1.8 中，为什么要使用内置锁 synchronized 来代替重入锁 ReentrantLock？ ①、粒度降低了； ②、JVM 开发团队没有放弃 synchronized，而且基于 JVM 的 synchronized 优化空间更大，更加自然。 ③、在大量的数据操作下，对于 JVM 的内存压力，基于 API 的 ReentrantLock 会开销更多的内存。 20.ConcurrentHashMap 简单介绍？ ①、重要的常量： private transient volatile int sizeCtl; 当为负数时，-1 表示正在初始化，-N 表示 N - 1 个线程正在进行扩容； 当为 0 时，表示 table 还没有初始化； 当为其他正数时，表示初始化或者下一次进行扩容的大小。 ②、数据结构： Node 是存储结构的基本单元，继承 HashMap 中的 Entry，用于存储数据； TreeNode 继承 Node，但是数据结构换成了二叉树结构，是红黑树的存储结构，用于红黑树中存储数据； TreeBin 是封装 TreeNode 的容器，提供转换红黑树的一些条件和锁的控制。 ③、存储对象时（put() 方法）： 1. 如果没有初始化，就调用 initTable() 方法来进行初始化； 2. 如果没有 hash 冲突就直接 CAS 无锁插入； 3. 如果需要扩容，就先进行扩容； 4. 如果存在 hash 冲突，就加锁来保证线程安全，两种情况：一种是链表形式就直接遍历到尾端插入，一种是红黑树就按照红黑树结构插入； 5. 如果该链表的数量大于阀值 8，就要先转换成红黑树的结构，break 再一次进入循环 6. 如果添加成功就调用 addCount() 方法统计 size，并且检查是否需要扩容。 ④、扩容方法 transfer()：默认容量为 16，扩容时，容量变为原来的两倍。 helpTransfer()：调用多个工作线程一起帮助进行扩容，这样的效率就会更高。 ⑤、获取对象时（get() 方法）： 1. 计算 hash 值，定位到该 table 索引位置，如果是首结点符合就返回； 2. 如果遇到扩容时，会调用标记正在扩容结点 ForwardingNode.find() 方法，查找该结点，匹配就返回； 3. 以上都不符合的话，就往下遍历结点，匹配就返回，否则最后就返回 null。 21.ConcurrentHashMap 的并发度是什么？ 程序运行时能够同时更新 ConccurentHashMap 且不产生锁竞争的最大线程数。默认为 16，且可以在构造函数中设置。当用户设置并发度时，ConcurrentHashMap 会使用大于等于该值的最小 2 幂指数作为实际并发度（假如用户设置并发度为 17，实际并发度则为 32） 有时间会对 HashTable，ConcurrentHashmap 解析。 参考博客：https://www.cnblogs.com/heqiyoujing/p/11143298.html https://www.jianshu.com/p/75adf47958a7","categories":[],"tags":[]},{"title":"浅谈HashMap","slug":"浅谈HashMap","date":"2020-07-10T09:07:59.392Z","updated":"2020-07-05T09:59:55.026Z","comments":true,"path":"2020/07/10/浅谈HashMap/","link":"","permalink":"https://topone233.github.io/2020/07/10/%E6%B5%85%E8%B0%88HashMap/","excerpt":"","text":"HashMap 什么是哈希表 HashMap的实现原理 为何HashMap的数组长度一定是2的次幂 重写equals方法需同时重写hashCode方法 JDK1.8中HashMap的性能优化 参考自：https://blog.csdn.net/woshimaxiao1/article/details/83661464 1.什么是哈希表讨论哈希表之前，先大概了解下其他数据结构 数组采用一段连续的存储单元来存储数据。 通过指定下标查找，时间复杂度为O(1)； 通过给定值查找，需要遍历数组，逐一对比给定关键字和数组元素，时间复杂度O(n)。 对于有序数组，则可采用二分查找、插值查找、斐波那契查找等方式，可将复杂度提高到O(logn)；一般的插入删除操作，涉及到数组元素的移动，评价复杂度也为O(n)。 线性链表对于链表的新增、删除等操作，在找到指定操作位置后，仅需处理结点间的引用即可，时间复杂度为O(1),而查找操作需要遍历链表逐一进行对比，复杂度为O(n)。 二叉树对一棵相对平衡的有序二叉树，CRUD，平均复杂度均为O(logn)。 哈希表哈希表(hash table)进行CRUD，性能十分之高，不考虑哈希冲突的情况下，仅需一次定位即可完成，时间复杂度为O(1)。 数据结构的物理存储结构只有两种：顺序存储结构和链式存储结构。栈、队列、树、图等都是从逻辑结构去抽象，映射到内存中，也是这两种物理组织形式。 哈希表主干是数组。如果要新增或查找某个元素，把元素的关键字，通过某个函数映射到数组中的某个位置，通过数组下标一次定位就可以完成。这个函数可以简单描述为：存储位置=f(关键字)。函数f一般成为哈希函数，直接影响到哈希表的优劣。 哈希冲突如果两个不同的元素，通过哈希函数得出的实际存储地址相同；或者元素哈希运算得到一个存储地址，进行插入的时候发现已经被其他元素占用了，这就是所谓的哈希冲突，也叫哈希碰撞。 好的哈希函数会尽可能使计算简单和散列地址分布均匀。但是，数组是一块连续的固定长度的内存空间，再好的哈希函数也不能保证得到的存储地址绝对不发生冲突。 哈希冲突的解决方案有多种：开放定址法(发生冲突，继续寻找下一块未被占用的存储地址)、再散列函数法、链地址法。HashMap采用的即是链地址法，也就是数组+链表的方式。 2.HashMap的实现原理HashMap的主干是一个Entry数组。Entry是HashMap的基本组成单元，每一个Entry包含一个key-value键值对。（其实所谓的Map就是保存了两个对象之间的映射关系的一种集合）。 12&#x2F;&#x2F;主干是一个Entry数组，初始值为空数组，长度一定是2的次幂transient Entry&lt;K,V&gt;[] table &#x3D; (Entry&lt;K,V&gt;[]) EMPty_TABLE; Entry是HashMap中的一个静态内部类。代码如下: 123456789101112131415static class Entry&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final K key; V value; &#x2F;&#x2F;存储执向下一个Entry的引用，单链表结构 Entry&lt;K,V&gt; next; &#x2F;&#x2F;对key的hashcode值进行hash运算后得到的值，存储在Entry，避免重复计算 int hash; &#x2F;&#x2F;creats new entry Entry(int h, k K, V v, Entry&lt;K,V&gt; n) &#123; value &#x3D; v; next &#x3D; n; key &#x3D; k; hash &#x3D; h; &#125; 总结一下：HashMap由数组+链表组成，Entry数组是HashMap的主体，链表用于解决哈希冲突。如果定位到的数组位置不含链表(当前entry的next指向null)，那么CRUD很快，O(1)，仅需一次寻址即可；如果定位到的数组包含链表，添加操作，复杂度O(n)，先遍历链表，存在即覆盖，否则新增；查找操作，仍需遍历链表，然后通过key对象的equals方法逐一对比查找。所以，HashMap中的链表出现越少，性能越好。 HashMap的4个构造器size、threshold、loadFactor、modCount 1234567891011121314151617&#x2F;&#x2F;实际存储key-value键值对的个数transient int size;&#x2F;&#x2F;阈值，当table &#x3D;&#x3D; &#123;&#125;时，该值为初始容量(默认16)&#x2F;&#x2F;当table被填充了，也就是为table分配内存空间后，threshold一般为capacity*loadFactory&#x2F;&#x2F;HashMap在进行扩容时需要参考thresholdint threshold;&#x2F;&#x2F;负载因子，代表了table的填充度，默认是0.75&#x2F;&#x2F;负载因子存在的原因，还是为了减缓哈希冲突&#x2F;&#x2F;如果初始桶为16，等到满16个才扩容，某些桶可能就有不止一个元素了&#x2F;&#x2F;所以加载因子默认为0.75，也就是说大小为16的HashMap，到了第13个元素，就会扩容成32final float loadFactor;&#x2F;&#x2F;HashMap被改变的次数&#x2F;&#x2F;由于HashMap非线程安全，在对HashMap进行迭代时，如果其他线程的参与导致HashMap的结构发生了变化(put、remove等操作)，需要抛出异常ConcurrentModificationExceptiontransient int modeCount; 示例代码: 1234567891011121314151617public HashMap(int initialCapacity, float loadFactor) &#123; &#x2F;&#x2F;此处对传入的初始容量进行校验，最大不能超过MAXIMUM_CAPACITY &#x3D; 1&lt;&lt;30(230) if (initialCapacity &lt; 0) throw new IllegalArgumentException(&quot;Illegal initial capacity: &quot; + initialCapacity); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity &#x3D; MAXIMUM_CAPACITY; if (loadFactor &lt;&#x3D; 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(&quot;Illegal load factor: &quot; + loadFactor); this.loadFactor &#x3D; loadFactor; threshold &#x3D; initialCapacity; &#x2F;&#x2F;init方法在HashMap中没有实际实现，不过在其子类如 linkedHashMap中就会有对应实现 init(); &#125; 从上面这段代码我们可以看出，在常规构造器中，没有为数组table分配内存空间（有一个入参为指定Map的构造器例外），而是在执行put操作的时候才真正构建table数组 put操作的实现: 12345678910111213141516171819202122232425public V put(K key, V value) &#123; &#x2F;&#x2F;如果table数组为空数组&#123;&#125;，进行数组填充（为table分配实际内存空间），入参为threshold， &#x2F;&#x2F;此时threshold为initialCapacity 默认是1&lt;&lt;4(24&#x3D;16) if (table &#x3D;&#x3D; EMPTY_TABLE) &#123; inflateTable(threshold); &#125; &#x2F;&#x2F;如果key为null，存储位置为table[0]或table[0]的冲突链上 if (key &#x3D;&#x3D; null) return putForNullKey(value); int hash &#x3D; hash(key);&#x2F;&#x2F;对key的hashcode进一步计算，确保散列均匀 int i &#x3D; indexFor(hash, table.length);&#x2F;&#x2F;获取在table中的实际位置 for (Entry&lt;K,V&gt; e &#x3D; table[i]; e !&#x3D; null; e &#x3D; e.next) &#123; &#x2F;&#x2F;如果该对应数据已存在，执行覆盖操作。用新value替换旧value，并返回旧value Object k; if (e.hash &#x3D;&#x3D; hash &amp;&amp; ((k &#x3D; e.key) &#x3D;&#x3D; key || key.equals(k))) &#123; V oldValue &#x3D; e.value; e.value &#x3D; value; e.recordAccess(this); return oldValue; &#125; &#125; modCount++;&#x2F;&#x2F;保证并发访问时，若HashMap内部结构发生变化，快速响应失败 addEntry(hash, key, value, i);&#x2F;&#x2F;新增一个entry return null; &#125; inflateTable这个方法用于为主干数组table在内存中分配存储空间，通过roundUpToPowerOf2(toSize)可以确保capacity为大于或等于toSize的最接近toSize的二次幂，比如toSize=13,则capacity=16;to_size=16,capacity=16;to_size=17,capacity=32。 123456789private void inflateTable(int toSize) &#123; &#x2F;&#x2F;capacity一定是2的次幂 int capacity &#x3D; roundUpToPowerOf2(toSize); &#x2F;&#x2F;此处为threshold赋值，取capacity*loadFactor和MAXIMUM_CAPACITY+1的最小值， &#x2F;&#x2F;capaticy一定不会超过MAXIMUM_CAPACITY，除非loadFactor大于1 threshold &#x3D; (int) Math.min(capacity * loadFactor, MAXIMUM_CAPACITY + 1); table &#x3D; new Entry[capacity]; initHashSeedAsNeeded(capacity); &#125; roundUpToPowerOf2中的这段处理使得数组长度一定为2的次幂，Integer.highestOneBit是用来获取最左边的bit（其他bit位为0）所代表的数值 123456private static int roundUpToPowerOf2(int number) &#123; &#x2F;&#x2F; assert number &gt;&#x3D; 0 : &quot;number must be non-negative&quot;; return number &gt;&#x3D; MAXIMUM_CAPACITY ? MAXIMUM_CAPACITY : (number &gt; 1) ? Integer.highestOneBit((number - 1) &lt;&lt; 1) : 1; &#125; hash函数: 12345678910111213&#x2F;&#x2F;这是一个神奇的函数，用了很多的异或，移位等运算&#x2F;&#x2F;对key的hashcode进一步进行计算以及二进制位的调整等来保证最终获取的存储位置尽量分布均匀final int hash(Object k) &#123; int h &#x3D; hashSeed; if (0 !&#x3D; h &amp;&amp; k instanceof String) &#123; return sun.misc.Hashing.stringHash32((String) k); &#125; h ^&#x3D; k.hashCode(); h ^&#x3D; (h &gt;&gt;&gt; 20) ^ (h &gt;&gt;&gt; 12); return h ^ (h &gt;&gt;&gt; 7) ^ (h &gt;&gt;&gt; 4); &#125; 以上hash函数计算出的值，通过indexFor进一步处理来获取实际的存储位置 1234&#x2F;&#x2F;返回数组下标static int indexFor(int h, int length) &#123; return h &amp; (length-1);&#125; h&amp;（length-1）保证获取的index一定在数组范围内，举个例子，默认容量16，length-1=15，h=18,转换成二进制计算为index=2。位运算对计算机来说，性能更高一些（HashMap中有大量位运算） 所以最终存储位置的确定流程是这样的： 123 hashCode() hash() indexFor()key ----------&gt; hashcode ----------&gt; h ------------&gt; 存储下标 h&amp;(length-1) 再来看看addEntry的实现： 12345678910void addEntry(int hash, K key, V value, int bucketIndex) &#123; if ((size &gt;&#x3D; threshold) &amp;&amp; (null !&#x3D; table[bucketIndex])) &#123; &#x2F;&#x2F;当size超过临界阈值threshold，并且即将发生哈希冲突时进行扩容 resize(2 * table.length); hash &#x3D; (null !&#x3D; key) ? hash(key) : 0; bucketIndex &#x3D; indexFor(hash, table.length); &#125; createEntry(hash, key, value, bucketIndex); &#125; 通过以上代码能够得知，当发生哈希冲突并且size大于阈值的时候，需要进行数组扩容，扩容时，需要新建一个长度为之前数组2倍的新的数组，然后将当前的Entry数组中的元素全部传输过去，扩容后的新数组长度为之前的2倍，所以扩容相对来说是个耗资源的操作 3.为何HashMap的数组长度一定是2的次幂我们来继续看上面提到的resize方法: 12345678910111213void resize(int newCapacity) &#123; Entry[] oldTable &#x3D; table; int oldCapacity &#x3D; oldTable.length; if (oldCapacity &#x3D;&#x3D; MAXIMUM_CAPACITY) &#123; threshold &#x3D; Integer.MAX_VALUE; return; &#125; Entry[] newTable &#x3D; new Entry[newCapacity]; transfer(newTable, initHashSeedAsNeeded(newCapacity)); table &#x3D; newTable; threshold &#x3D; (int)Math.min(newCapacity * loadFactor, MAXIMUM_CAPACITY + 1); &#125; 如果数组进行扩容，数组长度发生变化，而存储位置 index = h&amp;(length-1),index也可能会发生变化，需要重新计算index，我们先来看看transfer这个方法: 1234567891011121314151617void transfer(Entry[] newTable, boolean rehash) &#123; int newCapacity &#x3D; newTable.length; &#x2F;&#x2F;for循环中的代码，逐个遍历链表，重新计算索引位置，将老数组数据复制到新数组中去（数组不存储实际数据，所以仅仅是拷贝引用而已） for (Entry&lt;K,V&gt; e : table) &#123; while(null !&#x3D; e) &#123; Entry&lt;K,V&gt; next &#x3D; e.next; if (rehash) &#123; e.hash &#x3D; null &#x3D;&#x3D; e.key ? 0 : hash(e.key); &#125; int i &#x3D; indexFor(e.hash, newCapacity); &#x2F;&#x2F;将当前entry的next链指向新的索引位置,newTable[i]有可能为空，有可能也是个entry链，如果是entry链，直接在链表头部插入。 e.next &#x3D; newTable[i]; newTable[i] &#x3D; e; e &#x3D; next; &#125; &#125; &#125; 这个方法将老数组中的数据逐个链表地遍历，扔到新的扩容后的数组中，我们的数组索引位置的计算是通过 对key值的hashcode进行hash扰乱运算后，再通过和 length-1进行位运算得到最终数组索引位置。 HashMap的数组长度一定保持2的次幂，比如16的二进制表示为 10000，那么length-1就是15，二进制为01111，同理扩容后的数组长度为32，二进制表示为100000，length-1为31，二进制表示为011111。从下图可以我们也能看到这样会保证低位全为1，而扩容后只有一位差异，也就是多出了最左位的1，这样在通过 h&amp;(length-1)的时候，只要h对应的最左边的那一个差异位为0，就能保证得到的新的数组索引和老数组索引一致(大大减少了之前已经散列良好的老数组的数据位置重新调换)，个人理解。 还有，数组长度保持2的次幂，length-1的低位都为1，会使得获得的数组索引index更加均匀 我们看到，上面的&amp;运算，高位是不会对结果产生影响的（hash函数采用各种位运算可能也是为了使得低位更加散列），我们只关注低位bit，如果低位全部为1，那么对于h低位部分来说，任何一位的变化都会对结果产生影响，也就是说，要得到index=21这个存储位置，h的低位只有这一种组合。这也是数组长度设计为必须为2的次幂的原因。 如果不是2的次幂，也就是低位不是全为1此时，要使得index=21，h的低位部分不再具有唯一性了，哈希冲突的几率会变的更大，同时，index对应的这个bit位无论如何不会等于1了，而对应的那些数组位置也就被白白浪费了。 get方法: 1234567public V get(Object key) &#123; &#x2F;&#x2F;如果key为null,则直接去table[0]处去检索即可。 if (key &#x3D;&#x3D; null) return getForNullKey(); Entry&lt;K,V&gt; entry &#x3D; getEntry(key); return null &#x3D;&#x3D; entry ? null : entry.getValue();&#125; get方法通过key值返回对应value，如果key为null，直接去table[0]处检索。 我们再看一下getEntry方法: 123456789101112131415161718final Entry&lt;K,V&gt; getEntry(Object key) &#123; if (size &#x3D;&#x3D; 0) &#123; return null; &#125; &#x2F;&#x2F;通过key的hashcode值计算hash值 int hash &#x3D; (key &#x3D;&#x3D; null) ? 0 : hash(key); &#x2F;&#x2F;indexFor (hash&amp;length-1) 获取最终数组索引，然后遍历链表，通过equals方法比对找出对应记录 for (Entry&lt;K,V&gt; e &#x3D; table[indexFor(hash, table.length)]; e !&#x3D; null; e &#x3D; e.next) &#123; Object k; if (e.hash &#x3D;&#x3D; hash &amp;&amp; ((k &#x3D; e.key) &#x3D;&#x3D; key || (key !&#x3D; null &amp;&amp; key.equals(k)))) return e; &#125; return null; &#125; 可以看出，get方法的实现相对简单，key(hashcode)–&gt;hash–&gt;indexFor–&gt;最终索引位置，找到对应位置table[i]，再查看是否有链表，遍历链表，通过key的equals方法比对查找对应的记录。要注意的是，有人觉得上面在定位到数组位置之后然后遍历链表的时候，e.hash == hash这个判断没必要，仅通过equals判断就可以。其实不然，试想一下，如果传入的key对象重写了equals方法却没有重写hashCode，而恰巧此对象定位到这个数组位置，如果仅仅用equals判断可能是相等的，但其hashCode和当前对象不一致，这种情况，根据Object的hashCode的约定，不能返回当前对象，而应该返回null，后面的例子会做出进一步解释。 4.重写equals方法需同时重写hashCode方法先来看下如果重写equals而不重写hashcode会发生什么: 12345678910111213141516171819202122232425262728293031323334public class MyTest &#123; private static class Person&#123; int idCard; String name; public Person(int idCard, String name) &#123; this.idCard &#x3D; idCard; this.name &#x3D; name; &#125; @Override public boolean equals(Object o) &#123; if (this &#x3D;&#x3D; o) &#123; return true; &#125; if (o &#x3D;&#x3D; null || getClass() !&#x3D; o.getClass())&#123; return false; &#125; Person person &#x3D; (Person) o; &#x2F;&#x2F;两个对象是否等值，通过idCard来确定 return this.idCard &#x3D;&#x3D; person.idCard; &#125; &#125; public static void main(String []args)&#123; HashMap&lt;Person,String&gt; map &#x3D; new HashMap&lt;Person, String&gt;(); Person person &#x3D; new Person(1234,&quot;乔峰&quot;); &#x2F;&#x2F;put到hashmap中去 map.put(person,&quot;天龙八部&quot;); &#x2F;&#x2F;get取出，从逻辑上讲应该能输出“天龙八部” System.out.println(&quot;结果:&quot;+map.get(new Person(1234,&quot;萧峰&quot;))); &#125;&#125;实际输出结果：null 如果我们已经对HashMap的原理有了一定了解，这个结果就不难理解了。尽管我们在进行get和put操作的时候，使用的key从逻辑上讲是等值的（通过equals比较是相等的），但由于没有重写hashCode方法，所以put操作时，key(hashcode1)–&gt;hash–&gt;indexFor–&gt;最终索引位置 ，而通过key取出value的时候 key(hashcode1)–&gt;hash–&gt;indexFor–&gt;最终索引位置，由于hashcode1不等于hashcode2，导致没有定位到一个数组位置而返回逻辑上错误的值null(也有可能碰巧定位到一个数组位置，但是也会判断其entry的hash值是否相等，上面get方法中有提到) 所以，在重写equals的方法的时候，必须注意重写hashCode方法，同时还要保证通过equals判断相等的两个对象，调用hashCode方法要返回同样的整数值。而如果equals判断不相等的两个对象，其hashCode可以相同(只不过会发生哈希冲突，应尽量避免) 5.JDK1.8中HashMap的性能优化假如一个数组槽位上链上数据过多（即拉链过长的情况）导致性能下降该怎么办？ JDK1.8在JDK1.7的基础上针对增加了红黑树来进行优化。即当链表超过8时，链表就转换为红黑树，利用红黑树快速增删改查的特点提高HashMap的性能，其中会用到红黑树的插入、删除、查找等算法","categories":[],"tags":[]},{"title":"九大常见数据结构","slug":"九大常见数据结构","date":"2020-07-10T09:07:59.386Z","updated":"2020-07-10T09:22:00.737Z","comments":true,"path":"2020/07/10/九大常见数据结构/","link":"","permalink":"https://topone233.github.io/2020/07/10/%E4%B9%9D%E5%A4%A7%E5%B8%B8%E8%A7%81%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/","excerpt":"","text":"数据结构想必大家都不会陌生，对于一个成熟的程序员而言，熟悉和掌握数据结构和算法也是基本功之一。数据结构本身其实不过是数据按照特点关系进行存储或者组织的集合，特殊的结构在不同的应用场景中往往会带来不一样的处理效率。 常用的数据结构可根据数据访问的特点分为线性结构和非线性结构。线性结构包括常见的链表、栈、队列等，非线性结构包括树、图等。数据结构种类繁多，本文将通过图解的方式对常用的数据结构进行理论上的介绍和讲解，以方便大家掌握常用数据结构的基本知识。 本文提纲 1 数组数组可以说是最基本最常见的数据结构。数组一般用来存储相同类型的数据，可通过数组名和下标进行数据的访问和更新。数组中元素的存储是按照先后顺序进行的，同时在内存中也是按照这个顺序进行连续存放。数组相邻元素之间的内存地址的间隔一般就是数组数据类型的大小。 2 链表链表相较于数组，除了数据域，还增加了指针域用于构建链式的存储数据。链表中每一个节点都包含此节点的数据和指向下一节点地址的指针。由于是通过指针进行下一个数据元素的查找和访问，使得链表的自由度更高。 这表现在对节点进行增加和删除时，只需要对上一节点的指针地址进行修改，而无需变动其它的节点。不过事物皆有两极，指针带来高自由度的同时，自然会牺牲数据查找的效率和多余空间的使用。 一般常见的是有头有尾的单链表，对指针域进行反向链接，还可以形成双向链表或者循环链表。 链表和数组对比链表和数组在实际的使用过程中需要根据自身的优劣势进行选择。链表和数组的异同点也是面试中高频的考察点之一。这里对单链表和数组的区别进行了对比和总结。 3 跳表从上面的对比中可以看出，链表虽然通过增加指针域提升了自由度，但是却导致数据的查询效率恶化。特别是当链表长度很长的时候，对数据的查询还得从头依次查询，这样的效率会更低。跳表的产生就是为了解决链表过长的问题，通过增加链表的多级索引来加快原始链表的查询效率。这样的方式可以让查询的时间复杂度从 O(n) 提升至 O(logn)。 跳表通过增加的多级索引能够实现高效的动态插入和删除，其效率和红黑树和平衡二叉树不相上下。目前 redis 和 levelDB 都有用到跳表。 从上图可以看出，索引级的指针域除了指向下一个索引位置的指针，还有一个 down 指针指向低一级的链表位置，这样才能实现跳跃查询的目的。 4 栈栈是一种比较简单的数据结构，常用一句话描述其特性，后进先出。栈本身是一种线性结构，但是在这个结构中只有一个口子允许数据的进出。这种模式可以参考腔肠动物… 即进食和排泄都用一个口… 栈的常用操作包括入栈 push 和出栈 pop，对应于数据的压入和压出。还有访问栈顶数据、判断栈是否为空和判断栈的大小等。由于栈后进先出的特性，常可以作为数据操作的临时容器，对数据的顺序进行调控，与其它数据结构相结合可获得许多灵活的处理。 5 队列队列是栈的兄弟结构，与栈的后进先出相对应，队列是一种先进先出的数据结构。顾名思义，队列的数据存储是如同排队一般，先存入的数据先被压出。常与栈一同配合，可发挥最大的实力。 6 树树作为一种树状的数据结构，其数据节点之间的关系也如大树一样，将有限个节点根据不同层次关系进行排列，从而形成数据与数据之间的父子关系。常见的数的表示形式更接近 “倒挂的树”，因为它将根朝上，叶朝下。 树是图的一种，树与图的区别在于：树是没有环的，而图是可以有环的。 树的数据存储在结点中，每个结点有零个或者多个子结点。没有父结点的结点在最顶端，成为根节点；没有非根结点有且只有一个父节点；每个非根节点又可以分为多个不相交的子树。 这意味着树是具备层次关系的，父子关系清晰，家庭血缘关系明朗；这也是树与图之间最主要的区别。 别看树好像很高级，其实可看作是链表的高配版。树的实现就是对链表的指针域进行了扩充，增加了多个地址指向子结点。同时将 “链表” 竖起来，从而凸显了结点之间的层次关系，更便于分析和理解。 树可以衍生出许多的结构，若将指针域设置为双指针，那么即可形成最常见的二叉树，即每个结点最多有两个子树的树结构。二叉树根据结点的排列和数量还可进一度划分为完全二叉树、满二叉树、平衡二叉树、红黑树等。 完全二叉树：除了最后一层结点，其它层的结点数都达到了最大值；同时最后一层的结点都是按照从左到右依次排布。 满二叉树：除了最后一层，其它层的结点都有两个子结点。 平衡二叉树平衡二叉树又被称为 AVL 树，它是一棵二叉排序树，且具有以下性质：它是一棵空树或它的左右两个子树的高度差的绝对值不超过 1，并且左右两个子树都是一棵平衡二叉树。 二叉排序树：是一棵空树，或者：若它的左子树不空，则左子树上所有结点的值均小于它的根结点的值；若它的右子树不空，则右子树上所有结点的值均大于它的根结点的值；它的左、右子树也分别为二叉排序树。 树的高度：结点层次的最大值 平衡因子：左子树高度 - 右子树高度 二叉排序树意味着二叉树中的数据是排好序的，顺序为左结点 &lt;根节点&lt;右结点，这表明二叉排序树的中序遍历结果是有序的。 （二叉树四种遍历方式[前序遍历、中序遍历、后序遍历、层序遍历] ） 平衡二叉树的产生是为了解决二叉排序树在插入时发生线性排列的现象。由于二叉排序树本身为有序，当插入一个有序程度十分高的序列时，生成的二叉排序树会持续在某个方向的字数上插入数据，导致最终的二叉排序树会退化为链表，从而使得二叉树的查询和插入效率恶化。 平衡二叉树的出现能够解决上述问题，但是在构造平衡二叉树时，却需要采用不同的调整方式，使得二叉树在插入数据后保持平衡。主要的四种调整方式有 LL（左旋）、RR（右旋）、LR（先左旋再右旋）、RL（先右旋再左旋）。这里先给大家介绍下简单的单旋转操作，左旋和右旋。LR 和 RL 本质上只是 LL 和 RR 的组合。 在插入一个结点后应该沿搜索路径将路径上的结点平衡因子进行修改，当平衡因子大于 1 时，就需要进行平衡化处理。从发生不平衡的结点起，沿刚才回溯的路径取直接下两层的结点，如果这三个结点在一条直线上，则采用单旋转进行平衡化，如果这三个结点位于一条折线上，则采用双旋转进行平衡化。 左旋：S 为当前需要左旋的结点，E 为当前结点的父节点。 左旋的操作可以用一句话简单表示：将当前结点 S 的左孩子旋转为当前结点父结点 E 的右孩子，同时将父结点 E 旋转为当前结点 S 的左孩子。可用动画表示： 右旋：S 为当前需要左旋的结点，E 为当前结点的父节点。右单旋是左单旋的镜像旋转。 左旋的操作同样可以用一句话简单表示：将当前结点 S 的左孩子 E 的右孩子旋转为当前结点 S 的左孩子，同时将当前结点 S 旋转为左孩子 E 的右孩子。可用动画表示： 红黑树平衡二叉树（AVL）为了追求高度平衡，需要通过平衡处理使得左右子树的高度差必须小于等于 1。高度平衡带来的好处是能够提供更高的搜索效率，其最坏的查找时间复杂度都是 O(logN)。但是由于需要维持这份高度平衡，所付出的代价就是当对树种结点进行插入和删除时，需要经过多次旋转实现复衡。这导致 AVL 的插入和删除效率并不高。 为了解决这样的问题，能不能找一种结构能够兼顾搜索和插入删除的效率呢？这时候红黑树便申请出战了。 红黑树具有五个特性： 每个结点要么是红的要么是黑的。 根结点是黑的。 每个叶结点（叶结点即指树尾端 NIL 指针或 NULL 结点）都是黑的。 如果一个结点是红的，那么它的两个儿子都是黑的。 对于任意结点而言，其到叶结点树尾端 NIL 指针的每条路径都包含相同数目的黑结点。 红黑树通过将结点进行红黑着色，使得原本高度平衡的树结构被稍微打乱，平衡程度降低。红黑树不追求完全平衡，只要求达到部分平衡。这是一种折中的方案，大大提高了结点删除和插入的效率。C++ 中的 STL 就常用到红黑树作为底层的数据结构。 红黑树 VS 平衡二叉树 除了上面所提及的树结构，还有许多广泛应用在数据库、磁盘存储等场景下的树结构。比如 B 树、B + 树等。这里就先不介绍了诶，下次在讲述相关存储原理的时候将会着重介绍。（其实是因为懒） B树（B-tree）B树和平衡二叉树稍有不同的是B树属于多叉树又名平衡多路查找树（查找路径不只两个），数据库索引技术里大量使用者B树和B+树的数据结构。B树相对于平衡二叉树，每个节点包含的关键字增多了，特别是在B树应用到数据库中的时候，数据库充分利用了磁盘块的原理（磁盘数据存储是采用块的形式存储的，每个块的大小为4K，每次IO进行数据读取时，同一个磁盘块的数据可以一次性读取出来）把节点大小限制和充分使用在磁盘快大小范围；把树的节点关键字增多后树的层级比原来的二叉树少了，减少数据查找的次数和复杂度; 规则： 排序方式：所有节点关键字是按递增次序排列，并遵循左小右大原则； 子节点数：非叶节点的子节点数&gt;1，且&lt;=M ，且M&gt;=2，空树除外（注：M阶代表一个树节点最多有多少个查找路径，M=M路,当M=2则是2叉树,M=3则是3叉）； 关键字数：枝节点的关键字数量大于等于ceil(m/2)-1个且小于等于M-1个（注：ceil()是个朝正无穷方向取整的函数 如ceil(1.1)结果为2)； 所有叶子节点均在同一层、叶子节点除了包含了关键字和关键字记录的指针外也有指向其子节点的指针只不过其指针地址都为null对应下图最后一层节点的空格子; 查询： 如上图我要从上图中找到E字母，查找流程如下 获取根节点的关键字进行比较，当前根节点关键字为M，E&lt;M（26个字母顺序），所以往找到指向左边的子节点（二分法规则，左小右大，左边放小于当前节点值的子节点、右边放大于当前节点值的子节点）； 拿到关键字D和G，D&lt;E&lt;G 所以直接找到D和G中间的节点； 拿到E和F，因为E=E 所以直接返回关键字和指针信息（如果树结构里面没有包含所要查找的节点则返回null）； 插入： 节点拆分规则：当前是要组成一个5路查找树，那么此时m=5,关键字数必须&lt;=5-1（这里关键字数&gt;4就要进行节点拆分）； 排序规则：满足节点本身比左边节点大，比右边节点小的排序规则; 删除： 节点合并规则：当前是要组成一个5路查找树，那么此时m=5,关键字数必须大于等于ceil（5/2）（这里关键字数&lt;2就要进行节点合并）； 满足节点本身比左边节点大，比右边节点小的排序规则; 关键字数小于二时先从子节点取，子节点没有符合条件时就向向父节点取，取中间值往父节点放； B+树B+树是B树的一个升级版，相对于B树来说B+树更充分的利用了节点的空间，让查询速度更加稳定，其速度完全接近于二分法查找。查找的效率要比B树更高、更稳定。 规则： B+跟B树不同B+树的非叶子节点不保存关键字记录的指针，只进行数据索引，这样使得B+树每个非叶子节点所能保存的关键字大大增加； B+树叶子节点保存了父节点的所有关键字记录的指针，所有数据地址必须要到叶子节点才能获取到。所以每次数据查询的次数都一样； B+树叶子节点的关键字从小到大有序排列，左边结尾数据都会保存右边节点开始数据的指针。 非叶子节点的子节点数=关键字数（来源百度百科）（根据各种资料 这里有两种算法的实现方式，另一种为非叶节点的关键字数=子节点数-1（来源维基百科)，虽然他们数据排列结构不一样，但其原理还是一样的Mysql 的B+树是用第一种方式实现）; 特点： B+树的层级更少：相较于B树B+每个非叶子节点存储的关键字数更多，树的层级更少所以查询数据更快； B+树查询速度更稳定：B+所有关键字数据地址都存在叶子节点上，所以每次查找的次数都相同所以查询速度要比B树更稳定; B+树天然具备排序功能：B+树所有的叶子节点数据构成了一个有序链表，在查询大小区间的数据时候更方便，数据紧密性很高，缓存的命中率也会比B树高。 B+树全节点遍历更快：B+树遍历整棵树只需要遍历所有的叶子节点即可，，而不需要像B树一样需要对每一层进行遍历，这有利于数据库做全表扫描。 B树相对于B+树的优点是，如果经常访问的数据离根节点很近，而B树的非叶子节点本身存有关键字其数据的地址，所以这种数据检索的时候会要比B+树快。 7 堆了解完二叉树，再来理解堆就不是什么难事了。堆通常是一个可以被看做一棵树的数组对象。堆的具体实现一般不通过指针域，而是通过构建一个一维数组与二叉树的父子结点进行对应，因此堆总是一颗完全二叉树。 对于任意一个父节点的序号 n 来说（这里 n 从 0 算），它的子节点的序号一定是 2n+1，2n+2，因此可以直接用数组来表示一个堆。 不仅如此，堆还有一个性质：堆中某个节点的值总是不大于或不小于其父节点的值。将根节点最大的堆叫做最大堆或大根堆，根节点最小的堆叫做最小堆或小根堆。 堆常用来实现优先队列，在面试中经常考的问题都是与排序有关，比如堆排序、topK 问题等。由于堆的根节点是序列中最大或者最小值，因而可以在建堆以及重建堆的过程中，筛选出数据序列中的极值，从而达到排序或者挑选 topK 值的目的。 8 散列表散列表也叫哈希表，是一种通过键值对直接访问数据的机构。在初中，我们就学过一种能够将一个 x 值通过一个函数获得对应的一个 y 值的操作，叫做映射。散列表的实现原理正是映射的原理，通过设定的一个关键字和一个映射函数，就可以直接获得访问数据的地址，实现 O(1) 的数据访问效率。在映射的过程中，事先设定的函数就是一个映射表，也可以称作散列函数或者哈希函数。 散列表的实现最关键的就是散列函数的定义和选择。一般常用的有以下几种散列函数： 直接寻址法：取关键字或关键字的某个线性函数值为散列地址。 数字分析法：通过对数据的分析，发现数据中冲突较少的部分，并构造散列地址。例如同学们的学号，通常同一届学生的学号，其中前面的部分差别不太大，所以用后面的部分来构造散列地址。 平方取中**法**：当无法确定关键字里哪几位的分布相对比较均匀时，可以先求出关键字的平方值，然后按需要取平方值的中间几位作为散列地址。这是因为：计算平方之后的中间几位和关键字中的每一位都相关，所以不同的关键字会以较高的概率产生不同的散列地址。 取随机数法：使用一个随机函数，取关键字的随机值作为散列地址，这种方式通常用于关键字长度不同的场合。 除留取余法：取关键字被某个不大于散列表的表长 n 的数 m 除后所得的余数 p 为散列地址。这种方式也可以在用过其他方法后再使用。该函数对 m 的选择很重要，一般取素数或者直接用 n。 确定好散列函数之后，通过某个key值的确会得到一个唯一的value地址。但是却会出现一些特殊情况。即通过不同的key值可能会访问到同一个地址，这个现象称之为冲突。 冲突在发生之后，当在对不同的key值进行操作时会使得造成相同地址的数据发生覆盖或者丢失，是非常危险的。所以在设计散列表往往还需要采用冲突解决的办法。 常用的冲突处理方式有很多，常用的包括以下几种： 开放地址法（也叫开放寻址法）：实际上就是当需要存储值时，对 Key 哈希之后，发现这个地址已经有值了，这时该怎么办？不能放在这个地址，不然之前的映射会被覆盖。这时对计算出来的地址进行一个探测再哈希，比如往后移动一个地址，如果没人占用，就用这个地址。如果超过最大长度，则可以对总长度取余。这里移动的地址是产生冲突时的增列序量。 再哈希法：在产生冲突之后，使用关键字的其他部分继续计算地址，如果还是有冲突，则继续使用其他部分再计算地址。这种方式的缺点是时间增加了。 链地址法：链地址法其实就是对 Key 通过哈希之后落在同一个地址上的值，做一个链表。其实在很多高级语言的实现当中，也是使用这种方式处理冲突的。 公共溢出区：这种方式是建立一个公共溢出区，当地址存在冲突时，把新的地址放在公共溢出区里。 目前比较常用的冲突解决方法是链地址法，一般可以通过数组和链表的结合达到冲突数据缓存的目的。 左侧数组的每个成员包括一个指针，指向一个链表的头。每发生一个冲突的数据，就将该数据作为链表的节点链接到链表尾部。这样一来，就可以保证冲突的数据能够区分并顺利访问。 考虑到链表过长造成的问题，还可以使用红黑树替换链表进行冲突数据的处理操作，来提高散列表的查询稳定性。 9 图图相较于上文的几个结构可能接触的不多，但是在实际的应用场景中却经常出现。比方说交通中的线路图，常见的思维导图都可以看作是图的具体表现形式。 图结构一般包括顶点和边，顶点通常用圆圈来表示，边就是这些圆圈之间的连线。边还可以根据顶点之间的关系设置不同的权重，默认权重相同皆为 1。此外根据边的方向性，还可将图分为有向图和无向图。 图结构用抽象的图线来表示十分简单，顶点和边之间的关系非常清晰明了。但是在具体的代码实现中，为了将各个顶点和边的关系存储下来，却不是一件易事。 邻接矩阵目前常用的图存储方式为邻接矩阵，通过所有顶点的二维矩阵来存储两个顶点之间是否相连，或者存储两顶点间的边权重。 无向图的邻接矩阵是一个对称矩阵，是因为边不具有方向性，若能从此顶点能够到达彼顶点，那么彼顶点自然也能够达到此顶点。此外，由于顶点本身与本身相连没有意义，所以在邻接矩阵中对角线上皆为 0。 有向图由于边具有方向性，因此彼此顶点之间并不能相互达到，所以其邻接矩阵的对称性不再。 用邻接矩阵可以直接从二维关系中获得任意两个顶点的关系，可直接判断是否相连。但是在对矩阵进行存储时，却需要完整的一个二维数组。若图中顶点数过多，会导致二维数组的大小剧增，从而占用大量的内存空间。 而根据实际情况可以分析得，图中的顶点并不是任意两个顶点间都会相连，不是都需要对其边上权重进行存储。那么存储的邻接矩阵实际上会存在大量的 0。虽然可以通过稀疏表示等方式对稀疏性高的矩阵进行关键信息的存储，但是却增加了图存储的复杂性。 因此，为了解决上述问题，一种可以只存储相连顶点关系的邻接表应运而生。 邻接表在邻接表中，图的每一个顶点都是一个链表的头节点，其后连接着该顶点能够直接达到的相邻顶点。相较于无向图，有向图的情况更为复杂，因此这里采用有向图进行实例分析。 在邻接表中，每一个顶点都对应着一条链表，链表中存储的是顶点能够达到的相邻顶点。存储的顺序可以按照顶点的编号顺序进行。比如上图中对于顶点 B 来说，其通过有向边可以到达顶点 A 和顶点 E，那么其对应的邻接表中的顺序即 B-&gt;A-&gt;E，其它顶点亦如此。 通过邻接表可以获得从某个顶点出发能够到达的顶点，从而省去了对不相连顶点的存储空间。然而，这还不够。对于有向图而言，图中有效信息除了从顶点 “指出去” 的信息，还包括从别的顶点 “指进来” 的信息。这里的 “指出去” 和“指进来”可以用出度和入度来表示。 入度：有向图的某个顶点作为终点的次数和。 出度：有向图的某个顶点作为起点的次数和。 由此看出，在对有向图进行表示时，邻接表只能求出图的出度，而无法求出入度。这个问题很好解决，那就是增加一个表用来存储能够到达某个顶点的相邻顶点。这个表称作逆邻接表。 逆邻接表逆邻接表与邻接表结构类似，只不过图的顶点链接着能够到达该顶点的相邻顶点。也就是说，邻接表时顺着图中的箭头寻找相邻顶点，而逆邻接表时逆着图中的箭头寻找相邻顶点。 邻接表和逆邻接表的共同使用下，就能够把一个完整的有向图结构进行表示。可以发现，邻接表和逆邻接表实际上有一部分数据时重合的，因此可以将两个表合二为一，从而得到了所谓的十字链表。 十字链表十字链表似乎很简单，只需要通过相同的顶点分别链向以该顶点为终点和起点的相邻顶点即可。 但这并不是最优的表示方式。虽然这样的方式共用了中间的顶点存储空间，但是邻接表和逆邻接表的链表节点中重复出现的顶点并没有得到重复利用，反而是进行了再次存储。因此，上图的表示方式还可以进行进一步优化。 十字链表优化后，可通过扩展的顶点结构和边结构来进行正逆邻接表的存储：（下面的弧头可看作是边的箭头那端，弧尾可看作是边的圆点那端） data：用于存储该顶点中的数据； firstin 指针：用于连接以当前顶点为弧头的其他顶点构成的链表，即从别的顶点指进来的顶点； firstout 指针：用于连接以当前顶点为弧尾的其他顶点构成的链表，即从该顶点指出去的顶点； 边结构通过存储两个顶点来确定一条边，同时通过分别代表这两个顶点的指针来与相邻顶点进行链接： tailvex：用于存储作为弧尾的顶点的编号； headvex：用于存储作为弧头的顶点的编号； headlink 指针：用于链接下一个存储作为弧头的顶点的节点； taillink 指针：用于链接下一个存储作为弧尾的顶点的节点； 以上图为例子，对于顶点 A 而言，其作为起点能够到达顶点 E。因此在邻接表中顶点 A 要通过边AE（即边 04）指向顶点 E，顶点 A 的firstout指针需要指向边 04 的tailvex。同时，从 B 出发能够到达 A，所以在逆邻接表中顶点 A 要通过边AB（即边 10）指向 B，顶点 A 的firstin指针需要指向边 10 的弧头，即headlink指针。依次类推。 十字链表采用了一种看起来比较繁乱的方式对边的方向性进行了表示，能够在尽可能降低存储空间的情况下增加指针保留顶点之间的方向性。具体的操作可能一时间不好弄懂，建议多看几次上图，弄清指针指向的意义，明白正向和逆向邻接表的表示。 10 总结数据结构博大精深，没有高等数学的讳莫如深，也没有量子力学的玄乎其神，但是其在计算机科学的各个领域都具有强大的力量。本文试图采用图解的方式对九种数据结构进行理论上的介绍，但是其实这都是不够的。 即便是简单的数组、栈、队列等结构，在实际使用以及底层实现上都会有许多优化设计以及使用技巧，这意味着还需要真正把它们灵活的用起来，才能够算是真正意义上的熟悉和精通。但是本文可以作为常见数据结构的一个总结，当你对某些结构有些淡忘的时候，不妨重新回来看看。","categories":[],"tags":[]},{"title":"二叉树的四种遍历方式","slug":"二叉树的四种遍历方式","date":"2020-07-10T09:07:59.381Z","updated":"2020-07-09T08:57:53.853Z","comments":true,"path":"2020/07/10/二叉树的四种遍历方式/","link":"","permalink":"https://topone233.github.io/2020/07/10/%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E5%9B%9B%E7%A7%8D%E9%81%8D%E5%8E%86%E6%96%B9%E5%BC%8F/","excerpt":"","text":"原文地址 www.cnblogs.com 二叉树的四种遍历方式： 二叉树的遍历（traversing binary tree）是指从根结点出发，按照某种次序依次访问二叉树中所有的结点，使得每个结点被访问依次且仅被访问一次。四种遍历方式分别为：先序遍历、中序遍历、后序遍历、层序遍历。 树的相关术语： 节点的度：一个节点含有的子树的个数称为该节点的度； 叶节点：度为0的节点； 树的度：一棵树中，最大的节点的度； 森林：由m（m&gt;=0）棵互不相交的树的集合 树的符号表现法：（1（2（4（5，6）），3） 解读：祖先1的子节点2（子节点4（叶节点5，6）），3。同层子树间用逗号隔开。 遍历之前，我们首先介绍一下，如何创建一个二叉树，在这里我们用的是先建左树在建右树的方法， 首先要声明结点 TreeNode 类，代码如下： 12345678910public class TreeNode &#123; public int data; public TreeNode leftChild; public TreeNode rightChild; public TreeNode(int data)&#123; this.data &#x3D; data; &#125;&#125; 再来创建一颗二叉树： 123456789101112131415161718&#x2F;** * 构建二叉树 * @param list 输入序列 * @return *&#x2F; public static TreeNode createBinaryTree(LinkedList&lt;Integer&gt; list)&#123; TreeNode node &#x3D; null; if(list &#x3D;&#x3D; null || list.isEmpty())&#123; return null; &#125; Integer data &#x3D; list.removeFirst(); if(data!&#x3D;null)&#123; node &#x3D; new TreeNode(data); node.leftChild &#x3D; createBinaryTree(list); node.rightChild &#x3D; createBinaryTree(list); &#125; return node; &#125; 接下来我们按照上面列的顺序一一讲解， 首先来看先序遍历，所谓的先序遍历就是先访问根节点，在访问左节点，最后访问右节点， 如上图所示，前序遍历结果为：ABDFECGHI 实现代码如下： 123456789101112&#x2F;** * 二叉树前序遍历 根-&gt; 左-&gt; 右 * @param node 二叉树节点 *&#x2F; public static void preOrderTraveral(TreeNode node)&#123; if(node &#x3D;&#x3D; null)&#123; return; &#125; System.out.print(node.data+&quot; &quot;); preOrderTraveral(node.leftChild); preOrderTraveral(node.rightChild); &#125; 再者就是中序遍历，所谓的中序遍历就是先访问左节点，再访问根节点，最后访问右节点， 如上图所示，前序遍历结果为：DBEFAGHCI（G没有左子树，所以直接访问G，而不是访问H） 实现代码如下： 123456789101112&#x2F;** * 二叉树中序遍历 左-&gt; 根-&gt; 右 * @param node 二叉树节点 *&#x2F; public static void inOrderTraveral(TreeNode node)&#123; if(node &#x3D;&#x3D; null)&#123; return; &#125; inOrderTraveral(node.leftChild); System.out.print(node.data+&quot; &quot;); inOrderTraveral(node.rightChild); &#125; 最后就是中序遍历，所谓的中序遍历就是先访问左节点，再访问右节点，最后访问根节点。 如上图所示，前序遍历结果为：DEFBHGICA 实现代码如下： 123456789101112&#x2F;** * 二叉树后序遍历 左-&gt; 右-&gt; 根 * @param node 二叉树节点 *&#x2F; public static void postOrderTraveral(TreeNode node)&#123; if(node &#x3D;&#x3D; null)&#123; return; &#125; postOrderTraveral(node.leftChild); postOrderTraveral(node.rightChild); System.out.print(node.data+&quot; &quot;); &#125; 讲完上面三种非递归的方法，下面再给大家讲讲非递归是如何实现前中后序遍历的 还是一样，先看非递归前序遍历 首先申请一个新的栈，记为 stack； 声明一个结点 treeNode，让其指向 node 结点； 如果 treeNode 的不为空，将 treeNode 的值打印，并将 treeNode 入栈，然后让 treeNode 指向 treeNode 的右结点， 重复步骤 3，直到 treenode 为空； 然后出栈，让 treeNode 指向 treeNode 的右孩子 重复步骤 3，直到 stack 为空. 实现代码如下： 1234567891011121314151617public static void preOrderTraveralWithStack(TreeNode node)&#123; Stack&lt;TreeNode&gt; stack &#x3D; new Stack&lt;TreeNode&gt;(); TreeNode treeNode &#x3D; node; while(treeNode!&#x3D;null || !stack.isEmpty())&#123; &#x2F;&#x2F;迭代访问节点的左孩子，并入栈 while(treeNode !&#x3D; null)&#123; System.out.print(treeNode.data+&quot; &quot;); stack.push(treeNode); treeNode &#x3D; treeNode.leftChild; &#125; &#x2F;&#x2F;如果节点没有左孩子，则弹出栈顶节点，访问节点右孩子 if(!stack.isEmpty())&#123; treeNode &#x3D; stack.pop(); treeNode &#x3D; treeNode.rightChild; &#125; &#125; &#125; 中序遍历非递归，在此不过多叙述具体步骤了， 具体过程： 申请一个新栈，记为 stack，申请一个变量 cur，初始时令 treeNode 为头节点； 先把 treeNode 节点压入栈中，对以 treeNode 节点为头的整棵子树来说，依次把整棵树的左子树压入栈中，即不断令 treeNode=treeNode.leftChild，然后重复步骤 2； 不断重复步骤 2，直到发现 cur 为空，此时从 stack 中弹出一个节点记为 treeNode，打印 node 的值，并让 treeNode= treeNode.right，然后继续重复步骤 2； 当 stack 为空并且 cur 为空时结束。 12345678910111213141516public static void inOrderTraveralWithStack(TreeNode node)&#123; Stack&lt;TreeNode&gt; stack &#x3D; new Stack&lt;TreeNode&gt;(); TreeNode treeNode &#x3D; node; while(treeNode!&#x3D;null || !stack.isEmpty())&#123; while(treeNode !&#x3D; null)&#123; stack.push(treeNode); treeNode &#x3D; treeNode.leftChild; &#125; if(!stack.isEmpty())&#123; treeNode &#x3D; stack.pop(); System.out.print(treeNode.data+&quot; &quot;); treeNode &#x3D; treeNode.rightChild; &#125; &#125; &#125; 后序遍历非递归实现，后序遍历这里较前两者实现复杂一点，我们需要一个标记为来记忆我们此时节点上一个节点，具体看代码注释 12345678910111213141516171819202122232425262728293031public static void postOrderTraveralWithStack(TreeNode node)&#123; Stack&lt;TreeNode&gt; stack &#x3D; new Stack&lt;TreeNode&gt;(); TreeNode treeNode &#x3D; node; TreeNode lastVisit &#x3D; null; &#x2F;&#x2F;标记每次遍历最后一次访问的节点 while(treeNode!&#x3D;null || !stack.isEmpty())&#123;&#x2F;&#x2F;节点不为空，结点入栈，并且指向下一个左孩子 while(treeNode!&#x3D;null)&#123; stack.push(treeNode); treeNode &#x3D; treeNode.leftChild; &#125; &#x2F;&#x2F;栈不为空 if(!stack.isEmpty())&#123; &#x2F;&#x2F;出栈 treeNode &#x3D; stack.pop(); &#x2F;** * 这块就是判断treeNode是否有右孩子， * 如果没有输出treeNode.data，让lastVisit指向treeNode，并让treeNode为空 * 如果有右孩子，将当前节点继续入栈，treeNode指向它的右孩子,继续重复循环 *&#x2F; if(treeNode.rightChild &#x3D;&#x3D; null || treeNode.rightChild &#x3D;&#x3D; lastVisit) &#123; System.out.print(treeNode.data + &quot; &quot;); lastVisit &#x3D; treeNode; treeNode &#x3D; null; &#125;else&#123; stack.push(treeNode); treeNode &#x3D; treeNode.rightChild; &#125; &#125; &#125; &#125; 最后再介绍一下层序遍历 具体步骤如下： 首先申请一个新的队列，记为 queue； 将头结点 head 压入 queue 中； 每次从 queue 中出队，记为 node，然后打印 node 值，如果 node 左孩子不为空，则将左孩子入队；如果 node 的右孩子不为空，则将右孩子入队； 重复步骤 3，直到 queue 为空。 实现代码如下： 12345678910public static void levelOrder(TreeNode root)&#123; LinkedList&lt;TreeNode&gt; queue &#x3D; new LinkedList&lt;&gt;(); queue.add(root); while(!queue.isEmpty())&#123; root &#x3D; queue.pop(); System.out.print(root.data+&quot; &quot;); if(root.leftChild!&#x3D;null) queue.add(root.leftChild); if(root.rightChild!&#x3D;null) queue.add(root.rightChild); &#125; &#125;","categories":[],"tags":[]}],"categories":[],"tags":[]}