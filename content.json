{"meta":{"title":"QSX1C","subtitle":" ","description":"","author":"QSX1C","url":"https://topone233.github.io","root":"/"},"pages":[{"title":"about","date":"2020-07-12T08:05:04.000Z","updated":"2020-07-12T08:05:18.584Z","comments":true,"path":"about/index.html","permalink":"https://topone233.github.io/about/","excerpt":"","text":""},{"title":"categories","date":"2020-07-12T08:02:56.000Z","updated":"2020-07-12T08:04:10.280Z","comments":true,"path":"categories/index.html","permalink":"https://topone233.github.io/categories/","excerpt":"","text":""},{"title":"tags","date":"2020-07-12T08:04:26.000Z","updated":"2020-07-12T08:04:53.027Z","comments":true,"path":"tags/index.html","permalink":"https://topone233.github.io/tags/","excerpt":"","text":""},{"title":"contact","date":"2020-07-12T08:05:31.000Z","updated":"2020-07-12T08:05:48.424Z","comments":true,"path":"contact/index.html","permalink":"https://topone233.github.io/contact/","excerpt":"","text":""}],"posts":[{"title":"SSL协议","slug":"SSL协议","date":"2020-09-11T08:05:13.045Z","updated":"2020-09-11T08:05:13.045Z","comments":true,"path":"2020/09/11/SSL协议/","link":"","permalink":"https://topone233.github.io/2020/09/11/SSL%E5%8D%8F%E8%AE%AE/","excerpt":"","text":"1.基本概念安全套接层（secure sockets layer，SSL）协议是Netscape公司1994年提出的用于Web应用的传输层安全协议。 SSL协议使用非对称加密体制和数字证书技术，保护信息传输的秘密性和完整性。 2.特点2.1 主要应用于HTTP协议SSL协议尽管可以用于HTTP、FTP、TELNET等协议，但是目前主要应用于HTTP协议，为基于Web服务的各种网络应用中客户和服务器之间的用户身份认证与安全数据传输提供服务。 2.2 加密的安全通道SSL协议处于应用层和传输层之间，在TCP协议之上建立一个加密的安全通道，为TCP协议之间传输的数据提供安全保障。 2.3 加密与解密当HTTP协议使用SSL协议时，HTTP的请求、应答报文格式、处理方法不变。不同之处是：应用进程所产生的报文将通过SSL协议加密之后，再通过TCP连接传送出去。接收端TCP协议将加密的报文传送给SSL协议解密之后，再传送到应用层HTTP协议 2.4 不同的使用形式当Web系统采用SSL协议时，Web服务器的默认端口号从80 变换成 443；Web客户端使用HTTPS 取代HTTP。 2.5 握手协议、记录协议SSL协议包含两个协议：SSL握手协议（SSL Handshake Protocol）与 SSL记录协议（SSL Record Protocol）。SSL握手协议实现双方加密算法的协商与密钥传递，SSL记录协议定义SSL数据传输格式，实现对数据的加密与解密操作。","categories":[{"name":"网络协议","slug":"网络协议","permalink":"https://topone233.github.io/categories/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/"}],"tags":[{"name":"网络协议","slug":"网络协议","permalink":"https://topone233.github.io/tags/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/"},{"name":"SSL","slug":"ssl","permalink":"https://topone233.github.io/tags/ssl/"},{"name":"安全","slug":"安全","permalink":"https://topone233.github.io/tags/%E5%AE%89%E5%85%A8/"}]},{"title":"TCP协议","slug":"TCP协议","date":"2020-09-10T14:31:50.471Z","updated":"2020-09-15T08:12:40.779Z","comments":true,"path":"2020/09/10/TCP协议/","link":"","permalink":"https://topone233.github.io/2020/09/10/TCP%E5%8D%8F%E8%AE%AE/","excerpt":"","text":"1.特点1.1 支持面向连接的传输服务如果将UDP协议提供的服务比作一封邮件的话，那么TCP协议所能提供的服务相当于语音聊天，必须要通信双方建立连接。 面向连接对提高系统数据传输的可靠性是很重要的，使用TCP传输数据之前，必须在源进程端口与目的进程端口之间建立一条TCP传输连接。用双方端口号来标识。TCP建立在不可靠的网络层 IP 协议上，IP 协议不能提供任何可靠性保障机制，因此TCP 协议的可靠性需要自己解决。 1.2 支持字节流的传输流（stream）相当于是一个管道（水管），从一端放入什么，另一端可以照原样取出。描述了一个不出现 ：丢失、重复、乱序的数据传输过程。TCP 协议将数据看成是一连串的、无结构的字节流。 如果用户是通过键盘输入数据，应用进程将字符逐个提交给发送端。如果数据是从文件得到，那么数据可能是逐行或逐块交付发送端。 为了支持字节流传输，发送端和接收端都需要使用缓存。发送端将几个写操作组合成一个报文的，提交给 IP 协议，由 IP 协议封装成 IP 分组之后传输到接收端， 1.3 支持全双工通信由于通信双方都设置有发送和接收的缓冲区，TCP 协议允许通信双方在任何时候都可以发送数据。 1.4 支持同时建立多个并发的TCP连接TCP 协议需要支持同时建立多个连接，这个特点在服务端表现的更为突出。一个服务器必须同时处理多个客户端的访问。例如，一个Web服务器的套接字为“ 141.8.22.51:80 ”，同时有三个客户端需要访问这个服务器，它们的套接字分别为“ 202.1.12.5:30001 “ “ 242.1.12.5:300022 “ “ 212.1.12.5:300023 “则服务器端需要同时建立三个 TCP 连接。 也支持一个客户端与多个服务器同时建立多个 TCP 连接。 1.5 支持可靠的传输服务TCP 协议使用确认机制检查数据是否安全和完整，并且提供拥塞控制功能。对发送和接收的数据进行跟踪、确认和重传。 但是 TCP 协议是建立在不可靠的网络层 IP 协议之上，一旦 IP 协议及以下层出现传输错误，TCP 协议只能不断进行重传，可靠性会受到底层限制。 2.报文格式窗口 窗口字段长度为16位，表示以字节（B）为单位的窗口大小。 由于接收端的接收缓冲区是受到限制的，因此需要设置一个窗口字段，表示下一次传输接收端还有多大的接收容量。窗口字段值是准备接收下一个 TCP报文段的接收端，通知即将发送报文段的发送端，下一次最多可以发送报文段的字节数。 发送端将根据接收端通知的窗口值调整自己的发送窗口值大小。 窗口字段值是动态变化的。 主机A 发给主机 B的TCP报头中确认号是 502，窗口值 1000。表示：下一次主机B要向主机A发送的 TCP，字段第一字节号应该是 502，字段最大长度是 1000，最后一个字节号最大是 1501。 序号 序号字段长度位32位 TCP 是面向字节流的，它需要为发送字节流中的每个字节都按顺序编号。 TCP连接建立时，每方都需要使用随机数产生器，生成一个初始序号。 不能为0。避免因TCP连接非正常断开而可能引起的混乱。如果在连接突然中断时，可能有一个或两个进程同时等待对方的确认应答，而这个时候有一个新连接的序号也是从0开始，那么接收进程就有可能认为是对方重传的报文，这样就可能造成连接过程的错误。 ACK（确认位） 在TCP连接建立后发送的所有报文段的ACK位都要置 1。 SYN（同步位） 在连接建立时用来同步序号。例如 SYN=1，ACK=0时，表示这是一个连接建立请求报文，同意建立连接的响应报文：SYN=1，ACK=1。 3. 连接建立与释放3.1 三次握手3.1.1 最初，客户端TCP 进程是处于 CLOSE 状态。准备发起TCP连接时，进入 SYN-SEND 状态，向处于LISTEN 状态的服务器端 TCP 进程发送第一个控制位 SYN = 1 的”连接建立请求报文“，不携带数据字段，但需要给报文一个序号 seq=x。 SYN=1 seq=x 3.1.2 服务器端接收到” 连接建立请求报文“之后，如果同意建立连接，则向客户端发送第二个控制位 SYN=1， ACK=1 的 ” 连接建立请求确认报文 “。确认号 ack = x + 1，表示是对第一个” 连接建立请求报文“（序号 seq=x）的确认。同样不携带任何数据字段，但是需要给报文一个序号 seq=y。这时服务器进入 SYN-RCVD（准备接收）状态。 SYN=1 ACK=1 seq=y ack=x+1 3.1.3 客户端发送第三个控制位 ACK=1 ” 连接建立请求确认报文 “。由于该报文是对” 连接建立请求确认报文”（seq=y）的确认，因此确认序号 ack=y+1。同样不携带数据字段，但需要给一个序号，仍为 x+1 。ACK=1 seq=x+1 ack =y+1。这时客户端进入 ESTABLISHED（已建立连接）状态。服务器端在接收到ACK报文之后也进入 ESTABLISHED （已建立连接）状态。 三次握手完成。TCP连接建立。 3.2 报文传输TCP传输连接建立之后，双方可以使用这个连接，进行全双工的字节流传输。 为了保证TCP工作正常、有序的进行，TCP在服务器端设置了保持计时器（keep timer），用来防止TCP连接处于长时间空闲。当服务器端收到客户端的报文时，就保持计时器复位。如果没有收到客户端的信息，他就发送探测报文。如果发送10个探测报文（每个相隔 75s）还没有响应，就假设客户端出现故障，终止该连接。 3.3 四次挥手3.3.1 客户端主动提出释放TCP连接，进入 FIN-WAIT-1（释放等待-1）状态。向服务器发送第一个控制位FIN=1，的 ” 连接释放请求报文 ”，提出连接释放请求，停止发送数据。不携带任何数据字段。但是需要给报文一个序号。 FIN=1，seq=u 。u等于客户端发送的最后一个字节的序号加1。 3.3.2 服务器端收到之后，需要向客户发送 “ 连接释放请求确认报文 ”，表示对报文的确认， ack=u+1。这个 “ 连接释放请求报文 ” 的序号 v 等于服务器发送的最后一个字节序号加1。 ACK=1，seq=v，ack=u+1。 TCP服务器进程向高层应用进程通知客户请求释放TCP连接，客户到服务器的TCP连接断开，但是服务器到客户的TCP连接还没有断开，如果服务器还有数据报文需要发送时，它还可以继续发送直至完毕。这种状态称为半关闭（helf-close）状态。这个状态需要持续一段时间。 客户在接收到服务器发送的ACK报文之后进入 FIN-WAIT-2状态；服务器进入CLOSE-WAIT状态。 3.3.3 服务器的高层应用程序已经没有数据需要发送时，它会通知TCP可以释放连接，这时服务器向客户发送 “ 连接释放请求报文 ”。报文的序号（假定为w），取决于在半关闭状态时，服务器端是否发送过数据报文。服务器端经过 LAST-ACK状态之后转回到LISTEN（收听）状态。 ACK=1，FIN=1，seq=w，ack=u+1。 3.3.4 客户接收到FIN报文之后，向服务器发送 “ 连接释放请求确认报文 ”，ACK=1，seq=u+1，ack=w+1 3.4 时间等待计时器为了保证TCP连接释放过程正常的进行，TCP设置了时间等待计时器（TIME-WAIT Timer）。当TCP关闭一个连接时，它并不认为这个连接马上就真正的关闭。这时，客户端进入TIME-WAIT状态，需要再等待两个最长报文寿命（maximum segment lifetime，MSL）时间之后，才真正进入CLOSE（关闭）状态。 四次挥手之后，确认双方已经同意释放连接，客户端仍需要采取延迟2MSL时间，确保服务器在最后阶段发送给客户端的数据，以及客户端发送给服务器的最后一个ACK报文都能正确的被接收，防止因个别报文传输错误导致连接释放失败。 4.滑动窗口与确认、重传机制4.1 滑动窗口TCP协议使用以字节为单位的滑动窗口协议（Sliding-Windows Protocol），来控制字节流的发送、接收、确认、重传过程。 TCP使用两个缓存和一个窗口来控制字节流的传输过程。 发送端的TCP有一个缓存，用来存储应用进程准备发送的数据。对这个缓存设置一个发送窗口。 接收端也有一个缓存，将正确接收到字节流写入缓存，等待应用进程读取。也有一个接收窗口。 只要发送窗口值不为0就可以发送报文段。发送窗口的大小取决于接收窗口的大小。发送端每一次能够连续发送字节数取决于发送窗口的大小。不能超过接收窗口值，发送端可以根据自身的需要来决定。 接收窗口值等于接收缓存还可以继续接收的字节流的大小。由接收端根据接收缓存剩余空间的大小，以及应用进程读取数据的速度决定。 接收端通过TCP报头通知发送端，已经正确接收的字节号，以及发送端还能够连续发送的字节数。 虽然TCP协议是面向字节流的，但是它不可能每次传送一个字节，就对这个字节进行确认。它是将字节流分成段，一个段的多个字节打包成一个TCP报文段一起传送、一起确认。TCP协议通过报头的“序号”来标识发送的字节，用“确认号”表示哪些字节已经被正确的接收。 4.1.2 字节流传输状态为了达到利用滑动窗口协议控制差错的目的，TCP协议引入了“字节流传输状态”的概念。为了对正确传输的字节流进行确认，必须对字节流的传输状态进行跟踪： 假设发送的第一个字节的序号是1。 第一类：已经发送，且已得到确认的字节。假设序号为19之前的字节已经被接收端正确的接收，并且发送端发送了确认信息。1-19的字节属于第一类。 第二类：已经发送，但未收到确认的字节。 第三类：尚未发送，但是接收端表示接收缓冲区已经准备好，如果发送端准备好就可以立即发送这些字节。 第四类：尚未发送，且接收端也未做好接收准备的字节。 4.1.3 发送窗口与可用窗口发送端每一次能够连续发送字节数取决于发送窗口的大小。 发送窗口的长度等于第二类与第三类字节数之和。 可用窗口长度等于第三类字节数。如果没有任何问题，发送端可以立即发送可用窗口的字节。 接收端确认发送窗口的字节，为保持发送窗口值不变，需要将窗口向左滑动（例如从序号1 移动到 20）。 4.2 容错控制TCP协议通过滑动窗口机制来跟踪和记录发送字节的状态，实现差错控制功能。 TCP协议的设计思想是让应用进程将数据作为一个字节流传送，而不是限制应用层数据的长度。应用进程不需要考虑发送数据的长度，由TCP协议来负责将这些字节分段打包。 发送端利用已建立的TCP连接，将字节流传送到接收端的应用进程，并且是顺序的，没有差错、丢失、重复的。 TCP协议发送的报文是交给 IP 协议传输的，IP协议只能提供尽力而为的服务，IP分组在传输过程中出错是不可避免的，TCP协议必须提供差错控制、确认、重传功能，以保证接收的字节流是正确的。 4.3 选择重传策略上面我们没有考虑到报文段丢失的情况，但是在Internet中，报文段丢失是不可避免的，会造成接收的字节流序号不连续的现象。 接收字节流序号不连续的处理方法有两种：拉回、选择重传 4.3.1 拉回在丢失第二个报文段时，不管之后的报文段接收是否正确，都要求从第二个报文段开始，重传后面的所有的报文段。显然，拉回方式发效率是很低的。 4.3.2 选择重传选择重传（selective ACK，SACK），如果收到字节流序号不连续时，如果这些字节的序号都在接收窗口之内，则首先完成接收窗口内字节的接收，然后将丢失的字节序号通知发送端，发送端只需要重传丢失的报文段，而不需要重传已经接收的报文段。 4.4 重传计时器TCP使用重传计时器（retransmission timer）来控制报文确认与等待重传的时间。当发送端发送一个报文时，首先将它的一个报文的副本放入重传队列，同时启动一个重传计时器。重传计时器设定一个值，例如400ms，然后开始倒计时。时间结束前收到确认，表示传输成功，否则说明传输失败，准备重传该报文。 4.4.1 影响超时重传的元素设定重传计时器的时间值时很重要的。如果设定值过低，可能出现已被接收端正确接收的报文被重传，造成接收报文重复的现象。如果设定值过高，造成一个报文已经丢失，而发送端长时间等待，造成效率降低的现象。 如果一个主机同时与其他两个主机建立两条TCP连接，那么它就需要分别为每个连接启动一个重传计时器。如果一个用于本地局域网中传输文本文件，另一个用于Internet远程访问Web服务，那么两个TCP报文的往返时间相差很大。因此，需要对不同的TCP连接设定不同的重传计时器的时间。 由于Internet在不同时间段的用户数量变化很大，流量与传输延迟变化也很大，报文传输延迟也不会相同。 正是由于这些原因，为TCP连接确定合适的重传定时器数值是很可能的。TCP不会采用简单的静态方法，必须采用动态的自适应的方法。根据端对端报文往返时间的连续测量，不断调整和设定重传定时器的超时重传时间。 4.5超时重传时间的选择略。。。（写不动了，下次再补吧） 5.滑动窗口与流量控制、拥塞控制5.1 TCP窗口与流量控制研究流量控制（flow control）算法的目的是控制发送端发送速率，使之不超过接收端的接收速率，防止由于接收端来不及接收送达的字节流，而出现报文段丢失的现象。滑动窗口协议可以利用TCP报头中窗口字段，方便的实现流量控制。","categories":[{"name":"网络协议","slug":"网络协议","permalink":"https://topone233.github.io/categories/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/"}],"tags":[{"name":"网络协议","slug":"网络协议","permalink":"https://topone233.github.io/tags/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/"},{"name":"TCP","slug":"tcp","permalink":"https://topone233.github.io/tags/tcp/"},{"name":"滑动窗口","slug":"滑动窗口","permalink":"https://topone233.github.io/tags/%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3/"}]},{"title":"关于 Java 中 length、length()、size() 的区别","slug":"关于 Java 中 length、length()、size() 的区别","date":"2020-09-08T08:54:24.754Z","updated":"2020-09-11T12:54:07.995Z","comments":true,"path":"2020/09/08/关于 Java 中 length、length()、size() 的区别/","link":"","permalink":"https://topone233.github.io/2020/09/08/%E5%85%B3%E4%BA%8E%20Java%20%E4%B8%AD%20length%E3%80%81length()%E3%80%81size()%20%E7%9A%84%E5%8C%BA%E5%88%AB/","excerpt":"","text":"以前总是觉得自己好像会了，但是某天忽然面对这个笔试题还是会恍惚一下，混淆和答错的几率也很大，不知道有没有其他人像我一样的。 所以今天把这个问题记一下，希望印象更深刻。 首先区分一下 length 和 length()； length 不是方法，是属性，数组的属性； public static void main(String\\[\\] args) { int\\[\\] intArray = {1,2,3}; System.out.println(&quot;这个数组的长度为：&quot; + intArray.length); }length() 是字符串 String 的一个方法； public static void main(String\\[\\] args) { String str = &quot;HelloWorld&quot;; System.out.println(&quot;这个字符串的长度为：&quot; + str.length()); }进入 length() 方法看一下实现 private final char value\\[\\]; public int length() { return value.length; }注释中的解释是 @return the length of the sequence of characters represented by this object. 即由该对象所代表的字符序列的长度，所以归根结底最后要找的还是 length 这个底层的属性； size() 方法，是 List 集合的一个方法； public static void main(String\\[\\] args) { List&lt;String&gt; list = new ArrayList&lt;String&gt;(); list.add(&quot;a&quot;); list.add(&quot;b&quot;); list.add(&quot;c&quot;); System.out.println(&quot;这个list的长度为：&quot; + list.size()); }在 List 的方法中，是没有 length() 方法的； 也看一段 ArrayList 的源码 private final E\\[\\] a; ArrayList(E\\[\\] array) { if (array==null) throw new NullPointerException(); a = array; } public int size() { return a.length; }由这段就可以看出 list 的底层实现其实就是数组，size() 方法最后要找的其实还是数组的 length 属性； 另外，除了 List，Set 和 Map 也有 size() 方法，所以准确说 size() 方法是针对集合而言。 总结： length——数组的属性； length()——String 的方法； size()——集合的方法； 谨记。","categories":[{"name":"Java","slug":"java","permalink":"https://topone233.github.io/categories/java/"}],"tags":[{"name":"Java","slug":"java","permalink":"https://topone233.github.io/tags/java/"},{"name":"集合","slug":"集合","permalink":"https://topone233.github.io/tags/%E9%9B%86%E5%90%88/"}]},{"title":"JVM 初步理解","slug":"JVM 初步理解","date":"2020-09-04T02:25:57.056Z","updated":"2020-09-15T08:07:06.203Z","comments":true,"path":"2020/09/04/JVM 初步理解/","link":"","permalink":"https://topone233.github.io/2020/09/04/JVM%20%E5%88%9D%E6%AD%A5%E7%90%86%E8%A7%A3/","excerpt":"","text":"原文地址 [www.zhihu.com\\](https://www.zhihu.com/question/20097631/answer/817071740) 如果 JAVA 开发是降龙十八掌，JVM 就是九阳神功，具备九阳神功的内力基础降龙十八掌的威力会被发挥的淋漓尽致。 ) JVM 的内存结构和类加载机制是玩转 JVM 的入口，如果弄通了接下来的路该怎么走你自然就知道了 下面我就从这两个方面来深入解析一下 JVM JVM 内存结构 jvm 内存分为五大块： ) 标灰的是线程公有的内存区域，没有标灰的是线程私有。 一：程序计数器：程序计数器是用来指示当前线程要执行哪条指令，并且在执行完该条指令后让程序计数器指向下一条指令，直到将程序执行完毕。指令需要靠 cpu 来执行，在多线程中，多个线程是通过轮流切换分配 cpu 的时间片而执行的，在切换时需要记录当前执行到了哪条指令以便将来继续执行，每一个线程都需要有自己的程序计数器，所以程序计数器是线程私有的内存。 二：虚拟机栈：通常我们把 jvm 的内存粗略的分为堆和栈，其中的栈指的就是虚拟机栈, 虚拟机栈也是线程私有的。 虚拟机栈对应的是方法的内存区域，每个方法执行时都会创建一个栈帧，用来存储该方法的局部变量表，操作数栈，动态链接，方法返回地址： ) 1. 局部变量表：局部变量表中存储的是方法的参数和方法中定义的局部变量，在编译期间就为局部变量表分配好了内存空间。局部变量表中存储三种类型的数据： （1） 基本数据类型 （2） 引用类型：指向一个对象在内存中的地址 （3） returnAddress 类型：指向指令的地址（已经很少见了，指向异常处理的指令，现在已经由异常表代替） 2. 操作数栈：当虚拟机执行一些指令的时候会对操作数栈进行入栈或出栈的操作，比如 iadd 指令将两个数相加，会先将操作数栈中的两个数弹出来（出栈），相加后再压入栈（入栈）中。 3. 动态链接：在运行时常量池中存储了诸如类名，方法名，我们要找到目标类，执行相应的方法就需要用到动态链接，栈帧中有一个指向运行时常量池的引用，通过这个引用可以找到相应的类名和方法名，但是光知道名称是没法执行方法的，需要通过名称找到相应的类和方法在内存中的地址，这个过程就是动态链接。 4. 方法返回地址：当方法执行完以后如果有返回值，就会把这个返回值返回给该方法的调用者，方法的返回就是我们 java 中用到的 return 命令。方法返回之后调用者需要继续往下执行就需要知道要执行的地址，该地址就是方法返回地址，它被记录在了栈帧中，当然在发生异常的情况下不会有返回值，要继续执行的地址可以通过异常处理器表来确定。 虚拟机栈可能出现两种类型的异常： 1. 线程请求的栈深度大于虚拟机允许的栈深度会抛出 StackOverflowError,（虚拟机栈空间不能动态扩展的情况下） 2. 如果虚拟机栈空间可以动态扩展（目前多数的虚拟机都可以），当动态扩展无法申请到足够的空间时会抛出 OutOfMemory 异常。 三：本地方法栈：本地方法栈与虚拟机栈的作用是一样的，区别在于虚拟机栈为虚拟机执行 java 方法服务，而本地方法栈为虚拟机执行 native 方法服务，native 方法为本地方法，不是用 java 语言写的有可能是 c 或者 c++ 写的，在 jdk 中就有很多 c 的代码，就是提供给本地方法来调用的。 四: 堆：通常我们把 jvm 的内存粗略的分为堆和栈，其中的堆就是指它，它是虚拟机中占用内存最大的一块，是被所有线程共享的一块区域，它是用来存放对象实例的。是垃圾收集器管理的主要区域。 五：方法区：方法区也是被所有线程共享的一块区域，它存储的是类信息，常量，静态变量，编译后的字节码等信息。方法区中还有一块区域 “运行时常量池 “：运行时常量池中存储的是编译期生成的各种字面量和符号引用。字面量相当于 Java 里常量的概念，比如字符串，声明为 final 的常量值等，符号引用包括了：类和接口名，字段名，方法名。 类加载机制 一：java 类的加载过程 编译后的 Java 类是以字节码的形式存在的，它只有被加载到虚拟机内存中才能被使用，它是如何被加载到内存中的呢？ 下图为类加载到内存的机制： ) 1：加载： 在加载（注意和类加载是不同的概念）阶段虚拟机需要完成三件事 （1）. 通过一个类的全限定名（类名全称，带包路径的用点隔开，例如: java.lang.String）来获取其定义的二进制字节流（被编译以后的字节码文件就是二进制的）。 （2）. 将这个字节流所代表的静态存储结构（字节码文件就是其中一种）转化为方法区的运行时数据结构（能够在虚拟机中存储的结构）。 （3）. 在 Java 堆中生成一个代表这个类的 java.lang.Class 对象（用于表示这个类的信息），作为对方法区中这些数据的访问入口。 2：验证： 验证，准备，解析统称为连接，作为连接阶段的第一步，验证的主要作用是保证加载进来的二进制流中的信息是符合当前虚拟机要求的，并且不会对虚拟机的安全造成危害。主要包括： （1）文件格式验证：主要是验证二进制流是否符合 class 文件格式的规范，并且能被当前的虚拟机处理，例如：主次版本号是否在当前虚拟机处理范围之内，常量池的常量中是否有不被支持的常量类型。只有通过了这个阶段的验证后字节流才会进入内存的方法区中进行存储，从这里我们可以看出加载和验证阶段是交叉进行的，加载还未完成，文件格式验证就已经开始了。 （2）元数据验证：对字节码描述的信息进行语义分析以保证其描述的信息符合 java 语言规范的要求：例如：这个类是否有父类（所有类除了 Object 都应该有父类） （3）字节码验证：确定程序语义是合法的符合逻辑的，如将子类对象赋给父类类型是符合逻辑的，反之，将父类对象赋给子类类型则是不合法的。 （4）符号引用验证：可以对常量池中各种符号引用的信息进行匹配性校验。例如：符号引用中通过字符串描述的全限定名是否能找到对应的类。 3：准备： 准备阶段会为静态变量分配内存并设置初始值，注意：该初始值为数据类型的零值例如： Public static int num = 3; 在准备阶段会将 num 值设置为 0 而不是 3. 只有在初始化阶段才会赋值为 3. 4：解析： 解析阶段是把类中的符号引用转换为直接引用的过程： 符号引用：在编译的时候是不知道类所引用的类的具体地址，因此只能使用符号引用来代替，比如：com.Student 类引用了 com.Grade 类，编译时 Student 类并不知道 Grade 类在内存中的实际地址，只能用符号 com.Grade。 直接引用; 引用的实际内存地址。 5：初始化： 初始化阶段是类加载过程的最后一步，在这个阶段会根据程序中的赋值语句给变量赋值，当有继承关系时先初始化父类，再初始化子类。如果该类还没有被加载和连接，那么初始化之前先加加载和连接。 什么时候会进行初始化呢？ 1. 使用 new 关键字实例化对象的时候 2. 读取或设置一个类的静态字段的时候 3. 调用一个类的静态方法的时候 4. 对类进行反射调用的时候 5. 当虚拟机启动时执行一个类的 main 方法，会先初始化这个类 二：类加载器： 加载阶段中的第一步：“通过一个类的全限定名来获取其定义的二进制字节流” 是通过类加载器来完成的，类加载器分为三种： 1. 启动类加载器（BootStrap ClassLoader）, 这个类加载器负责将 jdk\\jre\\lib 下的类库加载到内存中，启动类加载器无法被应用程序直接使用。 2. 扩展类加载器（Extension ClassLoader）, 它负责加载 jdk\\jre\\lib\\ext 中的类库。开发者可以直接使用扩展类加载器。 3. 应用程序类加载器 (Application ClassLoader), 它用来加载 classpath 路径（src 路径下的文件在编译后会放到 WEB-INF/classes 路径下。默认的 classpath 是在这里）指定的类。开发者可以直接使用这个类加载器，如果如果应用程序中没有定义自己的类加载器，一般情况下这个就是程序中默认的类加载器。 我们的应用程序都是由这三种类加载器互相配合进行加载的，如果有必要还可以加入自己定义的类加载器。 三：双亲委派模型： 下图为双亲委派模型的类加载器的层次关系： ![](data:image/svg+xml;utf8,) 双亲委派模型的的工作过程是：如果一个类加载器收到了类加载的请求，它会把这个请求委派给父类加载器去完成，每一个层次的加载器都是如此，因此所有的加载请求最终都会传送到顶层的启动类加载器中。只有当父加载器反馈自己无法完成这个加载请求时（在自己的加载范围内没有搜索到该类）, 子加载器才会尝试自己去加载。例如： 1. 当应用程序类加载器加载一个类时，它会把类加载请求委派给扩展类加载器。 2. 扩展类加载器又把这个类加载请求委派给启动类加载器。 3. 启动类加载器如果加载失败，在 (jdk/jre/lib) 里没有找到这个类，会使用扩展类加载器进行加载。 4. 扩展类加载器如果加载失败，在（jdk/jre/lib/ext）里没有找到这个类，会使用应用程序类加载器来加载 5. 应用程序加载器加载失败则会报：ClassNotFoundException 异常。 使用双亲委派模型的意义： 例如类 java.lang.Object 存放在 rt.jar 中，无论哪个类加载器要加载这个类，最终都会委派启动类加载器来加载，如果没有双亲委派模型用户自己编写了一个 java.lang.Object 类，放到 ClassPath 中，系统中将会出现多个不同的 Object 类，应用程序也会变得混乱。 如果你想对 java 有更深入的理解可以看看我的这个回答，里面集合了我所有的高赞回答和文章： 如何系统地、全方面地自学 Java？​www.zhihu.com 我精心写了几个大厂面试必考知识点的文章，无论是对于完善你的技术栈还是准备面试都会大有裨益： Java 动态代理作用是什么？​www.zhihu.com 夏昊：HashMap 的底层原理​zhuanlan.zhihu.com 最后再送你两句话： 1: 学习贵在坚持，有付出就会有收获 2: 看到有帮助的回答一定记得点个赞，以后在动态随时能查看到回答，不怕找不到了 另外我给你准备了我精心编写的大厂面试技术点详解和近两百本 java 方面的电子书，送给已点赞加关注 的你： 关注公众号 『“极简 Java 学习营”』领取。 1. 近两百本 java 经典电子书： ) 2. 我精心编写的 java 面试考点详细解析 ) 陈树义​ 曾经我也对 JVM 感到很头痛，完全搞不懂应该如何入门 JVM 的学习。但经过了 5 年的学习，我对 JVM 有了更深入的理解。虽然还达不到精通源码的程度，但是对 JVM 各个知识点的理解和联系都形成了自己的体系。 对于初学者来说，首先理解为什么要学虚拟机是最重要的，关于这块内容建议阅读我的这篇文章： JVM 基础系列开篇：为什么要学虚拟机？ - 陈树义 - 博客园​www.cnblogs.com 当你明白为什么要学虚拟机之后，你需要明白：到底什么是虚拟机？这时候建议阅读我的这篇文章： JVM 基础系列第 3 讲：到底什么是虚拟机？ - 陈树义 - 博客园​www.cnblogs.com 看到这里，我相信你应该对虚拟机有了一个感性的认识了。那么接下来你需要继续深入学习，明白编译器是如何将 java 文件编译成 class 文件的。这时候你需要学习：编译器以及字节码文件相关知识。这时候推荐阅读下面几篇文章： JVM 基础系列第 4 讲：从源代码到机器码，发生了什么？ - 陈树义 - 博客园​www.cnblogs.comJVM 基础系列第 5 讲：字节码文件结构 - 陈树义 - 博客园​www.cnblogs.com 看到这里，你应该明白了不少知识，我们的源文件（java 文件）也顺利编译成了字节码文件（class 文件）。接下来就是运行程序并输出结果了，那么 JVM 是如何将字节码文件的内容加载到内存的（类加载机制），加载到内存之后又是如何进行数据存放的（JVM 内存模型）。这个时候你应该学习：Java 类加载机制、JVM 内存模型，这时候推荐阅读下面几篇文章： JVM 基础系列第 6 讲：Java 虚拟机内存结构​www.cnblogs.comJVM 基础系列第 7 讲：JVM 类加载机制​www.cnblogs.com 当我们把数据加载并存放于内存之后，就又有一个问题出现了：内存是有限的，那么势必会涉及到内存回收的问题。这时候你应该学习 Java 垃圾回收机制、Java 回收器的相关内容。这时候推荐下面几篇文章： JVM 基础系列第 8 讲：JVM 垃圾回收机制​www.cnblogs.comJVM 基础系列第 9 讲：JVM 垃圾回收器 - 陈树义 - 博客园​www.cnblogs.comJVM 基础系列第 10 讲：垃圾回收的几种类型 - 陈树义 - 博客园​www.cnblogs.com 学习到这里，你对 JVM 有了一个全面的了解。从源文件到字节码，从字节码到机器码，从机器码到内存模型，从内存到垃圾回收。你对 JVM 的基础知识也掌握得差不多了，但是如果要进行线上问题排查的话，还差一些排查知识的学习。这时候需要学习常见的 JVM 参数以及 JVM 的排查工具，这时候推荐下面几篇文章： JVM 基础系列第 11 讲：JVM 参数之堆栈空间配置 - 陈树义 - 博客园​www.cnblogs.comJVM 系列第 12 讲：JVM 参数之查看 JVM 参数 - 陈树义 - 博客园​www.cnblogs.comJVM 基础系列第 13 讲：JVM 参数之追踪类信息 - 陈树义 - 博客园​www.cnblogs.comJVM 基础系列第 14 讲：JVM 参数之 GC 日志配置 - 陈树义 - 博客园​www.cnblogs.comJVM 基础系列第 15 讲：JDK 性能监控命令 - 陈树义 - 博客园​www.cnblogs.com 到了这里，你不仅掌握了基础的 JVM 理论知识，还掌握了一些基础的问题排查技巧。接下来你要做的就是多学习一些 JVM 的问题排查案例，在实战中不断总结 JVM 排查的技巧，从而夯实自己的理论基础。 在关于 JVM 这块知识，我上面列出的「JVM 基础系列」专栏是不错的入门文章。比起书籍来说，其特点在于简单易懂，并且关联性强。但是正因为讲究关联，所以也省略了一些内容。所以当你阅读完上述系列文章后，可以阅读以下书籍。 深入理解 Java 虚拟机（第 2 版） (豆瓣)​book.douban.com 实战 Java 虚拟机 (豆瓣)​book.douban.com 《深入理解 Java 虚拟机》注重理论讲解，所以比较枯燥。而《Java 虚拟机实战》 则更加注重实战，有一些动手案例。一文一武，是学习虚拟机的利器。有了上面的基础系列文章做基础，我相信你在阅读书籍的时候会觉得很轻松。更多 JVM 的书籍，可以点击查看我收集的豆瓣书单：精通 Java 虚拟机必读书单 - 豆瓣书单 当你学习到这里，对于大多数人来说是足够在日常工作中使用的。但如果你还想继续深入，那么你可以阅读一下《Java 虚拟机规范》。《Java 虚拟机规范》是对于 JVM 的规范，其定义了 JVM 的方方面面。看完《Java 虚拟机规范》之前可能会对 JVM 有些许无界，但看完之后则又是另外一个境界了。如果你想粗略看一下内容，那你可以阅读一下我的读书笔记： JVM 规范系列开篇：为什么要读 JVM 规范？ - 陈树义 - 博客园 JVM 规范系列第 1 章：引言 - 陈树义 - 博客园 JVM 规范系列第 2 章：Java 虚拟机结构 - 陈树义 - 博客园 JVM 规范系列第 3 章：为 Java 虚拟机编译 - 陈树义 - 博客园 JVM 规范系列第 4 章：Class 文件格式 - 陈树义 - 博客园 JVM 规范系列第 5 章：加载、链接与初始化 - 陈树义 - 博客园 JVM 规范系列第 6 章：Java 虚拟机指令集 - 陈树义 - 博客园 JVM 规范系列：总结 - 陈树义 - 博客园 到这里，你对 JVM 的学习已经超过了绝大多数人了。如果你还想更深入学习，那可以阅读 HotSpot 源码了。阅读 HotSpot 源码的话，可以参考我的豆瓣 JVM 书单：精通 Java 虚拟机必读书单 - 豆瓣书单 有帮助就点个赞吧，让更多人看到~ 更多技术文章，可以关注我的公众号：陈树义。 RednaxelaFX​这完全取决于题主是为什么要学习 JVM，想学到多深。前面 @曹旭东 和 @Scott 说得很对。如果感觉摸不清东南西北的话请试试从我在豆瓣上发的豆单开始吧：从表到里学习 JVM 实现如果一上来就想通过阅读 OpenJDK 里的 HotSpot VM 的源码来入手学习 JVM，那么我推荐先读读我之前写的一个演示稿：为啥别读 HotSpot VM 的源码","categories":[{"name":"Java","slug":"java","permalink":"https://topone233.github.io/categories/java/"}],"tags":[{"name":"Java","slug":"java","permalink":"https://topone233.github.io/tags/java/"},{"name":"JVM","slug":"jvm","permalink":"https://topone233.github.io/tags/jvm/"}]},{"title":"Java 回收机制概述","slug":"Java 回收机制概述","date":"2020-09-04T02:22:56.930Z","updated":"2020-09-15T08:10:16.351Z","comments":true,"path":"2020/09/04/Java 回收机制概述/","link":"","permalink":"https://topone233.github.io/2020/09/04/Java%20%E5%9B%9E%E6%94%B6%E6%9C%BA%E5%88%B6%E6%A6%82%E8%BF%B0/","excerpt":"","text":"原文地址 [www.cnblogs.com\\](https://www.cnblogs.com/Young111/p/11348218.html) Java 技术体系中所提倡的 自动内存管理 最终可以归结为自动化地解决了两个问题：给对象分配内存 以及 回收分配给对象的内存，而且这两个问题针对的内存区域就是 Java 内存模型中的 堆区。 垃圾回收机制的引入可以有效的防止内存泄露、保证内存的有效使用，也大大解放了 Java 程序员的双手，使得他们在编写程序的时候不再需要考虑内存管理。本文着重介绍了判断一个对象是否可以被回收的两种经典算法，并详述了四种典型的垃圾回收算法的基本思想及其直接应用——垃圾收集器，最后结合内存回收策略介绍了内存分配规则。本文内容是基于 JDK 1.6 的，不同版本虚拟机之间也许会有些许差异，但不影响我们对 JVM 垃圾回收机制的整体把握和了解。 一、垃圾回收机制的意义在上篇《JVM 内存模型概述》中知道: JVM 内存模型一共包括三个部分：堆 (Java 代码可及的 Java 堆 和 JVM 自身使用的方法区)、栈 ( 服务 Java 方法的虚拟机栈 和 服务 Native 方法的本地方法栈 ) 和 保证程序在多线程环境下能够连续执行的程序计数器。特别地，我们当时就提到 Java 堆是进行垃圾回收的主要区域，故其也被称为 GC 堆；而方法区也有一个不太严谨的表述，就是永久代。总的来说，堆 (包括 Java 堆 和 方法区) 是 垃圾回收的主要对象，特别是 Java 堆。 实际上，Java 技术体系中所提倡的 自动内存管理 最终可以归结为自动化地解决了两个问题：给对象分配内存 以及回收分配给对象的内存，而且这两个问题针对的内存区域就是 Java 内存模型中的堆区。关于对象分配内存问题，笔者的博文《JVM 内存模型概述》已经阐述了 如何划分可用空间及其涉及到的线程安全问题，本文将结合垃圾回收策略进一步给出 内存分配规则。另外，我们知道垃圾回收机制是 Java 语言一个显著的特点，其可以有效的防止内存泄露、保证内存的有效使用，从而使得 Java 程序员在编写程序的时候不再需要考虑内存管理问题。Java 垃圾回收机制要考虑的问题很复杂，本文阐述了其三个核心问题，包括： 那些内存需要回收？(对象是否可以被回收的两种经典算法: 引用计数法 和 可达性分析算法) 什么时候回收？ （堆的新生代、老年代、永久代的垃圾回收时机，MinorGC 和 FullGC） 如何回收？(三种经典垃圾回收算法 (标记清除算法、复制算法、标记整理算法) 及分代收集算法 和 七种垃圾收集器) 在探讨 Java 垃圾回收机制之前，我们首先应该记住一个单词：Stop-the-World。Stop-the-world 意味着 JVM 由于要执行 GC 而停止了应用程序的执行，并且这种情形会在任何一种 GC 算法中发生。当 Stop-the-world 发生时，除了 GC 所需的线程以外，所有线程都处于等待状态直到 GC 任务完成。事实上，GC 优化很多时候就是指减少 Stop-the-world 发生的时间，从而使系统具有 高吞吐 、低停顿 的特点。 二. 如何确定一个对象是否可以被回收？1、 引用计数算法：判断对象的引用数量 引用计数算法是通过判断对象的引用数量来决定对象是否可以被回收。 引用计数算法是垃圾收集器中的早期策略。在这种方法中，堆中的每个对象实例都有一个引用计数。当一个对象被创建时，且将该对象实例分配给一个引用变量，该对象实例的引用计数设置为 1。当任何其它变量被赋值为这个对象的引用时，对象实例的引用计数加 1（a = b，则 b 引用的对象实例的计数器加 1），但当一个对象实例的某个引用超过了生命周期或者被设置为一个新值时，对象实例的引用计数减 1。特别地，当一个对象实例被垃圾收集时，它引用的任何对象实例的引用计数器均减 1。任何引用计数为 0 的对象实例可以被当作垃圾收集。 引用计数收集器可以很快的执行，并且交织在程序运行中，对程序需要不被长时间打断的实时环境比较有利，但其很难解决对象之间相互循环引用的问题。如下面的程序所示，对象 objA 和 objB 之间的引用计数永远不可能为 0，那么这两个对象就永远不能被回收。 public class ReferenceCountingGC { public Object instance = null; public static void testGC(){ ReferenceCountingGC objA = new ReferenceCountingGC (); ReferenceCountingGC objB = new ReferenceCountingGC (); // 对象之间相互循环引用，对象objA和objB之间的引用计数永远不可能为 0 objB.instance = objA; objA.instance = objB; objA = null; objB = null; System.gc(); } } 上述代码最后面两句将 objA 和 objB 赋值为 null，也就是说 objA 和 objB 指向的对象已经不可能再被访问，但是由于它们互相引用对方，导致它们的引用计数器都不为 0，那么垃圾收集器就永远不会回收它们。 2、 可达性分析算法：判断对象的引用链是否可达 可达性分析算法是通过判断对象的引用链是否可达来决定对象是否可以被回收。 可达性分析算法是从离散数学中的图论引入的，程序把所有的引用关系看作一张图，通过一系列的名为 “GC Roots” 的对象作为起始点，从这些节点开始向下搜索，搜索所走过的路径称为引用链（Reference Chain）。当一个对象到 GC Roots 没有任何引用链相连（用图论的话来说就是从 GC Roots 到这个对象不可达）时，则证明此对象是不可用的。在 Java 中，可作为 GC Root 的对象包括以下几种： 虚拟机栈 (栈帧中的局部变量表) 中引用的对象； 方法区中类静态属性引用的对象； 方法区中常量引用的对象； 本地方法栈中 Native 方法引用的对象； 三. 垃圾收集算法1、标记清除算法 标记 - 清除算法分为标记和清除两个阶段。该算法首先从根集合进行扫描，对存活的对象对象标记，标记完毕后，再扫描整个空间中未被标记的对象并进行回收，如下图所示。 从图中我们就可以发现，该算法最大的问题是内存碎片化严重，后续可能发生大对象不能找到可利用空间的问题。 效率问题：标记和清除两个过程的效率都不高; 空间问题：标记 - 清除算法不需要进行对象的移动，并且仅对不存活的对象进行处理，因此标记清除之后会产生大量不连续的内存碎片，空间碎片太多可能会导致以后在程序运行过程中需要分配较大对象时，无法找到足够的连续内存而不得不提前触发另一次垃圾收集动作。 2、复制算法 复制算法将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。当这一块的内存用完了，就将还存活着的对象复制到另外一块上面，然后再把已使用过的内存空间一次清理掉。这种算法适用于对象存活率低的场景，比如新生代。这样使得每次都是对整个半区进行内存回收，内存分配时也就不用考虑内存碎片等复杂情况，只要移动堆顶指针，按顺序分配内存即可，实现简单，运行高效。该算法示意图如下所示： 事实上，现在商用的虚拟机都采用这种算法来回收新生代。因为研究发现，新生代中的对象每次回收都基本上只有 10% 左右的对象存活，所以需要复制的对象很少，效率还不错。实践中会将新生代内存分为一块较大的 Eden 空间和两块较小的 Survivor 空间 (如下图所示)，每次使用 Eden 和其中一块 Survivor。当回收时，将 Eden 和 Survivor 中还存活着的对象一次地复制到另外一块 Survivor 空间上，最后清理掉 Eden 和刚才用过的 Survivor 空间。HotSpot 虚拟机默认 Eden 和 Survivor 的大小比例是 8:1，也就是每次新生代中可用内存空间为整个新生代容量的 90% ( 80%+10% )，只有 10% 的内存会被 “浪费”。 3、标记整理算法 复制收集算法在对象存活率较高时就要进行较多的复制操作，效率将会变低。更关键的是，如果不想浪费 50% 的空间，就需要有额外的空间进行分配担保，以应对被使用的内存中所有对象都 100% 存活的极端情况，所以在老年代一般不能直接选用这种算法。标记整理算法的标记过程类似标记清除算法，但后续步骤不是直接对可回收对象进行清理，而是让所有存活的对象都向一端移动，然后直接清理掉端边界以外的内存，类似于磁盘整理的过程，该垃圾回收算法适用于对象存活率高的场景（老年代），其作用原理如下图所示。 标记整理算法与标记清除算法最显著的区别是：标记清除算法不进行对象的移动，并且仅对不存活的对象进行处理；而标记整理算法会将所有的存活对象移动到一端，并对不存活对象进行处理，因此其不会产生内存碎片。 4、分代收集算法 分代收集法是目前大部分 JVM 所采用的方法，其核心思想是根据对象存活的不同生命周期将内存划分为不同的域，一般情况下将 GC 堆划分为老生代 (Tenured/Old Generation) 和新生代(YoungGeneration)。老生代的特点是每次垃圾回收时只有少量对象需要被回收，新生代的特点是每次垃圾回收时都有大量垃圾需要被回收，因此可以根据不同区域选择不同的算法 4.1、新生代与复制算法 目前大部分 JVM 的 GC 对于新生代都采取 Copying 算法，因为新生代中每次垃圾回收都要回收大部分对象，即要复制的操作比较少，但通常并不是按照 1： 1 来划分新生代。一般将新生代划分为一块较大的 Eden 空间和两个较小的 Survivor 空间 (From Space, To Space)，每次使用 Eden 空间和其中的一块 Survivor 空间，当进行回收时，将该两块空间中还存活的对象复制到另一块 Survivor 空间中。 ____ 4.2、老年代与标记整理算法 而老年代因为每次只回收少量对象，因而采用 标记整理算法（Mark-Compact） 算法。 1. JAVA 虚拟机提到过的处于方法区的永生代 (Permanet Generation)， 它用来存储 class 类，常量，方法描述等。对永生代的回收主要包括废弃常量和无用的类。 2. 对象的内存分配主要在新生代的 Eden Space 和 Survivor Space 的 From Space(Survivor 目前存放对象的那一块)，少数情况会直接分配到老生代。 3. 当新生代的 Eden Space 和 From Space 空间不足时就会发生一次 GC，进行 GC 后， EdenSpace 和 From Space 区的存活对象会被挪到 To Space，然后将 Eden Space 和 FromSpace 进行清理。 4. 如果 To Space 无法足够存储某个对象，则将这个对象存储到老生代。 5. 在进行 GC 后，使用的便是 Eden Space 和 To Space 了，如此反复循环。 6. 当对象在 Survivor 区躲过一次 GC 后，其年龄就会 + 1。 默认情况下年龄到达 15 的对象会被 移到老生代中。 ____ 由于对象进行了分代处理，因此垃圾回收区域、时间也不一样。垃圾回收有两种类型，Minor GC 和 Full GC。 Minor GC：对新生代进行回收，不会影响到年老代。因为新生代的 Java 对象大多死亡频繁，所以 Minor GC 非常频繁，一般在这里使用速度快、效率高的算法，使垃圾回收能尽快完成。 Full GC：也叫 Major GC，对整个堆进行回收，包括新生代和老年代。由于 Full GC 需要对整个堆进行回收，所以比 Minor GC 要慢，因此应该尽可能减少 Full GC 的次数，导致 Full GC 的原因包括：老年代被写满、永久代（Perm）被写满和 System.gc() 被显式调用等。 四. 垃圾收集器 如果说垃圾收集算法是内存回收的方法论，那么垃圾收集器就是内存回收的具体实现。下图展示了 7 种作用于不同分代的收集器，其中用于回收新生代的收集器包括 Serial、PraNew、Parallel Scavenge，回收老年代的收集器包括 Serial Old、Parallel Old、CMS，还有用于回收整个 Java 堆的 G1 收集器。不同收集器之间的连线表示它们可以搭配使用。 ____ Serial 收集器（复制算法): 新生代单线程收集器，标记和清理都是单线程，优点是简单高效； Serial Old 收集器 (标记 - 整理算法): 老年代单线程收集器，Serial 收集器的老年代版本； ParNew 收集器 (复制算法): 新生代收并行集器，实际上是 Serial 收集器的多线程版本，在多核 CPU 环境下有着比 Serial 更好的表现； Parallel Scavenge 收集器 (复制算法): 新生代并行收集器，追求高吞吐量，高效利用 CPU。吞吐量 = 用户线程时间 /(用户线程时间 + GC 线程时间)，高吞吐量可以高效率的利用 CPU 时间，尽快完成程序的运算任务，适合后台应用等对交互相应要求不高的场景； Parallel Old 收集器 (标记 - 整理算法)： 老年代并行收集器，吞吐量优先，Parallel Scavenge 收集器的老年代版本； CMS(Concurrent Mark Sweep) 收集器（标记 - 清除算法）： 老年代并行收集器，以获取最短回收停顿时间为目标的收集器，具有高并发、低停顿的特点，追求最短 GC 回收停顿时间。 G1(Garbage First)收集器 (标记 - 整理算法)： Java 堆并行收集器，G1 收集器是 JDK1.7 提供的一个新收集器，G1 收集器基于 “标记 - 整理” 算法实现，也就是说不会产生内存碎片。此外，G1 收集器不同于之前的收集器的一个重要特点是：G1 回收的范围是整个 Java 堆(包括新生代，老年代)，而前六种收集器回收的范围仅限于新生代或老年代。 五. 内存分配与回收策略 Java 技术体系中所提倡的自动内存管理最终可以归结为自动化地解决了两个问题：给对象分配内存 以及 回收分配给对象的内存。一般而言，对象主要分配在新生代的 Eden 区上，如果启动了本地线程分配缓存 (TLAB)，将按线程优先在 TLAB 上分配。少数情况下也可能直接分配在老年代中。总的来说，内存分配规则并不是一层不变的，其细节取决于当前使用的是哪一种垃圾收集器组合，还有虚拟机中与内存相关的参数的设置。 1) 对象优先在 Eden 分配，当 Eden 区没有足够空间进行分配时，虚拟机将发起一次 MinorGC。现在的商业虚拟机一般都采用复制算法来回收新生代，将内存分为一块较大的 Eden 空间和两块较小的 Survivor 空间，每次使用 Eden 和其中一块 Survivor。 当进行垃圾回收时，将 Eden 和 Survivor 中还存活的对象一次性地复制到另外一块 Survivor 空间上，最后处理掉 Eden 和刚才的 Survivor 空间。（HotSpot 虚拟机默认 Eden 和 Survivor 的大小比例是 8:1）当 Survivor 空间不够用时，需要依赖老年代进行分配担保。 2) 大对象直接进入老年代。所谓的大对象是指，需要大量连续内存空间的 Java 对象，最典型的大对象就是那种很长的字符串以及数组。 3) 长期存活的对象将进入老年代。当对象在新生代中经历过一定次数（默认为 15）的 Minor GC 后，就会被晋升到老年代中。 4) 动态对象年龄判定。为了更好地适应不同程序的内存状况，虚拟机并不是永远地要求对象年龄必须达到了 MaxTenuringThreshold 才能晋升老年代，如果在 Survivor 空间中相同年龄所有对象大小的总和大于 Survivor 空间的一半，年龄大于或等于该年龄的对象就可以直接进入老年代，无须等到 MaxTenuringThreshold 中要求的年龄。 需要注意的是，Java 的垃圾回收机制是 Java 虚拟机提供的能力，用于在空闲时间以不定时的方式动态回收无任何引用的对象占据的内存空间。也就是说，垃圾收集器回收的是无任何引用的对象占据的内存空间而不是对象本身。 六. Java 中的内存泄露问题 虽然 Java 拥有垃圾回收机制，但同样会出现内存泄露问题，比如下面提到的几种情况： (1). 诸如 HashMap、Vector 等集合类的静态使用最容易出现内存泄露，因为这些静态变量的生命周期和应用程序一致，所有的对象 Object 也不能被释放，因为他们也将一直被 Vector 等应用着。 private static Vector v = new Vector(); public void test(Vector v){ for (int i = 1; i&lt;100; i++) { Object o = new Object(); v.add(o); o = null; } } 在这个例子中，虚拟机栈中保存者 Vector 对象的引用 v 和 Object 对象的引用 o 。在 for 循环中，我们不断的生成新的对象，然后将其添加到 Vector 对象中，之后将 o 引用置空。问题是虽然我们将 o 引用置空，但当发生垃圾回收时，我们创建的 Object 对象也不能够被回收。因为垃圾回收在跟踪代码栈中的引用时会发现 v 引用，而继续往下跟踪就会发现 v 引用指向的内存空间中又存在指向 Object 对象的引用。也就是说，尽管 o 引用已经被置空，但是 Object 对象仍然存在其他的引用，是可以被访问到的，所以 GC 无法将其释放掉。如果在此循环之后， Object 对象对程序已经没有任何作用，那么我们就认为此 Java 程序发生了内存泄漏。 (2). 各种资源连接包括数据库连接、网络连接、IO 连接等没有显式调用 close 关闭，不被 GC 回收导致内存泄露。 (3). 监听器的使用，在释放对象的同时没有相应删除监听器的时候也可能导致内存泄露。 补充： 1、引用 1). 引用概述 无论是通过引用计数算法判断对象的引用数量，还是通过可达性分析算法判断对象的引用链是否可达，判定对象是否存活都与 “引用” 有关。在 JDK 1.2 之前，Java 中的引用的定义很传统：如果 reference 类型的数据中存储的数值代表的是另外一块内存的起始地址，就称这块内存代表着一个引用。这种定义很纯粹，但是太过狭隘，一个对象在这种定义下只有被引用或者没有被引用两种状态，对于如何描述一些 “食之无味，弃之可惜” 的对象就显得无能为力。我们希望能描述这样一类对象：当内存空间还足够时，则能保留在内存之中；如果内存在进行垃圾收集后还是非常紧张，则可以抛弃这些对象。很多系统的缓存功能都符合这样的应用场景。 为此，在 JDK 1.2 之后，Java 对引用的概念进行了扩充，将引用分为强引用（Strong Reference）、软引用（Soft Reference）、弱引用（Weak Reference）、虚引用（Phantom Reference）四种，这四种引用强度依次逐渐减弱。 2). 引用的种类及其定义 强引用就是指在程序代码之中普遍存在的，类似 “Object obj = new Object()” 这类引用。 只要强引用还存在，垃圾收集器就永远不会回收掉被引用的对象。 软引用用来描述一些还有用，但并非必需的对象。对于软引用关联着的对象，在系统将要发生内存溢出异常之前，将会把这些对象列进回收范围之中并进行第二次回收。如果这次回收还是没有足够的内存，才会抛出内存溢出异常。在 JDK 1.2 之后，提供了 SoftReference 类来实现软引用。 弱引用也是用来描述非必需对象的，但是它的强度比软引用更弱一些，被弱引用关联的对象只能生存到下一次垃圾收集发生之前。当垃圾收集器工作时，无论当前内存是否足够，都会回收掉只被弱引用关联的对象。在 JDK 1.2 之后，提供了 WeakReference 类来实现弱引用。 虚引用是最弱的一种引用关系。一个对象是否有虚引用的存在，完全不会对其生存时间构成影响，也无法通过虚引用来取得一个对象实例。为一个对象设置虚引用关联的唯一目的就是希望能在这个对象被收集器回收时收到一个系统通知。在 JDK 1.2 之后，提供了 PhantomReference 类来实现虚引用。 2、方法区的回收 方法区的内存回收目标主要是针对 常量池的回收 和 对类型的卸载。回收废弃常量与回收 Java 堆中的对象非常类似。以常量池中字面量的回收为例，假如一个字符串 “abc” 已经进入了常量池中，但是当前系统没有任何一个 String 对象是叫做 “abc” 的，换句话说是没有任何 String 对象引用常量池中的 “abc” 常量，也没有其他地方引用了这个字面量，如果在这时候发生内存回收，而且必要的话，这个 “abc” 常量就会被系统 “请” 出常量池。常量池中的其他类（接口）、方法、字段的符号引用也与此类似。 判定一个常量是否是 “废弃常量” 比较简单，而要判定一个类是否是 “无用的类” 的条件则相对苛刻许多。类需要同时满足下面 3 个条件才能算是“无用的类”： 该类所有的实例都已经被回收，也就是 Java 堆中不存在该类的任何实例； 加载该类的 ClassLoader 已经被回收； 该类对应的 java.lang.Class 对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。 虚拟机可以对满足上述 3 个条件的无用类进行回收 (卸载)，这里说的仅仅是 “可以”，而不是和对象一样，不使用了就必然会回收。特别地，在大量使用反射、动态代理、CGLib 等 bytecode 框架的场景，以及动态生成 JSP 和 OSGi 这类频繁自定义 ClassLoader 的场景都需要虚拟机具备类卸载的功能，以保证永久代不会溢出。","categories":[{"name":"Java","slug":"java","permalink":"https://topone233.github.io/categories/java/"}],"tags":[{"name":"Java","slug":"java","permalink":"https://topone233.github.io/tags/java/"},{"name":"GC","slug":"gc","permalink":"https://topone233.github.io/tags/gc/"}]},{"title":"JVM 类生命周期","slug":"JVM 类生命周期","date":"2020-09-04T02:22:16.720Z","updated":"2020-09-15T08:08:25.965Z","comments":true,"path":"2020/09/04/JVM 类生命周期/","link":"","permalink":"https://topone233.github.io/2020/09/04/JVM%20%E7%B1%BB%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/","excerpt":"","text":"原文地址 [www.cnblogs.com\\](https://www.cnblogs.com/Young111/p/11359700.html) 一个. java 文件在编译后会形成相应的一个或多个 Class 文件，这些 Class 文件中描述了类的各种信息，并且它们最终都需要被加载到虚拟机中才能被运行和使用。事实上，虚拟机把描述类的数据从 Class 文件加载到内存，并对数据进行校验，转换解析和初始化，最终形成可以被虚拟机直接使用的 Java 类型的过程就是虚拟机的类加载机制。本文概述了 JVM 加载类的时机和生命周期，并结合典型案例重点介绍了类的初始化过程，进而了解 JVM 类加载机制。 一、类加载机制概述 我们知道，一个. java 文件在编译后会形成相应的一个或多个 Class 文件（若一个类中含有内部类，则编译后会产生多个 Class 文件），但这些 Class 文件中描述的各种信息，最终都需要加载到虚拟机中之后才能被运行和使用。事实上，虚拟机把描述类的数据从 Class 文件加载到内存，并对数据进行校验，转换解析和初始化，最终形成可以被虚拟机直接使用的 Java 类型的过程就是虚拟机的 类加载机制。 与那些在编译时需要进行连接工作的语言不同，在 Java 语言里面，类型的加载和连接都是在程序运行期间完成，这样会在类加载时稍微增加一些性能开销，但是却能为 Java 应用程序提供高度的灵活性，Java 中天生可以动态扩展的语言特性多态就是依赖运行期动态加载和动态链接这个特点实现的。例如，如果编写一个使用接口的应用程序，可以等到运行时再指定其实际的实现。这种组装应用程序的方式广泛应用于 Java 程序之中。 既然这样，那么， 虚拟机什么时候才会加载 Class 文件并初始化类呢？（类加载和初始化时机） 虚拟机如何加载一个 Class 文件呢？（Java 类加载的方式：类加载器、双亲委派机制） 虚拟机加载一个 Class 文件要经历那些具体的步骤呢？（类加载过程 / 步骤） 本文主要对第一个和第三个问题进行阐述。 二. 类加载的时机 Java 类从被加载到虚拟机内存中开始，到卸载出内存为止，它的整个生命周期包括：加载（Loading）、验证（Verification）、准备 (Preparation)、解析(Resolution)、初始化(Initialization)、使用(Using) 和 卸载(Unloading) 七个阶段。其中准备、验证、解析 3 个部分统称为连接（Linking），如图所示： 加载、验证、准备、初始化和卸载这 5 个阶段的顺序是确定的，类的加载过程必须按照这种顺序按部就班地开始，而解析阶段则不一定：它在某些情况下可以在初始化阶段之后再开始，这是为了支持 Java 语言的运行时绑定（也称为动态绑定或晚期绑定）。以下陈述的内容都已 HotSpot 为基准。特别需要注意的是，类的加载过程必须按照这种顺序按部就班地 “开始”，而不是按部就班的“进行” 或“完成”，因为这些阶段通常都是相互交叉地混合式进行的，也就是说通常会在一个阶段执行的过程中调用或激活另外一个阶段。 了解了 Java 类的生命周期以后，那么我们现在来回答第一个问题：虚拟机什么时候才会加载 Class 文件并初始化类呢？ 1、类加载时机 什么情况下虚拟机需要开始加载一个类呢？虚拟机规范中并没有对此进行强制约束，这点可以交给虚拟机的具体实现来自由把握。 2、类初始化时机 那么，什么情况下虚拟机需要开始初始化一个类呢？这在虚拟机规范中是有严格规定的，虚拟机规范指明 有且只有 五种情况必须立即对类进行初始化（而这一过程自然发生在加载、验证、准备之后）： 1) 遇到 new、getstatic、putstatic 或 invokestatic 这四条字节码指令（注意，newarray 指令触发的只是数组类型本身的初始化，而不会导致其相关类型的初始化，比如，new String[] 只会直接触发 String[] 类的初始化，也就是触发对类 [Ljava.lang.String 的初始化，而直接不会触发 String 类的初始化）时，如果类没有进行过初始化，则需要先对其进行初始化。生成这四条指令的最常见的 Java 代码场景是： 使用 new 关键字实例化对象的时候； 读取或设置一个类的静态字段（被 final 修饰，已在编译器把结果放入常量池的静态字段除外）的时候； 调用一个类的静态方法的时候。 2) 使用 java.lang.reflect 包的方法对类进行反射调用的时候，如果类没有进行过初始化，则需要先触发其初始化。 3) 当初始化一个类的时候，如果发现其父类还没有进行过初始化，则需要先触发其父类的初始化。 4) 当虚拟机启动时，用户需要指定一个要执行的主类（包含 main() 方法的那个类），虚拟机会先初始化这个主类。 5) 当使用 jdk1.7 动态语言支持时，如果一个 java.lang.invoke.MethodHandle 实例最后的解析结果 REF_getstatic,REF_putstatic,REF_invokeStatic 的方法句柄，并且这个方法句柄所对应的类没有进行初始化，则需要先出触发其初始化。 注意，对于这五种会触发类进行初始化的场景，虚拟机规范中使用了一个很强烈的限定语：“有且只有”，这五种场景中的行为称为对一个类进行 主动引用。除此之外，所有引用类的方式，都不会触发初始化，称为 被动引用。 特别需要指出的是，类的实例化与类的初始化是两个完全不同的概念： 类的实例化是指创建一个类的实例 (对象) 的过程； 类的初始化是指为类中各个类成员 (被 static 修饰的成员变量) 赋初始值的过程，是类生命周期中的一个阶段。 3、被动引用的几种经典场景 1)、通过子类引用父类的静态字段，不会导致子类初始化 public class SSClass{ static{ System.out.println(&quot;SSClass&quot;); } } public class SClass extends SSClass{ static{ System.out.println(&quot;SClass init!&quot;); } public static int value = 123; public SClass(){ System.out.println(&quot;init SClass&quot;); } } public class SubClass extends SClass{ static{ System.out.println(&quot;SubClass init&quot;); } static int a; public SubClass(){ System.out.println(&quot;init SubClass&quot;); } } public class NotInitialization{ public static void main(String\\[\\] args){ System.out.println(SubClass.value); } } /\\* Output: SSClass SClass init! 123 \\*/ 对于静态字段，只有直接定义这个字段的类才会被初始化，因此通过其子类来引用父类中定义的静态字段，只会触发父类的初始化而不会触发子类的初始化。在本例中，由于 value 字段是在类 SClass 中定义的，因此该类会被初始化；此外，在初始化类 SClass 时，虚拟机会发现其父类 SSClass 还未被初始化，因此虚拟机将先初始化父类 SSClass，然后初始化子类 SClass，而 SubClass 始终不会被初始化。 2)、通过数组定义来引用类，不会触发此类的初始化 public class NotInitialization{ public static void main(String\\[\\] args){ SClass\\[\\] sca = new SClass\\[10\\]; } } 3)、常量在编译阶段会存入调用类的常量池中，本质上并没有直接引用到定义常量的类，因此不会触发定义常量的类的初始化 public class ConstClass{ static{ System.out.println(&quot;ConstClass init!&quot;); } public static final String CONSTANT = &quot;hello world&quot;; } public class NotInitialization{ public static void main(String\\[\\] args){ System.out.println(ConstClass.CONSTANT); } } /\\* Output: hello world \\*/ 上述代码运行之后，只输出 “hello world”，这是因为虽然在 Java 源码中引用了 ConstClass 类中的常量 CONSTANT，但是编译阶段将此常量的值 “hello world” 存储到了 NotInitialization 常量池中，对常量 ConstClass.CONSTANT 的引用实际都被转化为 NotInitialization 类对自身常量池的引用了。也就是说，实际上 NotInitialization 的 Class 文件之中并没有 ConstClass 类的符号引用入口，这两个类在编译为 Class 文件之后就不存在关系了。 三. 类加载过程 如上图所示，我们在上文已经提到过一个类的生命周期包括加载（Loading）、验证（Verification）、准备 (Preparation)、解析(Resolution)、初始化(Initialization)、使用(Using) 和 卸载(Unloading) 七个阶段。现在我们一一学习一下 JVM 在加载、验证、准备、解析和初始化五个阶段是如何对每个类进行操作的。1、加载 加载是类加载过程中的一个阶段， 这个阶段会在内存中生成一个代表这个类的 java.lang.Class 对象， 作为方法区这个类的各种数据的入口。注意这里不一定非得要从一个 Class 文件获取，这里既可以从 ZIP 包中读取（比如从 jar 包和 war 包中读取），也可以在运行时计算生成（动态代理），也可以由其它文件生成（比如将 JSP 文件转换成对应的 Class 类）。 2、验证 这一阶段的主要目的是为了确保 Class 文件的字节流中包含的信息是否符合当前虚拟机的要求，并**且不会危害虚拟机自身的安全。** 3、准备 准备阶段是正式为类变量分配内存并设置类变量的初始值阶段，即在方法区中分配这些变量所使用的内存空间。注意这里所说的初始值概念，比如一个类变量定义为 public static int v = 8080; 实际上变量 v 在准备阶段过后的初始值为 0 而不是 8080， 将 v 赋值为 8080 的 put static 指令是程序被编译后， 存放于类构造器 方法之中。但是注意如果声明为 public static final int v = 8080； 在编译阶段会为 v 生成 ConstantValue 属性，在准备阶段虚拟机会根据 ConstantValue 属性将 v 赋值为 8080。 4、解析 解析阶段是指虚拟机将常量池中的符号引用替换为直接引用的过程。符号引用就是 class 文件中的： 1. CONSTANT_Class_info 2. CONSTANT_Field_info 3. CONSTANT_Method_info 等类型的常量。 4.1 符号引用 符号引用与虚拟机实现的布局无关， 引用的目标并不一定要已经加载到内存中。 各种虚拟机实现的内存布局可以各不相同，但是它们能接受的符号引用必须是一致的，因为符号引用的字面量形式明确定义在 Java 虚拟机规范的 Class 文件格式中 4.2 直接引用 直接引用可以是指向目标的指针，相对偏移量或是一个能间接定位到目标的句柄。如果有了直接引用，那引用的目标必定已经在内存中存在。 5、初始化 初始化阶段是类加载最后一个阶段，前面的类加载阶段之后，除了在加载阶段可以自定义类加载器以外，其它操作都由 JVM 主导。到了初始阶段，才开始真正执行类中定义的 Java 程序代码 。初始化阶段是执行类构造器 方法的过程。 方法是由编译器自动收集类中的类变量的赋值操作和静态语句块中的语句合并而成的。虚拟机会保证子 方法执行之前，父类的 方法已经执行完毕， 如果一个类中没有对静态变量赋值也没有静态语句块，那么编译器可以不为这个类生成 () 方法 注意以下几种情况不会执行类初始化： 1. 通过子类引用父类的静态字段，只会触发父类的初始化，而不会触发子类的初始化。 2. 定义对象数组，不会触发该类的初始化。 3. 常量在编译期间会存入调用类的常量池中，本质上并没有直接引用定义常量的类，不会触 发定义常量所在的类。 4. 通过类名获取 Class 对象，不会触发类的初始化。 5. 通过 Class.forName 加载指定类时，如果指定参数 initialize 为 false 时，也不会触发类初 始化，其实这个参数是告诉虚拟机，是否要对类进行初始化。 6. 通过 ClassLoader 默认的 loadClass 方法，也不会触发初始化动作。 虚拟机会保证一个类的类构造器 () 在多线程环境中被正确的加锁、同步，如果多个线程同时去初始化一个类，那么只会有一个线程去执行这个类的类构造器 &lt; clinit&gt;()，其他线程都需要阻塞等待，直到活动线程执行 &lt; clinit&gt;() 方法完毕。特别需要注意的是，在这种情形下，其他线程虽然会被阻塞，但如果执行 &lt; clinit&gt;() 方法的那条线程退出后，其他线程在唤醒之后不会再次进入 / 执行 &lt; clinit&gt;() 方法，因为 在同一个类加载器下，一个类型只会被初始化一次。如果在一个类的 &lt; clinit&gt;() 方法中有耗时很长的操作，就可能造成多个线程阻塞，在实际应用中这种阻塞往往是隐藏的，如下所示： public class DealLoopTest { static{ System.out.println(&quot;DealLoopTest...&quot;); } static class DeadLoopClass { static { if (true) { System.out.println(Thread.currentThread() + &quot;init DeadLoopClass&quot;); while (true) { // 模拟耗时很长的操作 } } } } public static void main(String\\[\\] args) { Runnable script = new Runnable() { // 匿名内部类 public void run() { System.out.println(Thread.currentThread() + &quot; start&quot;); DeadLoopClass dlc = new DeadLoopClass(); System.out.println(Thread.currentThread() + &quot; run over&quot;); } }; Thread thread1 = new Thread(script); Thread thread2 = new Thread(script); thread1.start(); thread2.start(); } } /\\* Output: DealLoopTest... Thread\\[Thread-1,5,main\\] start Thread\\[Thread-0,5,main\\] start Thread\\[Thread-1,5,main\\]init DeadLoopClass \\*/ 如上述代码所示，在初始化 DeadLoopClass 类时，线程 Thread-1 得到执行并在执行这个类的类构造器 () 时，由于该方法包含一个死循环，因此久久不能退出。 四. 典型案例分析 在 Java 中， 创建一个对象常常需要经历如下几个过程：父类的类构造器 () -&gt; 子类的类构造器 &lt; clinit&gt;() -&gt; 父类的成员变量和实例代码块 -&gt; 父类的构造函数 -&gt; 子类的成员变量和实例代码块 -&gt; 子类的构造函数。 那么，我们看看下面的程序的输出结果： public class StaticTest { public static void main(String\\[\\] args) { staticFunction(); } static StaticTest st = new StaticTest(); static { //静态代码块 System.out.println(&quot;1&quot;); } { // 实例代码块 System.out.println(&quot;2&quot;); } StaticTest() { // 实例构造器 System.out.println(&quot;3&quot;); System.out.println(&quot;a=&quot; + a + &quot;,b=&quot; + b); } public static void staticFunction() { // 静态方法 System.out.println(&quot;4&quot;); } int a = 110; // 实例变量 static int b = 112; // 静态变量 } /\\* Output: 2 3 a=110,b=0 1 4 \\*/ 大家能得到正确答案吗？虽然笔者勉强猜出了正确答案，但总感觉怪怪的。因为在初始化阶段，当 JVM 对类 StaticTest 进行初始化时，首先会执行下面的语句： static StaticTest st = new StaticTest(); 也就是实例化 StaticTest 对象，但这个时候类都没有初始化完毕啊，能直接进行实例化吗？事实上，这涉及到一个根本问题就是：实例初始化不一定要在类初始化结束之后才开始初始化。 下面我们结合类的加载过程说明这个问题。 我们知道，类的生命周期是：加载 -&gt; 验证 -&gt; 准备 -&gt; 解析 -&gt; 初始化 -&gt; 使用 -&gt; 卸载，并且只有在准备阶段和初始化阶段才会涉及类变量的初始化和赋值，因此我们只针对这两个阶段进行分析： 首先，在类的准备阶段需要做的是为类变量（static 变量）分配内存并设置默认值 (零值)，因此在该阶段结束后，类变量 st 将变为 null、b 变为 0。特别需要注意的是，如果类变量是 final 的，那么编译器在编译时就会为 value 生成 ConstantValue 属性，并在准备阶段虚拟机就会根据 ConstantValue 的设置将变量设置为指定的值。也就是说，如果上述程度对变量 b 采用如下定义方式时： static final int b=112 那么，在准备阶段 b 的值就是 112，而不再是 0 了。 此外，在类的初始化阶段需要做的是执行类构造器 ()，需要指出的是，类构造器本质上是编译器收集所有静态语句块和类变量的赋值语句按语句在源码中的顺序合并生成类构造器 &lt; clinit&gt;()。因此，对上述程序而言，JVM 将先执行第一条静态变量的赋值语句： st = new StaticTest ()； 在类都没有初始化完毕之前，能直接进行实例化相应的对象吗？ 事实上，从 Java 角度看，我们知道一个类初始化的基本常识，那就是：在同一个类加载器下，一个类型只会被初始化一次。所以，一旦开始初始化一个类型，无论是否完成，后续都不会再重新触发该类型的初始化阶段了 (只考虑在同一个类加载器下的情形)。因此，在实例化上述程序中的 st 变量时，实际上是把实例初始化嵌入到了静态初始化流程中，并且在上面的程序中，嵌入到了静态初始化的起始位置。这就导致了实例初始化完全发生在静态初始化之前，当然，这也是导致 a 为 110b 为 0 的原因。 因此，上述程序的 StaticTest 类构造器 () 的实现等价于： public class StaticTest { &lt;clinit&gt;(){ a = 110; // 实例变量 System.out.println(&quot;2&quot;); // 实例代码块 System.out.println(&quot;3&quot;); // 实例构造器中代码的执行 System.out.println(&quot;a=&quot; + a + &quot;,b=&quot; + b); // 实例构造器中代码的执行 类变量st被初始化 System.out.println(&quot;1&quot;); //静态代码块 类变量b被初始化为112 } } 因此，上述程序会有上面的输出结果。下面，我们对上述程序稍作改动，在程序最后的一行，增加以下代码行： static StaticTest st1 = new StaticTest(); 那么，此时程序的输出又是什么呢？如果你对上述的内容理解很好的话，不难得出结论 (只有执行完上述代码行后，StaticTest 类才被初始化完成)，即： 2 3 a=110,b=0 1 2 3 a=110,b=112 4 那么下面的程序的执行结果是什么呢？？？ class Foo { int i = 1; Foo() { System.out.println(i); int x = getValue(); System.out.println(x); } { i = 2; } protected int getValue() { return i; } } //子类 class Bar extends Foo { int j = 1; Bar() { j = 2; } { j = 3; } @Override protected int getValue() { return j; } } public class ConstructorExample { public static void main(String... args) { Bar bar = new Bar(); System.out.println(bar.getValue()); } } 在创建对象前，先进行类的初始化，类的初始化会将所有非静态代码块收集起来先执行，而父类必须先于子类初始化，所以父类静态代码块先执行，接着是子类静态代码块。此时类初始化完成。接下来要创建子类实例，子类通过 super() 调用父类构造方法，在执行构造方法之前要先执行非静态代码块，所以顺序是 父类非静态代码块 》 父类构造函数 》 子类非静态代码块 》 子类构造函数 运行程序，就知道结果。只要真正理解类的实例化过程，这类问题不会再难道我们了！","categories":[{"name":"Java","slug":"java","permalink":"https://topone233.github.io/categories/java/"}],"tags":[{"name":"Java","slug":"java","permalink":"https://topone233.github.io/tags/java/"},{"name":"JVM","slug":"jvm","permalink":"https://topone233.github.io/tags/jvm/"}]},{"title":"MYSQL","slug":"MYSQL","date":"2020-09-04T02:21:49.744Z","updated":"2020-09-15T08:26:40.837Z","comments":true,"path":"2020/09/04/MYSQL/","link":"","permalink":"https://topone233.github.io/2020/09/04/MYSQL/","excerpt":"","text":"原文地址 [www.cnblogs.com\\](https://www.cnblogs.com/Young111/p/9598728.html) 数据库 数据库概述1. 什么是数据库 数据库就是存储数据的仓库，其本质是一个文件系统，数据按照特定的格式将数据存储起来，用户可以对数据库中的数据进行增加，修改，删除及查询操作。 2. 什么是数据库管理系统 数据库管理系统（DataBase Management System，DBMS）：指一种操作和管理数据库的大型软件，用于建立、使用和维护数据库，对数据库进行统一管理和控制，以保证数据库的安全性和完整性。用户通过数据库管理系统访问数据库中表内的数据。 常见的数据库管理系统 MYSQL ：开源免费的数据库，小型的数据库. 已经被 Oracle 收购了. MySQL6.x 版本也开始收费。 Oracle ：收费的大型数据库，Oracle 公司的产品。Oracle 收购 SUN 公司，收购 MYSQL。 DB2 ：IBM 公司的数据库产品, 收费的。常应用在银行系统中. SQLServer：MicroSoft 公司收费的中型的数据库。C#、.net 等语言常使用。 SyBase ：已经淡出历史舞台。提供了一个非常专业数据建模的工具 PowerDesigner。 SQLite : 嵌入式的小型数据库，应用在手机端。 Java 相关的数据库：MYSQL，Oracle． 这里使用 MySQL 数据库。MySQL 中可以有多个数据库，数据库是真正存储数据的地方。 数据库与数据库管理系统的关系 mysqlmysql 的管理安装linux: \\--yum -y install mariadb mariadb-server OR --yum -y install mysql mysql-server window \\--http://dev.mysql.com/downloads/mysql/ 启动\\--service mysqld start #开启 --chkconfig mysqld on #设置开机自启 OR --systemctl start mariadb --systemctl enable mariadb 查看\\-- ps aux |grep mysqld #查看进程 -- netstat -an |grep 3306 #查看端口 设置密码\\-- mysqladmin -uroot password &#39;123&#39; #设置初始密码，初始密码为空因此-p选项没有用 -- mysqladmin -u root -p123 password &#39;1234&#39; #修改root用户密码 登录\\-- mysql #本地登录，默认用户root，空密码，用户为root@127.0.0.1 -- mysql -uroot -p1234 #本地登录，指定用户名和密码，用户为root@127.0.0.1 -- mysql -uroot -p1234 -h 192.168.31.95 #远程登录，用户为root@192.168.31.95 mysql 的常用命令 \\-- -- 启动mysql服务与停止mysql服务命令： -- -- net start mysql -- net stop mysql -- -- -- 登陆与退出命令： -- -- mysql －h 服务器IP -P 端口号 -u 用户名 -p 密码 －－prompt 命令提示符 －－delimiter 指定分隔符 -- mysql －h 127.0.0.1 -P 3306 -uroot -p123 -- quit------exit----\\\\q; -- -- -- \\\\s; ------my.ini文件：\\[mysql\\] default-character-set=gbk \\[mysqld\\] character-set-server=gbk -- -- prompt 命令提示符（\\\\D:当前日期 \\\\d:当前数据库 \\\\u:当前用户） -- -- \\\\T(开始日志) \\\\t(结束日志) -- -- show warnings; -- -- help() ? \\\\h -- -- \\\\G； -- -- select now(); -- select version(); -- select user; -- -- \\\\c 取消命令 -- -- delimiter 指定分隔符 忘记密码??? 方法一: 启动 mysql 时, 跳过授权表 \\[root@controller ~\\]# service mysqld stop \\[root@controller ~\\]# mysqld\\_safe --skip-grant-table &amp; \\[root@controller ~\\]# mysql mysql&gt; select user,host,password from mysql.user; +----------+-----------------------+-------------------------------------------+ | user | host | password | +----------+-----------------------+-------------------------------------------+ | root | localhost | \\*A4B6157319038724E3560894F7F932C8886EBFCF | | root | localhost.localdomain | | | root | 127.0.0.1 | | | root | ::1 | | | | localhost | | | | localhost.localdomain | | | root | % | \\*23AE809DDACAF96AF0FD78ED04B6A265E05AA257 | +----------+-----------------------+-------------------------------------------+ mysql&gt; update mysql.user set password=password(&quot;123&quot;) where user=&quot;root&quot; and host=&quot;localhost&quot;; mysql&gt; flush privileges; mysql&gt; exit \\[root@controller ~\\]# service mysqld restart \\[root@controller ~\\]# mysql -uroot -p123 方法二: 删库 删除与权限相关的库mysql，所有的授权信息都丢失，主要用于测试数据库或者刚刚建库不久没有授权数据的情况（从删库到跑路） \\[root@controller ~\\]# rm -rf /var/lib/mysql/mysql \\[root@controller ~\\]# service mysqld restart \\[root@controller ~\\]# mysql SQL 语句数据库是不认识 python 语言的，但是我们同样要与数据库交互，这时需要使用到数据库认识的语言 SQL 语句，它是数据库的代码。 结构化查询语言 (Structured Query Language) 简称 SQL，是一种数据库查询和程序设计语言，用于存取数据以及查询、更新和管理关系数据库系统。 创建数据库、创建数据表、向数据表中添加一条条数据信息均需要使用 SQL 语句。 SQL 分类： 数据定义语言：简称 DDL(Data Definition Language)，用来定义数据库对象：数据库，表，列等。关键字：create，alter，drop 等 数据操作语言：简称 DML(Data Manipulation Language)，用来对数据库中表的记录进行更新。关键字：insert，delete，update 等 数据控制语言：简称 DCL(Data Control Language)，用来定义数据库的访问权限和安全级别，及创建用户。 数据查询语言：简称 DQL(Data Query Language)，用来查询数据库中表的记录。关键字：select，from，where 等 SQL 通用语法 l SQL 语句可以单行或多行书写，以分号结尾 l 可使用空格和缩进来增强语句的可读性 l MySQL 数据库的 SQL 语句不区分大小写，建议使用大写，例如：SELECT * FROM user。 l 同样可以使用 /**/ 的方式完成注释 l MySQL 中的我们常使用的数据类型如下 ) 详细的数据类型如下 (不建议详细阅读！) | 分类 | 类型名称 | 说明 || 整数类型 | tinyInt | 很小的整数 || smallint | 小的整数 || mediumint | 中等大小的整数 || int(integer) | 普通大小的整数 || 小数类型 | float | 单精度浮点数 || double | 双精度浮点数 || decimal（m,d） | 压缩严格的定点数 || 日期类型 | year | YYYY 1901~2155 || time | HH:MM:SS -838:59:59~838:59:59 || date | YYYY-MM-DD 1000-01-01~9999-12-3 || datetime | YYYY-MM-DD HH:MM:SS 1000-01-01 00:00:00~ 9999-12-31 23:59:59 || timestamp | YYYY-MM-DD HH:MM:SS 19700101 00:00:01 UTC~2038-01-19 03:14:07UTC || 文本、二进制类型 | CHAR(M) | M 为 0~255 之间的整数 || VARCHAR(M) | M 为 0~65535 之间的整数 || TINYBLOB | 允许长度 0~255 字节 || BLOB | 允许长度 0~65535 字节 || MEDIUMBLOB | 允许长度 0~167772150 字节 || LONGBLOB | 允许长度 0~4294967295 字节 || TINYTEXT | 允许长度 0~255 字节 || TEXT | 允许长度 0~65535 字节 || MEDIUMTEXT | 允许长度 0~167772150 字节 || LONGTEXT | 允许长度 0~4294967295 字节 || VARBINARY(M) | 允许长度 0~M 个字节的变长字节字符串 || BINARY(M) | 允许长度 0~M 个字节的定长字节字符串 | 数据库操作基础操作: \\-- 1.创建表（类似于一个excel表） create table tab\\_name( field1 type\\[完整性约束条件\\], field2 type, ... fieldn type )\\[character set xxx\\]; -- 创建一个员工表employee create table employee( id int primary key auto\\_increment , name varchar(20), gender bit default 1, -- gender char(1) default 1 ----- 或者 TINYINT(1) birthday date, entry\\_date date, job varchar(20), salary double(4,2) unsigned, resume text -- 注意，这里作为最后一个字段不加逗号 ); /\\* 约束: primary key (非空且唯一) :能够唯一区分出当前记录的字段称为主键！ unique not null auto\\_increment 主键字段必须是数字类型。 外键约束 foreign key \\*/ -- 2.查看表信息 desc tab\\_name 查看表结构 show columns from tab\\_name 查看表结构 show tables 查看当前数据库中的所有的表 show create table tab\\_name 查看当前数据库表建表语句 -- 3.修改表结构 -- (1)增加列(字段) alter table tab\\_name add \\[column\\] 列名 类型［完整性约束条件］［first｜after 字段名］; alter table user add addr varchar(20) not null unique first/after username; #添加多个字段 alter table users2 add addr varchar(20), add age int first, add birth varchar(20) after name; -- (2)修改一列类型 alter table tab\\_name modify 列名 类型 \\[完整性约束条件\\]［first｜after 字段名］; alter table users2 modify age tinyint default 20; alter table users2 modify age int after id; -- (3)修改列名 alter table tab\\_name change \\[column\\] 列名 新列名 类型 \\[完整性约束条件\\]［first｜after 字段名］; alter table users2 change age Age int default 28 first; -- (4)删除一列 alter table tab\\_name drop \\[column\\] 列名; -- 思考：删除多列呢？删一个填一个呢？ alter table users2 add salary float(6,2) unsigned not null after name, drop addr; -- (5)修改表名 rename table 表名 to 新表名; -- (6)修该表所用的字符集 alter table student character set utf8; -- 4.删除表 drop table tab\\_name; ---5 添加主键，删除主键 alter table tab\\_name add primary key(字段名称,...) alter table users drop primary key; eg: mysql&gt; create table test5(num int auto\\_increment); ERROR 1075 (42000): Incorrect table definition; there can be only one auto column and it must be defined as a key create table test(num int primary key auto\\_increment); -- 思考，如何删除主键？ alter table test modify id int; -- auto\\_increment没了，但这样写主键依然存在，所以还要加上下面这句 alter table test drop primary key;-- 仅仅用这句也无法直接删除主键 -- 唯一索引 alter table tab\\_name add unique \\[index|key\\] \\[索引名称\\](字段名称,...) alter table users add unique(name)-- 索引值默认为字段名show create table users; alter table users add unique key user\\_name(name);-- 索引值为user\\_name -- 添加联合索引 alter table users add unique index name\\_age(name,age);#show create table users; -- 删除唯一索引 alter table tab\\_name drop {index|key} index\\_name 完整性约束条件之主键约束单字段主键 主键字段特点：非空且唯一 ) create table users( id INT primary key, name varchar(20), city varchar(20) ); View Code 多字段联合主键 ) create table users2( id INT, name varchar(20), city varchar(20), primary key(name,id) ); View Code &lt;1&gt; 一张表只能有一个主键 &lt;2&gt; 主键类型不一定非是整型 表纪录操作表纪录之增，删，改) \\-- 1.增加一条记录insert /\\*insert ［into］ tab\\_name (field1,filed2,.......) values (value1,value2,.......);\\*/ create table employee\\_new( id int primary key auto\\_increment, name varchar(20) not null unique, birthday varchar(20), salary float(7,2) ); insert into employee\\_new (id,name,birthday,salary) values (1,&#39;yuan&#39;,&#39;1990-09-09&#39;,9000); insert into employee\\_new values (2,&#39;alex&#39;,&#39;1989-08-08&#39;,3000); insert into employee\\_new (name,salary) values (&#39;xialv&#39;,1000); -- 插入多条数据 insert into employee\\_new values (4,&#39;alvin1&#39;,&#39;1993-04-20&#39;,3000), (5,&#39;alvin2&#39;,&#39;1995-05-12&#39;,5000); -- set插入: insert ［into］ tab\\_name set 字段名=值 insert into employee\\_new set id=12,; -- 2.修改表记录 update tab\\_name set field1=value1,field2=value2,......\\[where 语句\\] /\\* UPDATE语法可以用新值更新原有表行中的各列。 SET子句指示要修改哪些列和要给予哪些值。 WHERE子句指定应更新哪些行。如没有WHERE子句，则更新所有的行。\\*/ update employee\\_new set birthday=&quot;1989-10-24&quot; WHERE id=1; --- 将yuan的薪水在原有基础上增加1000元。 update employee\\_new set salary=salary+4000 where name=&#39;yuan&#39;; -- 3.删除表纪录 delete from tab\\_name \\[where ....\\] /\\* 如果不跟where语句则删除整张表中的数据 delete只能用来删除一行记录 delete语句只能删除表中的内容，不能删除表本身，想要删除表，用drop TRUNCATE TABLE也可以删除表中的所有数据，词语句首先摧毁表，再新建表。此种方式删除的数据不能在 事务中恢复。\\*/ -- 删除表中名称为’alex’的记录。 delete from employee\\_new where name=&#39;alex&#39;; -- 删除表中所有记录。 delete from employee\\_new;-- 注意auto\\_increment没有被重置:alter table employee auto\\_increment=1; -- 使用truncate删除表中记录。 truncate table emp\\_new; View Code 表纪录之查 (单表查询)) \\-- 查询表达式 SELECT \\*|field1,filed2 ... FROM tab\\_name WHERE 条件 GROUP BY field HAVING 筛选 ORDER BY field LIMIT 限制条数 ---准备表 CREATE TABLE ExamResult( id INT PRIMARY KEY auto\\_increment, name VARCHAR (20), JS DOUBLE , Django DOUBLE , OpenStack DOUBLE ); INSERT INTO ExamResult VALUES (1,&quot;yuan&quot;,98,98,98), (2,&quot;tom&quot;,35,98,67), (3,&quot;jerry&quot;,59,59,62), (4,&quot;jean&quot;,88,89,82), (5,&quot;lilei&quot;,88,98,67), (6,&quot;kivn&quot;,86,100,55); -- （1）select \\[distinct\\] \\*|field1，field2，...... from tab\\_name -- 其中from指定从哪张表筛选，\\*表示查找所有列，也可以指定一个列 -- 表明确指定要查找的列，distinct用来剔除重复行。 -- 查询表中所有学生的信息。 select \\* from ExamResult; -- 查询表中所有学生的姓名和对应的英语成绩。 select name,JS from ExamResult; -- 过滤表中重复数据。 select distinct JS ,name from ExamResult; -- （2）select 也可以使用表达式，并且可以使用: 字段 as 别名或者:字段 别名 -- 在所有学生分数上加10分特长分显示。 select name,JS+10,Django+10,OpenStack+10 from ExamResult; -- 统计每个学生的总分。 select name,JS+Django+OpenStack from ExamResult; -- 使用别名表示学生总分。 select name as 姓名,JS+Django+OpenStack as 总成绩 from ExamResult; select name,JS+Django+OpenStack 总成绩 from ExamResult; select name JS from ExamResult; -- what will happen?----&gt;记得加逗号 -- （3）使用where子句，进行过滤查询。 -- 查询姓名为XXX的学生成绩 select \\* from ExamResult where name=&#39;jerry&#39;; -- 查询英语成绩大于90分的同学 select id,name,JS from ExamResult where JS&gt;90; -- 查询总分大于200分的所有同学 select name,JS+Django+OpenStack as 总成绩 from ExamResult where JS+Django+OpenStack&gt;200 ; -- where字句中可以使用： -- 比较运算符： &gt; &lt; &gt;= &lt;= &lt;&gt; != between 80 and 100 值在10到20之间 in(80,90,100) 值是10或20或30 like &#39;jerry%&#39; /\\* pattern可以是%或者\\_， 如果是%则表示任意多字符，此例如唐僧,唐国强 如果是\\_则表示一个字符唐\\_，只有唐僧符合。两个\\_则表示两个字符：\\_\\_ \\*/ -- 逻辑运算符 在多个条件直接可以使用逻辑运算符 and or not -- 练习 -- 查询JS分数在 70－100之间的同学。 select name ,JS from ExamResult where JS between 80 and 100; -- 查询Django分数为75,76,77的同学。 select name ,Django from ExamResult where Django in (75,98,77); -- 查询所有姓王的学生成绩。 select \\* from ExamResult where name like &#39;王%&#39;; -- 查询JS分&gt;90，Django分&gt;90的同学。 select id,name from ExamResult where JS&gt;90 and Django &gt;90; -- 查找缺考数学的学生的姓名 select name from ExamResult where Database is null; -- （4）Order by 指定排序的列，排序的列即可是表中的列名，也可以是select 语句后指定的别名。 -- select \\*|field1,field2... from tab\\_name order by field \\[Asc|Desc\\] -- Asc 升序、Desc 降序，其中asc为默认值 ORDER BY 子句应位于SELECT语句的结尾。 -- 练习： -- 对JS成绩排序后输出。 select \\* from ExamResult order by JS; -- 对总分排序按从高到低的顺序输出 select name ,(ifnull(JS,0)+ifnull(Django,0)+ifnull(Database,0)) 总成绩 from ExamResult order by 总成绩 desc; -- 对姓李的学生成绩排序输出 select name ,(ifnull(JS,0)+ifnull(Django,0)+ifnull(OpenStack,0)) 总成绩 from ExamResult where name like &#39;a%&#39; order by 总成绩 desc; -- （5）group by 分组查询： CREATE TABLE order\\_menu( id INT PRIMARY KEY auto\\_increment, product\\_name VARCHAR (20), price FLOAT(6,2), born\\_date DATE, class VARCHAR (20) ); INSERT INTO order\\_menu (product\\_name,price,born\\_date,class) VALUES (&quot;苹果&quot;,20,20170612,&quot;水果&quot;), (&quot;香蕉&quot;,80,20170602,&quot;水果&quot;), (&quot;水壶&quot;,120,20170612,&quot;电器&quot;), (&quot;被罩&quot;,70,20170612,&quot;床上用品&quot;), (&quot;音响&quot;,420,20170612,&quot;电器&quot;), (&quot;床单&quot;,55,20170612,&quot;床上用品&quot;), (&quot;草莓&quot;,34,20170612,&quot;水果&quot;); -- 注意,按分组条件分组后每一组只会显示第一条记录 -- group by字句，其后可以接多个列名，也可以跟having子句,对group by 的结果进行筛选。 -- 按位置字段筛选 select \\* from order\\_menu group by 5; -- 练习：对购物表按类名分组后显示每一组商品的价格总和 select class,SUM(price)from order\\_menu group by class; -- 练习：对购物表按类名分组后显示每一组商品价格总和超过150的商品 select class,SUM(price)from order\\_menu group by class HAVING SUM(price)&gt;150; /\\* having 和 where两者都可以对查询结果进行进一步的过滤，差别有： &lt;1&gt;where语句只能用在分组之前的筛选，having可以用在分组之后的筛选； &lt;2&gt;使用where语句的地方都可以用having进行替换 &lt;3&gt;having中可以用聚合函数，where中就不行。 \\*/ -- GROUP\\_CONCAT() 函数 SELECT id,GROUP\\_CONCAT(name),GROUP\\_CONCAT(JS) from ExamResult GROUP BY id; -- （6）聚合函数： 先不要管聚合函数要干嘛，先把要求的内容查出来再包上聚合函数即可。 -- (一般和分组查询配合使用) --&lt;1&gt; 统计表中所有记录 -- COUNT(列名)：统计行的个数 -- 统计一个班级共有多少学生？先查出所有的学生，再用count包上 select count(\\*) from ExamResult; -- 统计JS成绩大于70的学生有多少个？ select count(JS) from ExamResult where JS&gt;70; -- 统计总分大于280的人数有多少？ select count(name) from ExamResult where (ifnull(JS,0)+ifnull(Django,0)+ifnull(OpenStack,0))&gt;280; -- 注意:count(\\*)统计所有行; count(字段)不统计null值. -- SUM(列名)：统计满足条件的行的内容和 -- 统计一个班级JS总成绩？先查出所有的JS成绩，再用sum包上 select JS as JS总成绩 from ExamResult; select sum(JS) as JS总成绩 from ExamResult; -- 统计一个班级各科分别的总成绩 select sum(JS) as JS总成绩, sum(Django) as Django总成绩, sum(OpenStack) as OpenStack from ExamResult; -- 统计一个班级各科的成绩总和 select sum(ifnull(JS,0)+ifnull(Django,0)+ifnull(Database,0)) as 总成绩 from ExamResult; -- 统计一个班级JS成绩平均分 select sum(JS)/count(\\*) from ExamResult ; -- 注意：sum仅对数值起作用，否则会报错。 -- AVG(列名)： -- 求一个班级JS平均分？先查出所有的JS分，然后用avg包上。 select avg(ifnull(JS,0)) from ExamResult; -- 求一个班级总分平均分 select avg((ifnull(JS,0)+ifnull(Django,0)+ifnull(Database,0))) from ExamResult ; -- Max、Min -- 求班级最高分和最低分（数值范围在统计中特别有用） select Max((ifnull(JS,0)+ifnull(Django,0)+ifnull(OpenStack,0))) 最高分 from ExamResult; select Min((ifnull(JS,0)+ifnull(Django,0)+ifnull(OpenStack,0))) 最低分 from ExamResult; -- 求购物表中单价最高的商品名称及价格 ---SELECT id, MAX(price) FROM order\\_menu;--id和最高价商品是一个商品吗? SELECT MAX(price) FROM order\\_menu; -- 注意：null 和所有的数计算都是null，所以需要用ifnull将null转换为0！ -- -----ifnull(JS,0) -- with rollup的使用 --&lt;2&gt; 统计分组后的组记录 -- （7） 重点：Select from where group by having order by -- Mysql在执行sql语句时的执行顺序： -- from where select group by having order by -- 分析: select JS as JS成绩 from ExamResult where JS成绩 &gt;70; ---- 不成功 select JS as JS成绩 from ExamResult having JS成绩 &gt;90; --- 成功 -- (8) limit SELECT \\* from ExamResult limit 1; SELECT \\* from ExamResult limit 2,5;--跳过前两条显示接下来的五条纪录 SELECT \\* from ExamResult limit 2,2; --- (9) 使用正则表达式查询 SELECT \\* FROM employee WHERE emp\\_name REGEXP &#39;^yu&#39;; SELECT \\* FROM employee WHERE emp\\_name REGEXP &#39;yun$&#39;; SELECT \\* FROM employee WHERE emp\\_name REGEXP &#39;m{2}&#39;; View Code 外键约束创建外键) \\--- 每一个班主任会对应多个学生 , 而每个学生只能对应一个班主任 ----主表 CREATE TABLE ClassCharger( id TINYINT PRIMARY KEY auto\\_increment, name VARCHAR (20), age INT , is\\_marriged boolean -- show create table ClassCharger: tinyint(1) ); INSERT INTO ClassCharger (name,age,is\\_marriged) VALUES (&quot;冰冰&quot;,12,0), (&quot;丹丹&quot;,14,0), (&quot;歪歪&quot;,22,0), (&quot;姗姗&quot;,20,0), (&quot;小雨&quot;,21,0); ----子表 CREATE TABLE Student( id INT PRIMARY KEY auto\\_increment, name VARCHAR (20), charger\\_id TINYINT, --切记:作为外键一定要和关联主键的数据类型保持一致 -- \\[ADD CONSTRAINT charger\\_fk\\_stu\\]FOREIGN KEY (charger\\_id) REFERENCES ClassCharger(id) ) ENGINE=INNODB; INSERT INTO Student(name,charger\\_id) VALUES (&quot;alvin1&quot;,2), (&quot;alvin2&quot;,4), (&quot;alvin3&quot;,1), (&quot;alvin4&quot;,3), (&quot;alvin5&quot;,1), (&quot;alvin6&quot;,3), (&quot;alvin7&quot;,2); DELETE FROM ClassCharger WHERE ; INSERT student (name,charger\\_id) VALUES (&quot;yuan&quot;,1); -- 删除居然成功,可是 alvin3显示还是有班主任id=1的冰冰的; -----------增加外键和删除外键--------- ALTER TABLE student ADD CONSTRAINT abc FOREIGN KEY(charger\\_id) REFERENCES classcharger(id); ALTER TABLE student DROP FOREIGN KEY abc; View Code INNODB 支持的 ON 语句) \\--外键约束对子表的含义: 如果在父表中找不到候选键,则不允许在子表上进行insert/update --外键约束对父表的含义: 在父表上进行update/delete以更新或删除在子表中有一条或多条对 -- 应匹配行的候选键时,父表的行为取决于：在定义子表的外键时指定的 -- on update/on delete子句 -----------------innodb支持的四种方式--------------------------------------- -----cascade方式 在父表上update/delete记录时，同步update/delete掉子表的匹配记录 -----外键的级联删除：如果父表中的记录被删除，则子表中对应的记录自动被删除-------- FOREIGN KEY (charger\\_id) REFERENCES ClassCharger(id) ON DELETE CASCADE ------set null方式 在父表上update/delete记录时，将子表上匹配记录的列设为null -- 要注意子表的外键列不能为not null FOREIGN KEY (charger\\_id) REFERENCES ClassCharger(id) ON DELETE SET NULL ------Restrict方式 :拒绝对父表进行删除更新操作(了解) ------No action方式 在mysql中同Restrict,如果子表中有匹配的记录,则不允许对父表对应候选键 -- 进行update/delete操作（了解） View Code 多表查询) \\-- 准备两张表 -- company.employee -- company.department create table employee( emp\\_id int auto\\_increment primary key not null, emp\\_name varchar(50), age int, dept\\_id int ); insert into employee(emp\\_name,age,dept\\_id) values (&#39;A&#39;,19,200), (&#39;B&#39;,26,201), (&#39;C&#39;,30,201), (&#39;D&#39;,24,202), (&#39;E&#39;,20,200), (&#39;F&#39;,38,204); create table department( dept\\_id int, dept\\_name varchar(100) ); insert into department values (200,&#39;人事部&#39;), (201,&#39;技术部&#39;), (202,&#39;销售部&#39;), (203,&#39;财政部&#39;); mysql&gt; select \\* from employee; +--------+----------+------+---------+ | emp\\_id | emp\\_name | age | dept\\_id | +--------+----------+------+---------+ | 1 | A | 19 | 200 | | 2 | B | 26 | 201 | | 3 | C | 30 | 201 | | 4 | D | 24 | 202 | | 5 | E | 20 | 200 | | 6 | F | 38 | 204 | +--------+----------+------+---------+ 6 rows in set (0.00 sec) mysql&gt; select \\* from department; +---------+-----------+ | dept\\_id | dept\\_name | +---------+-----------+ | 200 | 人事部 | | 201 | 技术部 | | 202 | 销售部 | | 203 | 财政部 | +---------+-----------+ 4 rows in set (0.01 sec) 准备表 多表查询之连接查询) mysql&gt; SELECT \\* FROM employee,department; -- select employee.emp\\_id,employee.emp\\_name,employee.age, -- department.dept\\_name from employee,department; +--------+----------+------+---------+---------+-----------+ | emp\\_id | emp\\_name | age | dept\\_id | dept\\_id | dept\\_name | +--------+----------+------+---------+---------+-----------+ | 1 | A | 19 | 200 | 200 | 人事部 | | 1 | A | 19 | 200 | 201 | 技术部 | | 1 | A | 19 | 200 | 202 | 销售部 | | 1 | A | 19 | 200 | 203 | 财政部 | | 2 | B | 26 | 201 | 200 | 人事部 | | 2 | B | 26 | 201 | 201 | 技术部 | | 2 | B | 26 | 201 | 202 | 销售部 | | 2 | B | 26 | 201 | 203 | 财政部 | | 3 | C | 30 | 201 | 200 | 人事部 | | 3 | C | 30 | 201 | 201 | 技术部 | | 3 | C | 30 | 201 | 202 | 销售部 | | 3 | C | 30 | 201 | 203 | 财政部 | | 4 | D | 24 | 202 | 200 | 人事部 | | 4 | D | 24 | 202 | 201 | 技术部 | | 4 | D | 24 | 202 | 202 | 销售部 | | 4 | D | 24 | 202 | 203 | 财政部 | | 5 | E | 20 | 200 | 200 | 人事部 | | 5 | E | 20 | 200 | 201 | 技术部 | | 5 | E | 20 | 200 | 202 | 销售部 | | 5 | E | 20 | 200 | 203 | 财政部 | | 6 | F | 38 | 204 | 200 | 人事部 | | 6 | F | 38 | 204 | 201 | 技术部 | | 6 | F | 38 | 204 | 202 | 销售部 | | 6 | F | 38 | 204 | 203 | 财政部 | +--------+----------+------+---------+---------+-----------+ 1. 笛卡尔积查询 ) \\-- 查询两张表中都有的关联数据,相当于利用条件从笛卡尔积结果中筛选出了正确的结果。 select \\* from employee,department where employee.dept\\_id = department.dept\\_id; --select \\* from employee inner join department on employee.dept\\_id = department.dept\\_id; +--------+----------+------+---------+---------+-----------+ | emp\\_id | emp\\_name | age | dept\\_id | dept\\_id | dept\\_name | +--------+----------+------+---------+---------+-----------+ | 1 | A | 19 | 200 | 200 | 人事部 | | 2 | B | 26 | 201 | 201 | 技术部 | | 3 | C | 30 | 201 | 201 | 技术部 | | 4 | D | 24 | 202 | 202 | 销售部 | | 5 | E | 20 | 200 | 200 | 人事部 | +--------+----------+------+---------+---------+-----------+ 2. 内连接 ) \\--（1）左外连接：在内连接的基础上增加左边有右边没有的结果 select \\* from employee left join department on employee.dept\\_id = department.dept\\_id; +--------+----------+------+---------+---------+-----------+ | emp\\_id | emp\\_name | age | dept\\_id | dept\\_id | dept\\_name | +--------+----------+------+---------+---------+-----------+ | 1 | A | 19 | 200 | 200 | 人事部 | | 5 | E | 20 | 200 | 200 | 人事部 | | 2 | B | 26 | 201 | 201 | 技术部 | | 3 | C | 30 | 201 | 201 | 技术部 | | 4 | D | 24 | 202 | 202 | 销售部 | | 6 | F | 38 | 204 | NULL | NULL | +--------+----------+------+---------+---------+-----------+ --（2）右外连接：在内连接的基础上增加右边有左边没有的结果 select \\* from employee RIGHT JOIN department on employee.dept\\_id = department.dept\\_id; +--------+----------+------+---------+---------+-----------+ | emp\\_id | emp\\_name | age | dept\\_id | dept\\_id | dept\\_name | +--------+----------+------+---------+---------+-----------+ | 1 | A | 19 | 200 | 200 | 人事部 | | 2 | B | 26 | 201 | 201 | 技术部 | | 3 | C | 30 | 201 | 201 | 技术部 | | 4 | D | 24 | 202 | 202 | 销售部 | | 5 | E | 20 | 200 | 200 | 人事部 | | NULL | NULL | NULL | NULL | 203 | 财政部 | +--------+----------+------+---------+---------+-----------+ --（3）全外连接：在内连接的基础上增加左边有右边没有的和右边有左边没有的结果 -- mysql不支持全外连接 full JOIN -- mysql可以使用此种方式间接实现全外连接 select \\* from employee RIGHT JOIN department on employee.dept\\_id = department.dept\\_id UNION select \\* from employee LEFT JOIN department on employee.dept\\_id = department.dept\\_id; +--------+----------+------+---------+---------+-----------+ | emp\\_id | emp\\_name | age | dept\\_id | dept\\_id | dept\\_name | +--------+----------+------+---------+---------+-----------+ | 1 | A | 19 | 200 | 200 | 人事部 | | 2 | B | 26 | 201 | 201 | 技术部 | | 3 | C | 30 | 201 | 201 | 技术部 | | 4 | D | 24 | 202 | 202 | 销售部 | | 5 | E | 20 | 200 | 200 | 人事部 | | NULL | NULL | NULL | NULL | 203 | 财政部 | | 6 | F | 38 | 204 | NULL | NULL | +--------+----------+------+---------+---------+-----------+ -- 注意 union与union all的区别：union会去掉相同的纪录 3. 外连接 多表查询之复合条件连接查询) \\-- 查询员工年龄大于等于25岁的部门 SELECT DISTINCT department.dept\\_name FROM employee,department WHERE employee.dept\\_id = department.dept\\_id AND age&gt;25; --以内连接的方式查询employee和department表，并且以age字段的升序方式显示 select employee.emp\\_id,employee.emp\\_name,employee.age,department.dept\\_name from employee,department where employee.dept\\_id = department.dept\\_id order by age asc; View Code 多表查询之子查询) \\-- 子查询是将一个查询语句嵌套在另一个查询语句中。 -- 内层查询语句的查询结果，可以为外层查询语句提供查询条件。 -- 子查询中可以包含：IN、NOT IN、ANY、ALL、EXISTS 和 NOT EXISTS等关键字 -- 还可以包含比较运算符：= 、 !=、&gt; 、&lt;等 -- 1. 带IN关键字的子查询 ---查询employee表，但dept\\_id必须在department表中出现过 select \\* from employee where dept\\_id IN (select dept\\_id from department); +--------+----------+------+---------+ | emp\\_id | emp\\_name | age | dept\\_id | +--------+----------+------+---------+ | 1 | A | 19 | 200 | | 2 | B | 26 | 201 | | 3 | C | 30 | 201 | | 4 | D | 24 | 202 | | 5 | E | 20 | 200 | +--------+----------+------+---------+ 5 rows in set (0.01 sec) -- 2. 带比较运算符的子查询 -- =、!=、&gt;、&gt;=、&lt;、&lt;=、&lt;&gt; -- 查询员工年龄大于等于25岁的部门 select dept\\_id,dept\\_name from department where dept\\_id IN (select DISTINCT dept\\_id from employee where age&gt;=25); -- 3. 带EXISTS关键字的子查询 -- EXISTS关字键字表示存在。在使用EXISTS关键字时，内层查询语句不返回查询的记录。 -- 而是返回一个真假值。Ture或False -- 当返回Ture时，外层查询语句将进行查询；当返回值为False时，外层查询语句不进行查询 select \\* from employee WHERE EXISTS (SELECT dept\\_name from department where dept\\_id=203); --department表中存在dept\\_id=203，Ture select \\* from employee WHERE EXISTS (SELECT dept\\_name from department where dept\\_id=205); -- Empty set (0.00 sec) ps: create table t1(select \\* from t2); View Code","categories":[{"name":"SQL","slug":"sql","permalink":"https://topone233.github.io/categories/sql/"}],"tags":[{"name":"SQL","slug":"sql","permalink":"https://topone233.github.io/tags/sql/"}]},{"title":"我的写作工具","slug":"我的写作工具","date":"2020-09-03T12:22:56.040Z","updated":"2020-09-07T14:19:01.729Z","comments":true,"path":"2020/09/03/我的写作工具/","link":"","permalink":"https://topone233.github.io/2020/09/03/%E6%88%91%E7%9A%84%E5%86%99%E4%BD%9C%E5%B7%A5%E5%85%B7/","excerpt":"","text":"写作工具：Typora Markdown 写作工具 下载链接： Typora官网：https://typora.io/ 自用：0.9.89版本官网安装包（蓝奏云）：https://wwe.lanzous.com/icxyogbrykd 图片上传工具：Picgo 搭配Typora，效率神器 下载链接： Typora官网：https://molunerfinn.com/PicGo 自用：2.2.2版本官网安装包（蓝奏云）：https://wwe.lanzous.com/ie0iWgbryha 免费图床： SM.MS 5GB免费空间、Picgo有插件支持 官网：https://sm.ms/ 第一次使用要先注册账户 体验了一阵感觉差强人意。改用码云了。 Gitee 码云 免费、速度可以、稳定、Picgo有插件支持 教程：https://www.jianshu.com/p/b69950a49ae2 Typora + Picgo + SM图床 设置： Typora： Ctrl + 逗号 进入偏好设置 -&gt; 图像 插入图片时 -&gt; 上传图片 -&gt; 勾选前两项 上传服务设定 -&gt; PicGo（app）-&gt; PicGo本地安装路径 打开Picgo -&gt; 打开配置文件 -&gt; 修改server端口号为：36677 插件中心 -&gt; 搜索：smms-user -&gt; 安装 到SM.MS官网 -&gt; User -&gt; Dashboard -&gt; API Token -&gt; 生成并复制Token 回到Picgo -&gt; 粘贴到刚才的插件 配置plugin-smms-user -&gt; 配置uploder-smms-user 上传区选择SM.MS登录用户 重启Picgo 回到第三步Typora页面 -&gt; 验证图片上传路径 -&gt; 验证成功","categories":[{"name":"工具","slug":"工具","permalink":"https://topone233.github.io/categories/%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"工具","slug":"工具","permalink":"https://topone233.github.io/tags/%E5%B7%A5%E5%85%B7/"},{"name":"配置","slug":"配置","permalink":"https://topone233.github.io/tags/%E9%85%8D%E7%BD%AE/"}]},{"title":"SQL Or NoSQL","slug":"SQL Or NoSQL","date":"2020-09-03T11:43:12.624Z","updated":"2020-09-15T08:30:56.449Z","comments":true,"path":"2020/09/03/SQL Or NoSQL/","link":"","permalink":"https://topone233.github.io/2020/09/03/SQL%20Or%20NoSQL/","excerpt":"","text":"原文地址:https://www.cnblogs.com/xrq730/p/11039384.html 前言你是否在为系统的数据库来一波大流量就几乎打满 CPU，日常 CPU 居高不下烦恼？你是否在各种 NoSql 间纠结不定，到底该选用那种最好？今天的你就是昨天的我，这也是写这篇文章的初衷。 这篇文章是我好几个月来一直想写的一篇文章，也是一直想学习的一个内容，作为互联网从业人员，我们要知道关系型数据库（MySql、Oracle）无法满足我们对存储的所有要求，因此对底层存储的选型，对每种存储引擎的理解非常重要。同时也由于过去一段时间的工作经历，对这块有了一些更多的思考，想通过自己的总结把这块写出来分享给大家。 结构化数据、非结构化数据与半结构化数据文章的开始，聊一下结构化数据、非结构化数据与半结构化数据，因为数据特点的不同，将在技术上直接影响存储引擎的选型。 结构化数据根据定义结构化数据指的是由二维表结构来逻辑表达和实现的数据，严格遵循数据格式与长度规范，也称作为行数据，特点为：数据以行为单位，一行数据表示一个实体的信息，每一行数据的属性是相同的。例如： 因此关系型数据库完美契合结构化数据的特点，关系型数据库也是关系型数据最主要的存储与管理引擎。 非结构化数据指的是数据结构不规则或不完整，没有任何预定义的数据模型，不方便用二维逻辑表来表现的数据，例如办公文档（Word）、文本、图片、HTML、各类报表、视频音频等。 半结构化数据介于结构化与非结构化数据之间的数据就是半结构化数据了，它是结构化数据的一种形式，虽然不符合二维逻辑这种数据模型结构，但是包含相关标记，用来分割语义元素以及对记录和字段进行分层。常见的半结构化数据有 XML 和 JSON，例如： &lt;person&gt; &lt;name&gt;张三&lt;/name&gt; &lt;age&gt;18&lt;/age&gt; &lt;phone&gt;12345&lt;/phone&gt; &lt;/person&gt;这种结构也被成为自描述的结构。 以关系型数据库的方式做存储的架构演进首先，我们看一下使用关系型数据库的方式，企业一个系统发展的几个阶段的架构演进（由于本文写的是 Sql 与 NoSql，因此只以存储方式作为切入点，不会涉及类似 MQ、ZK 这些中间件内容）： 阶段一：企业刚发展的阶段，最简单，一个应用服务器配一个关系型数据库，每次读写数据库。 阶段二：无论是使用 MySQL 还是 Oracle 还是别的关系型数据库，数据库通常不会先成为性能瓶颈，通常随着企业规模的扩大，一台应用服务器扛不住上游过来的流量且一台应用服务器会产生单点故障的问题，因此加应用服务器并且在流量入口使用 Nginx 做一层负载均衡，保证把流量均匀打到应用服务器上。 阶段三：随着企业规模的继续扩大，此时由于读写都在同一个数据库上，数据库性能出现一定的瓶颈，此时简单地做一层读写分离，每次写主库，读备库，主备库之间通过 binlog 同步数据，就能很大程度上解决这个阶段的数据库性能问题 阶段四：企业发展越来越好了，业务越来越大了，做了读写分离数据库压力还是越来越大，这时候怎么办呢，一台数据库扛不住，那我们就分几台吧，做分库分表，对表做垂直拆分，对库做水平拆分。以扩数据库为例，扩出两台数据库，以一定的单号（例如交易单号），以一定的规则（例如取模），交易单号对 2 取模为 0 的丢到数据库 1 去，交易单号对 2 取模为 1 的丢到数据库 2 去，通过这样的方式将写数据库的流量均分到两台数据库上。一般分库分表会使用 Shard 的方式，通过一个中间件，便于连接管理、数据监控且客户端无需感知数据库 ip 关系型数据库的优点上面的方式，看似可以解决问题（实际上确实也能解决很多问题），正常对关系型数据库做一下读写分离 + 分库分表，支撑个 1W + 的读写 QPS 还是问题不大的。但是受限于关系型数据库本身，这套架构方案依然有着明显的不足，下面对利用关系型数据库方式做存储的方案的优点先进行一下分析，后一部分再分析一下缺点，对某个技术的优缺点的充分理解是技术选型的前提。 易理解 因为行 + 列的二维表逻辑是非常贴近逻辑世界的一个概念，关系模型相对网状、层次等其他模型更加容易被理解 操作方便 通用的 SQL 语言使得操作关系型数据库非常方便，支持 join 等复杂查询，Sql + 二维关系是关系型数据库最无可比拟的优点，这种易用性非常贴近开发者 数据一致性 支持 ACID 特性，可以维护数据之间的一致性，这是使用数据库非常重要的一个理由之一，例如同银行转账，张三转给李四 100 元钱，张三扣 100 元，李四加 100 元，而且必须同时成功或者同时失败，否则就会造成用户的资损 数据稳定 数据持久化到磁盘，没有丢失数据风险，支持海量数据存储 服务稳定 最常用的关系型数据库产品 MySql、Oracle 服务器性能卓越，服务稳定，通常很少出现宕机异常 关系型数据库的缺点紧接着的，我们看一下关系型数据库的缺点，也是比较明显的。 高并发下 IO 压力大 数据按行存储，即使只针对其中某一列进行运算，也会将整行数据从存储设备中读入内存，导致 IO 较高 为维护索引付出的代价大 为了提供丰富的查询能力，通常热点表都会有多个二级索引，一旦有了二级索引，数据的新增必然伴随着所有二级索引的新增，数据的更新也必然伴随着所有二级索引的更新，这不可避免地降低了关系型数据库的读写能力，且索引越多读写能力越差。有机会的话可以看一下自己公司的数据库，除了数据文件不可避免地占空间外，索引占的空间其实也并不少 为维护数据一致性付出的代价大 数据一致性是关系型数据库的核心，但是同样为了维护数据一致性的代价也是非常大的。我们都知道 SQL 标准为事务定义了不同的隔离级别，从低到高依次是读未提交、读已提交、可重复度、串行化，事务隔离级别越低，可能出现的并发异常越多，但是通常而言能提供的并发能力越强。那么为了保证事务一致性，数据库就需要提供并发控制与故障恢复两种技术，前者用于减少并发异常，后者可以在系统异常的时候保证事务与数据库状态不会被破坏。对于并发控制，其核心思想就是加锁，无论是乐观锁还是悲观锁，只要提供的隔离级别越高，那么读写性能必然越差 水平扩展后带来的种种问题难处理 前文提过，随着企业规模扩大，一种方式是对数据库做分库，做了分库之后，数据迁移（1 个库的数据按照一定规则打到 2 个库中）、跨库 join（订单数据里有用户数据，两条数据不在同一个库中）、分布式事务处理都是需要考虑的问题，尤其是分布式事务处理，业界当前都没有特别好的解决方案 表结构扩展不方便 由于数据库存储的是结构化数据，因此表结构 schema 是固定的，扩展不方便，如果需要修改表结构，需要执行 DDL（data definition language）语句修改，修改期间会导致锁表，部分服务不可用 全文搜索功能弱 例如 like “% 中国真伟大 %”，只能搜索到 “2019 年中国真伟大，爱祖国”，无法搜索到 “中国真是太伟大了” 这样的文本，即不具备分词能力，且 like 查询在 “% 中国真伟大” 这样的搜索条件下，无法命中索引，将会导致查询效率大大降低 写了这么多，我的理解核心还是前三点，它反映出的一个问题是关系型数据库在高并发下的能力是有瓶颈的，尤其是写入 / 更新频繁的情况下，出现瓶颈的结果就是数据库 CPU 高、Sql 执行慢、客户端报数据库连接池不够等错误，因此例如万人秒杀这种场景，我们绝对不可能通过数据库直接去扣减库存。 可能有朋友说，数据库在高并发下的能力有瓶颈，我公司有钱，加 CPU、换固态硬盘、继续买服务器加数据库做分库不就好了，问题是这是一种性价比非常低的方式，花 1000 万达到的效果，换其他方式可能 100 万就达到了，不考虑人员、服务器投入产出比的 Leader 就是个不合格的 Leader，且关系型数据库的方式，受限于它本身的特点，可能花了钱都未必能达到想要的效果。至于什么是花 100 万就能达到花 1000 万效果的方式呢？可以继续往下看，这就是我们要说的 NoSql。 结合 NoSql 的方式做存储的架构演进像上文分析的，数据库作为一种关系型数据的存储引擎，存储的是关系型数据，它有优点，同时也有明显的缺点，因此通常在企业规模不断扩大的情况下，不会一味指望通过增强数据库的能力来解决数据存储问题，而是会引入其他存储，也就是我们说的 NoSql。 NoSql 的全称为 Not Only SQL，泛指非关系型数据库，是对关系型数据库的一种补充，特别注意补充这两个字，这意味着 NoSql 与关系型数据库并不是对立关系，二者各有优劣，取长补短，在合适的场景下选择合适的存储引擎才是正确的做法。 比较简单的 NoSql 就是缓存： 针对那些读远多于写的数据，引入一层缓存，每次读从缓存中读取，缓存中读取不到，再去数据库中取，取完之后再写入到缓存，对数据做好失效机制通常就没有大问题了。通常来说，缓存是性能优化的第一选择也是见效最明显的方案。 但是，缓存通常都是 KV 型存储且容量有限（基于内存），无法解决所有问题，于是再进一步的优化，我们继续引入其他 NoSql： 数据库、缓存与其他 NoSql 并行工作，充分发挥每种 NoSql 的特点。当然 NoSql 在性能方面大大优于关系挺数据库的同时，往往也伴随着一些特性的缺失，比较常见的就是事务功能的缺失。 下面看一下常用的 NoSql 及他们的代表产品，并对每种 NoSql 的优缺点和适用场景做一下分析，便于熟悉每种 NoSql 的特点，方便技术选型。 KV 型 NoSql（Redis）KV 型 NoSql 顾名思义就是以键值对形式存储的非关系型数据库，是最简单、最容易理解也是大家最熟悉的一种 NoSql，因此比较快地带过。Redis、MemCache 是其中的代表，Redis 又是 KV 型 NoSql 中应用最广泛的 NoSql，KV 型数据库以 Redis 为例，最大的优点我总结下来就两点： 数据基于内存，读写效率高 KV 型数据，时间复杂度为 O(1)，查询速度快 因此，KV 型 NoSql 最大的优点就是高性能，利用 Redis 自带的 BenchMark 做基准测试，TPS 可达到 10 万的级别，性能非常强劲。同样的 Redis 也有所有 KV 型 NoSql 都有的比较明显的缺点： 只能根据 K 查 V，无法根据 V 查 K 查询方式单一，只有 KV 的方式，不支持条件查询，多条件查询唯一的做法就是数据冗余，但这会极大的浪费存储空间 内存是有限的，无法支持海量数据存储 同样的，由于 KV 型 NoSql 的存储是基于内存的，会有丢失数据的风险 综上所述，KV 型 NoSql 最合适的场景就是缓存的场景： 读远多于写 读取能力强 没有持久化的需求，可以容忍数据丢失，反正丢了再查询一把写入就是了 例如根据用户 id 查询用户信息，每次根据用户 id 去缓存中查询一把，查到数据直接返回，查不到去关系型数据库里面根据 id 查询一把数据写到缓存中去。 搜索型 NoSql（ElasticSearch）传统关系型数据库主要通过索引来达到快速查询的目的，但是在全文搜索的场景下，索引是无能为力的，like 查询一来无法满足所有模糊匹配需求，二来使用限制太大且使用不当容易造成慢查询，搜索型 NoSql 的诞生正是为了解决关系型数据库全文搜索能力较弱的问题，ElasticSearch 是搜索型 NoSql 的代表产品。 全文搜索的原理是倒排索引，我们看一下什么是倒排索引。要说倒排索引我们先看下什么是正排索引，传统的正排索引是文档 –&gt; 关键字的映射，例如 “Tom is my friend” 这句话，会将其切分为 “Tom”、”is”、”my”、”friend” 四个单词，在搜索的时候对文档进行扫描，符合条件的查出来。这种方式原理非常简单，但是由于其检索效率太低，基本没什么实用价值。 倒排索引则完全相反，它是关键字 –&gt; 文档的映射，我用张表格展示一下就比较清楚了： 意思是我现在这里有四个短句： “Tom is Tom” “Tom is my friend” “Thank you, Betty” “Tom is Betty’s husband” 搜索引擎会根据一定的切分规则将这句话切成 N 个关键字，并以关键字的维度维护关键字在每个文本中的出现次数。这样下次搜索 “Tom” 的时候，由于 Tom 这个词语在 “Tom is Tom”、”Tom is my friend”、”Tom is Betty’s husband”三句话中都有出现，因此这三条记录都会被检索出来，且由于”Tom is Tom”这句话中”Tom”出现了 2 次，因此这条记录对”Tom” 这个单词的匹配度最高，最先展示。这就是搜索引擎倒排索引的基本原理，假设某个关键字在某个文档中出现，那么倒排索引中有两部分内容： 文档 ID 在该文档中出现的位置情况 可以举一反三，我们搜索 “Betty Tom” 这两个词语也是一样，搜索引擎将 “Betty Tom” 切分为 “Tom”、”Betty” 两个单词，根据开发者指定的满足率，比如满足率 = 50%，那么只要记录中出现了两个单词之一的记录都会被检索出来，再按照匹配度进行展示。 搜索型 NoSql 以 ElasticSearch 为例，它的优点为： 支持分词场景、全文搜索，这是区别于关系型数据库最大特点 支持条件查询，支持聚合操作，类似关系型数据库的 Group By，但是功能更加强大，适合做数据分析 数据写文件无丢失风险，在集群环境下可以方便横向扩展，可承载 PB 级别的数据 高可用，自动发现新的或者失败的节点，重组和重新平衡数据，确保数据是安全和可访问的 同样，ElasticSearch 也有比较明显的缺点： 性能全靠内存来顶，也是使用的时候最需要注意的点，非常吃硬件资源、吃内存，大数据量下 64G + SSD 基本是标配，算得上是数据库中的爱马仕了。为什么要专门提一下内存呢，因为内存这个东西是很值钱的，相同的配置多一倍内存，一个月差不多就要多花几百块钱，至于 ElasticSearch 内存用在什么地方，大概有如下这些： Indexing Buffer—-ElasticSearch 基于 Luence，Lucene 的倒排索引是先在内存里生成，然后定期以 Segment File 的方式刷磁盘的，每个 Segment File 实际就是一个完整的倒排索引 Segment Memory—- 倒排索引前面说过是基于关键字的，Lucene 在 4.0 后会将所有关键字以 FST 这种数据结构的方式将所有关键字在启动的时候全量加载到内存，加快查询速度，官方建议至少留系统一半内存给 Lucene 各类缓存 —-Filter Cache、Field Cache、Indexing Cache 等，用于提升查询分析性能，例如 Filter Cache 用于缓存使用过的 Filter 的结果集 Cluter State Buffer—-ElasticSearch 被设计为每个 Node 都可以响应用户请求，因此每个 Node 的内存中都包含有一份集群状态的拷贝，一个规模很大的集群这个状态信息可能会非常大 读写之间有延迟，写入的数据差不多 1s 样子会被读取到，这也正常，写入的时候自动加入这么多索引肯定影响性能 数据结构灵活性不高，ElasticSearch 这个东西，字段一旦建立就没法修改类型了，假如建立的数据表某个字段没有加全文索引，想加上，那么只能把整个表删了再重建 因此，搜索型 NoSql 最适用的场景就是有条件搜索尤其是全文搜索的场景，作为关系型数据库的一种替代方案。 另外，搜索型数据库还有一种特别重要的应用场景。我们可以想，一旦对数据库做了分库分表后，原来可以在单表中做的聚合操作、统计操作是否统统失效？例如我把订单表分 16 个库，1024 张表，那么订单数据就散落在 1024 张表中，我想要统计昨天浙江省单笔成交金额最高的订单是哪笔如何做？我想要把昨天的所有订单按照时间排序分页展示如何做？这就是搜索型 NoSql 的另一大作用了，我们可以把分表之后的数据统一打在搜索型 NoSql 中，利用搜索型 NoSql 的搜索与聚合能力完成对全量数据的查询。 至于为什么把它放在 KV 型 NoSql 后面作为第二个写呢，因为通常搜索型 NoSql 也会作为一层前置缓存，来对关系型数据库进行保护。 列式 NoSql（HBase）列式 NoSql，大数据时代最具代表性的技术之一了，以 HBase 为代表。 列式 NoSql 是基于列式存储的，那么什么是列式存储呢，列式 NoSql 和关系型数据库一样都有主键的概念，区别在于关系型数据库是按照行组织的数据： 看到每行有 name、phone、address 三个字段，这是行式存储的方式，且可以观察 id = 2 的这条数据，即使 phone 字段没有，它也是占空间的。 列式存储完全是另一种方式，它是按每一列进行组织的数据： 这么做有什么好处呢？大致有以下几点： 查询时只有指定的列会被读取，不会读取所有列 存储上节约空间，Null 值不会被存储，一列中有时候会有很多重复数据（尤其是枚举数据，性别、状态等），这类数据可压缩，行式数据库压缩率通常在 3:15:1 之间，列式数据库的压缩率一般在 8:130:1 左右 列数据被组织到一起，一次磁盘 IO 可以将一列数据一次性读取到内存中 第二点说到了数据压缩，什么意思呢，以比较常见的字典表压缩方式举例： 自己看图理解一下，应该就懂了。 接着继续讲讲优缺点，列式 NoSql，以 HBase 为代表的，优点为： 海量数据无限存储，PB 级别数据随便存，底层基于 HDFS（Hadoop 文件系统），数据持久化 读写性能好，只要没有滥用造成数据热点，读写基本随便玩 横向扩展在关系型数据库及非关系型数据库中都是最方便的之一，只需要添加新机器就可以实现数据容量的线性增长，且可用在廉价服务器上，节省成本 本身没有单点故障，可用性高 可存储结构化或者半结构化的数据 列数理论上无限，HBase 本身只对列族数量有要求，建议 1~3 个 说了这么多 HBase 的优点，又到了说 HBase 缺点的时候了： HBase 是 Hadoop 生态的一部分，因此它本身是一款比较重的产品，依赖很多 Hadoop 组件，数据规模不大没必要用，运维还是有点复杂的 KV 式，不支持条件查询，或者说条件查询非常非常弱吧，HBase 在 Scan 扫描一批数据的情况下还是提供了前缀匹配这种 API 的，条件查询除非定义多个 RowKey 做数据冗余 不支持分页查询，因为统计不了数据总数 因此 HBase 比较适用于那种 KV 型的且未来无法预估数据增长量的场景，另外 HBase 使用还是需要一定的经验，主要体现在 RowKey 的设计上。 文档型 NoSql（MongoDB）坦白讲，根据我的工作经历，文档型 NoSql 我只有比较浅的使用经验，因此这部分只能结合之前的使用与网上的文章大致给大家介绍一下。 什么是文档型 NoSql 呢，文档型 NoSql 指的是将半结构化数据存储为文档的一种 NoSql，文档型 NoSql 通常以 JSON 或者 XML 格式存储数据，因此文档型 NoSql 是没有 Schema 的，由于没有 Schema 的特性，我们可以随意地存储与读取数据，因此文档型 NoSql 的出现是解决关系型数据库表结构扩展不方便的问题的。 MongoDB 是文档型 NoSql 的代表产品，同时也是所有 NoSql 产品中的明星产品之一，因此这里以 MongoDB 为例。按我的理解，作为文档型 NoSql，MongoDB 是一款完全和关系型数据库对标的产品，就我们从存储上来看： 看到，关系型数据库是按部就班地每个字段一列存，在 MongDB 里面就是一个 JSON 字符串存储。关系型数据可以为 name、phone 建立索引，MongoDB 使用 createIndex 命令一样可以为列建立索引，建立索引之后可以大大提升查询效率。其他方面而言，就大的基本概念，二者之间基本也是类似的： 因此，对于 MongDB，我们只要理解成一个 Free-Schema 的关系型数据库就完事了，它的优缺点比较一目了然，优点： 没有预定义的字段，扩展字段容易 相较于关系型数据库，读写性能优越，命中二级索引的查询不会比关系型数据库慢，对于非索引字段的查询则是全面胜出 缺点在于： 不支持事务操作，虽然 Mongodb4.0 之后宣称支持事务，但是效果待观测 多表之间的关联查询不支持（虽然有嵌入文档的方式），join 查询还是需要多次操作 空间占用较大，这个是 MongDB 的设计问题，空间预分配机制 + 删除数据后空间不释放，只有用 db.repairDatabase() 去修复才能释放 目前没发现 MongoDB 有关系型数据库例如 MySql 的 Navicat 这种成熟的运维工具 总而言之，MongDB 的使用场景很大程度上可以对标关系型数据库，但是比较适合处理那些没有 join、没有强一致性要求且表 Schema 会常变化的数据。 总结：数据库与 NoSql 及各种 NoSql 间的对比最后一部分，做一个总结，本文归根到底是两个话题： 何时选用关系型数据库，何时选用非关系型数据库 选用非关系型数据库，使用哪种非关系型数据库 首先是第一个话题，关系型数据库与非关系型数据库的选择，在我理解里面无非就是两点考虑： 第一点，不多解释应该都理解，非关系型数据库都是通过牺牲了 ACID 特性来获取更高的性能的，假设两张表之间有比较强的一致性需求，那么这类数据是不适合放在非关系型数据库中的。 第二点，核心数据不走非关系型数据库，例如用户表、订单表，但是这有一个前提，就是这一类核心数据会有多种查询模式，例如用户表有 ABCD 四个字段，可能根据 AB 查，可能根据 AC 查，可能根据 D 查，假设核心数据，但是就是个 KV 形式，比如用户的聊天记录，那么 HBase 一存就完事了。 这几年的工作经验来看，非核心数据尤其是日志、流水一类中间数据千万不要写在关系型数据库中，这一类数据通常有两个特点： 写远高于读 写入量巨大 一旦使用关系型数据库作为存储引擎，将大大降低关系型数据库的能力，正常读写 QPS 不高的核心服务会受这一类数据读写的拖累。 接着是第二个问题，如果我们使用非关系型数据库作为存储引擎，那么如何选型？其实上面的文章基本都写了，这里只是做一个总结（所有的缺点都不会体现事务这个点，因为这是所有 NoSql 相比关系型数据库共有的一个问题）： 但是这里特别说明，选型一定要结合实际情况而不是照本宣科，比如： 企业发展之初，明明一个关系型数据库就能搞定且支撑一年的架构，搞一套大而全的技术方案出来 有一些数据条件查询多，更适合使用 ElasticSearch 做存储降低关系型数据库压力，但是公司成本有限，这种情况下这类数据可以尝试继续使用关系型数据库做存储 有一类数据格式简单，就是个 KV 类型且增长量大，但是公司没有 HBase 这方面的人才，运维上可能会有一定难度，出于实际情况考虑，可先用关系型数据库顶一阵子 所以，如果不考虑实际情况，虽然合适有些存储引擎更加合适，但是强行使用反而适得其反，总而言之，适合自己的才是最好的。","categories":[{"name":"NoSQL","slug":"nosql","permalink":"https://topone233.github.io/categories/nosql/"}],"tags":[{"name":"SQL","slug":"sql","permalink":"https://topone233.github.io/tags/sql/"},{"name":"NoSQL","slug":"nosql","permalink":"https://topone233.github.io/tags/nosql/"}]},{"title":"Spring 事务管理","slug":"Spring 事务管理","date":"2020-09-02T03:25:57.245Z","updated":"2020-09-07T14:20:50.377Z","comments":true,"path":"2020/09/02/Spring 事务管理/","link":"","permalink":"https://topone233.github.io/2020/09/02/Spring%20%E4%BA%8B%E5%8A%A1%E7%AE%A1%E7%90%86/","excerpt":"","text":"在数据库操作中事务管理是一个重要的概念，例如银行转账。 Spring的事务管理简化了传统的数据库事务管理流程，提高了开发效率。 1.编程式事务管理 在代码中显示调用beginTransaction、commit、rollback 等与事务处理相关的方法，这就是编程式事务管理。当只有少数事务操作时，编程式事务管理才比较合适。 基于底层API的编程式事务管理 基于 TransactionTemplate 的编程式事务管理 2.声明式事务管理 Spring的声明式事务管理是通过AOP技术实现的事务管理，其本质是对方法前后进行拦截，然后在目标方法开始之前创建或加入一个事务，在执行完目标方法之后根据执行情况提交或回滚事务。 声明式事务管理最大的优点是不需要通过编程的方式管理事务，因而不需要在业务逻辑代码中掺杂事务处理的代码，只需相关的事务规则声明便可以将事务规则应用到业务逻辑中。 使用声明式事务管理不仅因为其简单，更主要的是可以使得纯业务代码不被污染，极大的方便了后期的代码维护。 与编程式事务管理相比，唯一不足的是：最细粒度只能作用到方法级别，无法像编程式那样可以作用到代码块级别。（不过可以通过变通的方法解决，比如将需要进行事务处理的代码块独立为方法等）。 Spring的声明式事务管理通过两种方式实现：XML、@Transactional 注解 2.1 基于XML创建Dao层 package com.statement.dao; public interface TestDao { public int save(String sql, Object param[]); public int delete(String sql, Object param[]); }package com.statement.dao; @Repository(&quot;TestDao&quot;) public class TestDaoImpl implements TestDao { @Autowired private JdbcTemplate jdbcTemplate; @Override public int save(String sql, Object[] param) { return jdbcTemplate.update(sql, param); } @Override public int delete(String sql, Object[] param) { return jdbcTemplate.update(sql, param); } }创建Service层，依赖注入数据访问层。 package com.statement.service; public interface TestService { public int save(String sql, Object param[]); public int delete(String sql, Object param[]); }package com.statement.service; @Service(&quot;testService&quot;) public class TestServiceImpl implements TestService { @Autowired private TestDao testDao; @Override public int save(String sql, Object[] param) { return testDao.save(sql, param); } @Override public int delete(String sql, Object[] param) { return testDao.delete(sql, param); } }创建Controller层，依赖注入Service层。 package com.statement.controller; @Controller(&quot;statementController&quot;) public class StatementController { @Autowired private TestService testService; public String test() { String message=&quot;&quot;; String deleteSql=&quot;delete from user&quot;; String saveSql=&quot;insert into user values(?,?,?)&quot;; Object param[]={1,&quot;chen&quot;,&quot;男&quot;}; try{ testService.delete(deletSql, null); testService.save(saveSql, param); testService.save(saveSql, param); }catch(Exception e) { message=&quot;主键重复，事务回滚！&quot;; e.printStackTrace(); } return message; } }创建配置文件 &lt;!-- 为数据源添加事务管理器 --&gt; &lt;bean id=&quot;txManager&quot; class=&quot;org.springframework.jdbc.datasource.DataSourceTransactionManager&quot;&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot;/&gt; &lt;/bean&gt; &lt;!-- 编写通知声明事务 --&gt; &lt;tx:advice id=&quot;myAdvice&quot; transaction-manager=&quot;txManager&quot;&gt; &lt;tx:attributes&gt; &lt;!-- *表示任意方法 --&gt; &lt;tx:method name=&quot;*&quot;/&gt; &lt;/tx:attributes&gt; &lt;/tx:advice&gt; &lt;!-- 编写AOP，让Spring自动对目标对象生成代理，需要使用AspectJ的表达式 --&gt; &lt;aop:config&gt; &lt;!-- 定义切入点 --&gt; &lt;aop:pointcut expression=&quot;execution(* com.statement.sservice.*.*())&quot; id=&quot;txPointCut&quot;/&gt; &lt;!-- 切面：将切入点与通知关联 --&gt; &lt;aop:advisor advice-ref=&quot;myAdvice&quot; pointcut-ref=&quot;txPointCut&quot;/&gt; &lt;/aop:config&gt;创建测试类 package com.statement.test; public class Test { public static void main(String[] args) { ApplicationContext appCon=new ClassPathXmlApplicationContext(&quot;/com/statement/applicationContext.xml&quot;); StatementController ct=(StatementController)appCon.getBean(&quot;statementController&quot;); String result=ct.test(); System.out.println(result); } } 运行结果： 主键重复，事务回滚！2.2 基于@Transactional@Transactional 可以作用于接口、接口方法、类、类的方法上。 当作用于类上时，该类的所有public方法都将具有该类型的事务属性，同时也可以在方法级别使用该注解来覆盖类级别的定义。 Spring小组不建议在接口或接口方法上使用该注解，因为它只有在使用基于接口的代理时才会生效。 Dao、Service、Controller层相同，仅展示修改的部分代码。 配置文件 &lt;!-- 为数据源添加事务管理器 --&gt; &lt;bean id=&quot;txManager&quot; class=&quot;org.springframework.jdbc.datasource.DataSourceTransactionManager&quot;&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot;/&gt; &lt;/bean&gt; &lt;!-- 为事务管理器注册注解驱动器 --&gt; &lt;tx:annotation-driven transaction-manager=&quot;txManager&quot;/&gt;Spring MVC通常在Service层进行事务管理。 package com.statement.service; @Service(&quot;testService&quot;) @Transactional // 指定这个类需要接受Spring的事务管理 // 只能针对public属性范围内的方法 public class TestServiceImpl implements TestService {","categories":[{"name":"Spring","slug":"spring","permalink":"https://topone233.github.io/categories/spring/"}],"tags":[{"name":"Java","slug":"java","permalink":"https://topone233.github.io/tags/java/"},{"name":"Spring","slug":"spring","permalink":"https://topone233.github.io/tags/spring/"}]},{"title":"Spring AOP","slug":"Spring AOP","date":"2020-08-24T04:05:54.847Z","updated":"2020-09-07T14:21:09.833Z","comments":true,"path":"2020/08/24/Spring AOP/","link":"","permalink":"https://topone233.github.io/2020/08/24/Spring%20AOP/","excerpt":"","text":"1.AOP的概念AOP（Aspect Oriented Programming）面向切面编程，与OOP（Object Oriented Programming，面向对象编程）相辅相成，提供了与OOP不同的抽象软件结构的视角。在OOP中，以类为程序的基本单元，而AOP的基本单元是Aspect（切面）。 尽管OOP可以通过封装、继承达到代码的复用，但仍然有同样的代码分散在各个方法中。AOP采取横向抽取机制，将分散在各个方法中的重复代码提取出来，然后在编译或运行阶段应用到需要执行的地方。这种横向抽取是OOP无法实现的，因为OOP实现的父子关系的纵向复用。AOP不是OOP的替代品，而是补充，两者相辅相成。 1.1 切面Aspect 是指：封装横切到系统功能（如事务处理）的类。 1.2 连接点Joinpoint ：程序运行中的一些时间点，例如：方法的调用、异常的抛出。 1.3 切入点Pointcut ：指需要处理的连接点。Spring AOP中，所有的方法执行都是连接点，而切入点是一个描述信息，修饰连接点。通过切入点确定哪些连接点需要被处理。 1.4 通知Advice ：由切面添加到特定的连接点（满足切入点规则）的一段代码，即在定义好的切入点处所要执行的代码。可以理解为切面开启后切面的方法，通知是切面的具体实现。 根据Spring中通知中目标类方法中的连接点位置，通知可分为6种类型： 1.4.1 环绕通知​ MethodInterceptor 在目标方法执行前、后实施增强，可用于日志记录、事务处理等功能。@Around 1.4.2 前置通知​ MethodBeforeAdvice 在目标方法执行前实施增强，可用于权限管理等功能。@Before 1.4.3 后置返回通知​ AfterReturningAdvice 在目标方法执行成功后实施增强，可用于关闭流、删除临时文件等功能。@AfterReturning 1.4.4 后置（最终）通知​ AfterAdvice 在目标方法执行后实施增强，与后置返回不同的是，不管是否发生异常都要执行，类似于finally。可用于释放资源。@After 1.4.5 异常通知​ ThrowsAdvice 在方法抛出异常后实施增强，可用于处理异常、记录日志等功能。@AfterThrowing 1.4.6 引入通知​ IntroductionInterceptor 在目标类中添加一些新的方法和属性，可用于修改目标类（增强类）。 1.5 引入Introduction ：在不修改代码的前提下，引入可以在运行期为实现类动态的添加自定义的方法和属性 1.6 目标对象Target Object ：指所有被通知的对象。 1.7 代理Proxy ：通知应用到目标对象之后被动态创建的对象。 1.8 织入Weaving ：将切面代码插入到目标对象上，从而生成代理对象的过程。 织入方式： 编译期织入：需要有特殊的Java编译器 类装载期织入：需要有特殊的类装载器 动态代理织入：在运行期为目标类添加通知生成子类的方式。Spring AOP默认采用动态代理织入。 2.动态代理动态代理 Spring AOP中常用JDK和CGLIB两种动态代理技术。 2.1 JDK动态代理JDK动态代理必须借助一个接口才能产生代理对象。对于使用业务接口的类，Spring默认使用JDK动态代理实现AOP。 package dynamic.jdk; public interface TestDao { public void save(); public void modify(); public void delete(); }创建接口实现类作为目标类，在代理类中对其方法进行增强处理。 package dynamic.jdk; public class TestDaoImpl implements TestDao { @Override public void save() { System.out.println(&quot;保存&quot;); } @Override public void modify() { System.out.println(&quot;修改&quot;); } @Override public void delete() { System.out.println(&quot;删除&quot;); } }创建切面类，定义多个通知（增强处理的功能方法）。 package aspect; public class MyAspect { public void check() { System.out.println(&quot;模拟权限控制&quot;); } public void except() { System.out.println(&quot;模拟异常处理&quot;); } public void log() { System.out.println(&quot;模拟日志记录&quot;); } }创建代理类，JDK动态代理中代理类必须实现java.lang.reflect.InvocationHandler接口，并编写代理方法。 package dynamic.jdk; public class JDKDynamicProxy implements InvocationHandler { // 声明目标类接口对象（真实对象） private TestDao testDao; /** * 创建代理的方法，建立代理对象和真实对象的代理关系，并返回代理对象 */ public Object createProxy(TestDao testDao) { this.testDao=testDao; // 类加载器 ClassLoader cld=JDKDynamicProxy.class.getClassLoader(); // 被代理对象实现的所有接口 Class[] clazz=testDao.getClass().getInterFaces(); // 使用代理类进行增强，返回代理后的对象 return Proxy.newProxyInstance(cld, clazz, this); } /** * 代理的逻辑方法，所有动态代理类的方法调用都交给该方法处理 * proxy 是被代理对象 * method 是将要被执行的方法 * args 是执行方法是需要的参数 * return 是返回代理结果 */ @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { // 创建一个切面 MyAspect myAspect=new MyAspect(); // 前置增强 myAspect.check(); myAspect.except(); // 在目标类上调用方法并传入参数，相当于调用testDao中的方法 Object obj=method.invoke(testDao, args); // 后置增强 myAspect.log(); myAspect.monitor(); return obj; } }创建测试类，在main方法中创建代理对象和目标对象，然后从代理对象中获取对目标对象增强后的对象，最后调用该对象的添加、修改、删除方法。 package dynamic.jdk; public class JDKDynamicTest { public static void main(String[] args) { // 创建代理对象 JDKDynamicProxy jdkProxy=new JDKDynamicProxy(); // 创建目标对象 TestDao testDao=new TestDaoImpl(); // 从代理对象中获取增强后的目标对象。该对象是一个被代理的对象，它会进入代理的逻辑方法invoke中 TestDao testDaoAdvice=(TestDao)jdkProxy.createProxy(testDao); // 执行方法 testDaoAdvice.save(); System.out.println(&quot;===============&quot;); testDaoAdvice.modify(); System.out.println(&quot;===============&quot;); testDaoAdvice.delete(); } } 运行结果： 模拟权限控制 模拟异常处理 保存 模拟日志记录 =============== 模拟权限控制 模拟异常处理 修改 模拟日志记录 =============== 模拟权限控制 模拟异常处理 删除 模拟日志记录2.2 CGLIB 动态代理JDK动态代理必须提供接口才能使用，对于没有提供接口的类，只能采用CGLIB动态代理。 CGLIB（Code Generation Library，代码生成库）是一个高性能开源的代码生成库，采用非常底层的字节码技术，对指定的目标类生成一个子类，并对子类进行增强。Spring Core包已经集成了所需的jar包。 创建目标类，不需要实现任何接口。 package dynamic.cglib; public class TestDao { public void save() { System.out.println(&quot;保存&quot;); } public void modify() { System.out.println(&quot;修改&quot;); } public void delete() { System.out.println(&quot;删除&quot;); } }创建代理类，该类实现MethodInterceptor接口 package dynamic.cglib; public class CglibDynamicProxy implements MethodInterceptor { /** * 创建代理的方法，生成CGLIB代理对象 * target 是目标对象，需要增强的对象 * 返回目标对象的CGLLIB代理对象 */ public Object createProxy(Object target) { // 创建一个动态类对象，即增强类对象 Enhancer enhancer=new Enhancer(); // 确定需要增强的类，设置其父类 enhancer.setSuperclass(target.getClass()); // 确定代理逻辑对象为当前对象，要求当前对象实现MethodInterceptor的方法 enhancer.setCallback(this); // 返回创建的代理对象 return enhancer.create(); } /** * intercept 方法会在程序执行目标方法时被调用 * proxy 是CGLIb根据指定父类生成的代理对象 * method 是拦截方法 * args 是拦截方法的参数数组 * methodProxy 是方法的代理对象，用于执行父类的方法 * 返回代理结果 */ @Override public Object intercept(Object proxy, Method method, Object[] args, MethodProxy methodProxy) throws Throwable { MyAspect myAspect=new MyAspect(); myAspect.check(); myAspect.except(); // 目标方法执行，返回代理结果 Object obj=methodProxy.invokeSuper(proxy, args); myAspect.log(); myAspect.monitor(); return obj; } }创建测试类。 package dynamic.cglib; public class CglibDynamicTest { public static void main(String[] args) { // 创建代理对象 CglibDynamicProxy cdp=new CglibDynamicProxy(); // 创建目标对象 TestDao testDao=new TestDao(); // 获取增强后的目标对象 TestDao testDaoAdvice=(TestDao)cdp.createProxy(testDao); // 执行方法 testDaoAdvice.save(); System.out.println(&quot;==============&quot;); testDaoAdvice.modify(); System.out.println(&quot;==============&quot;); testDaoAdvice.delete(); } } 运行结果相同3.基于代理类的AOP实现纵观AOP编程，程序员只需要参与三个部分： 定义普通业务组件 定义切入点，一个切入点可能横切多个业务组件 定义增强处理，增强处理就是AOP框架为普通业务组件织入的处理动作 所以进行AOP编程的关键就是定义切入点和定义增强处理，一旦定义了合适的切入点和增强处理，AOP框架将自动生成AOP代理，即：代理对象的方法=增强处理+被代理对象的方法。 Spring默认使用JDK动态代理实现AOP编程。使用org.springframework.aop.framework.ProxyFactoryBean 创建代理是Spring AOP实现的最基本方式。 3.1 ProxyFactoryBeanProxyFactoryBean 是org.springframework.beans.factory.FactoryBean 接口的实现类，FactoryBean负责实例化一个Bean实例，ProxyFactoryBean负责为其他Bean实例创建代理实例。 下面通过一个实现环绕通知的实例演示Spring使用ProxyFactoryBean创建AOP代理的过程。 3.1.1 创建切面类由于该实例实现环绕通知，切面类需要实现 MethodInterceptor 接口。 package spring.proxyfactorybean; public class MyAspect implements MethodInterceptor { @Override public Object invoke(MethodInvocation arg) throw Throwable { check(); except(); Object obj=arg.proceed(); log(); return obj; } public void check() { System.out.println(&quot;模拟权限控制&quot;); } public void except() { System.out.println(&quot;模拟异常处理&quot;); } public void log() { System.out.println(&quot;模拟日志记录&quot;); } }3.1.2 配置切面并指定代理切面类需要配置为Bean实例，这样Spring容器才能识别为切面对象。 applicationContext.xml &lt;!-- 定义目标对象（使用上一个案例的） --&gt; &lt;bean id=&quot;testDao&quot; class=&quot;dynamic.jdk.TestDaoImpl&quot;/&gt; &lt;!-- 创建一个切面 --&gt; &lt;bean id=&quot;myAspect&quot; class=&quot;spring.proxyfactorybean.MyAspect&quot;/&gt; &lt;!-- 使用Spring代理工厂定义一个名为testDaoProxy的代理对象 --&gt; &lt;bean id=&quot;testDaoProxy&quot; class=&quot;org.springframework.aop.framework.ProxyFactoryBean&quot;&gt; &lt;!-- 指定代理实现的接口 --&gt; &lt;property name=&quot;proxyInterfaces&quot; value=&quot;dynamic.jdk.TestDao&quot;/&gt; &lt;!-- 指定目标对象 --&gt; &lt;property name=&quot;target&quot; ref=&quot;testDao&quot;/&gt; &lt;!-- 指定切面，织入环绕通知 --&gt; &lt;property name=&quot;interceptorNames&quot; value=&quot;myAspect&quot;/&gt; &lt;!-- 指定代理方式，true指定CGLIB动态代理（默认为false，指定JDK动态代理）--&gt; &lt;property name=&quot;proxyTargetClass&quot; value=&quot;true&quot;/&gt; &lt;/bean&gt;3.1.3 测试package spring.proxyfactorbean; public class ProxyFactoryBeanTest { public static void main(String[] args) { ApplicationContext appCon=new ClassPathXmlApplicationContext(&quot;/spring/proxyfactorybean/applicationContext.xml&quot;); TestDao testDaoAdvice=(TestDao)appCon.getBean(&quot;testDaoProxy&quot;); testDaoAdvice.save(); System.out.println(&quot;===============&quot;); testDaoAdvice.modify(); System.out.println(&quot;===============&quot;); testDaoAdvice.delete(); } } 运行结果与之前相同4.基于注解开发AspectJ AspectJ 是一个基于Java的AOP框架。从Spring 2.0以后引入了AspectJ的支持。建议使用AspectJ实现AOP。 AspectJ实现Spring AOP有两种方式：基于XML、基于注解。基于注解要比基于XML配置开发便捷许多。 注解名称 描述 @Aspect 用于定义一个切面。注解在切面类上。 @Pointcut 用于定义切入点表达式。在使用时需要定义一个切入点方法，该方法是一个返回void且方法体为空的普通方法。 @Before 用于定义前置通知。在使用时通常为其指定value属性值。 @AfterReturning 用于定义后置返回通知。在使用时通常为其指定value属性值。 @Around 用于定义环绕通知。在使用时通常为其指定value属性值。 @AfterThrowing 用于定义异常通知。在使用时通常为其指定value属性值。还有一个throwing属性，用于访问目标方法抛出的异常，该属性值与异常通知方法中同名的形参一致。 @After 用于定义后置（最终）通知。在使用时通常为其指定value属性值。 4.1 创建切面类，并进行注解首先需要使用@Aspect 定义一个切面类，由于该类在Spring中是作为组件使用的，所以还需要使用@Component 。然后使用@Pointcut 注解切入点表达式，并通过定义方法来表示切入点名称。最后在每个通知方法上添加相应的注解，并将切入点名称作为参数传递给需要执行增强的通知方法。 package aspectj.annotation; @Aspect @Component public class MyAspect { /** * execution(* dynamic.jdk.*.*(..))定义切入点表达式 * 意思是：匹配dynamic.jdk包中任意类的任意方法的执行 * 第一个* 返回类型，使用*代表所有类型。注意第一个*与包名之间有一个空格 * 第二个* 表示的类名，使用*代表匹配包中的所有类 * 第三个* 表示的是方法名，使用*表示所有方法 * (..)表示方法的参数，&quot;...&quot;表示任意参数 */ @Pointcut(&quot;execution(* dynamic.jdk.*.*(..))&quot;) private void myPointCut() {} /** * 前置通知，使用Joinpoint接口作为参数获取目标对象信息 */ @Before(&quot;myPointCut()&quot;) public void before(JoinPoint jp) { System.out.print(&quot;前置通知：模拟权限控制&quot;); System.out.println(&quot;, 目标类对象：&quot; + jp.getTarget() + &quot;, 被增强处理的方法：&quot; + jp.getSignature().getName()); } /** * 后置返回通知 */ @AfterReturning(&quot;myPointCut()&quot;) public void afterReturning(JoinPoint jp) { System.out.print(&quot;后置返回通知：模拟删除临时文件&quot;); System.out.println(&quot;, 被增强处理的方法：&quot; + jp.getSignature().getName()); } /** * 环绕通知 * ProceedingJoinPoint 是JoinPoint的子接口，代表可以执行的目标方法 * 返回值的类型必须是Object * 必须一个参数是ProceedingJoinPoint类型 * 必须 throws Throwable */ @Around(&quot;myPointCut()&quot;) public Object around(ProceedingJoinPoint pjp) throws Throwable { System.out.print(&quot;环绕开始：执行目标方法前，模拟开启事务&quot;); // 执行当前目标方法 Object obj=pjp,proceed(); System.out.println(&quot;, 目标类对象：&quot; + jp.getTarget() + &quot;, 被增强处理的方法：&quot; + jp.getSignature().getName()); return obj; } /** * 异常通知 */ @AfterThrowing(value=&quot;myPointCut()&quot;, throwing=&quot;e&quot;) public void except(Throwable e) { System.out.println(&quot;异常通知：&quot; + &quot;程序执行异常&quot; + e.getMessage()); } /** * 后置（最终）通知 */ @After(&quot;myPointCut()&quot;) public void after() { System.out.println(&quot;最终通知：模拟释放资源&quot;); } }4.2 注解目标类使用@Repository 将目标类 TestDaoImpl 注解为目标对象。 @Repository(&quot;testDao&quot;)4.3 创建配置文件applicationContext.xml &lt;!-- 指定需要扫描的包，使注解生效 --&gt; &lt;context:component-scan base-package=&quot;aspectj.annotation&quot;/&gt; &lt;context:component-scan base-package=&quot;dynamic.jdk&quot;/&gt; &lt;!-- 启动基于注解的AspectJ支持 --&gt; &lt;aop:aspectj-autoproxy /&gt;4.4 测试public class AnnotationAspectJTest { public static void main(String[] args) { ApplicationContext appCon=new ClassPathXmlApplicationContext(&quot;/aspectj/applicationContext.xml&quot;); TestDao testDaoAdvice=(TestDao)appCon.getBean(&quot;testDao&quot;); testDaoAdvice.save(); } } 运行结果： 前置通知：模拟权限控制，目标类对象：dynamic.jdk.TestDaoImpl@647fd8ce，被增强处理的方法：save 环绕开始：执行目标方法前，模拟开启事务 保存 最终通知：模拟释放资源 环绕结束：执行目标方法后，模拟关闭事务 后置返回通知：模拟删除临时文件，被增强处理的方法：save异常通知得到执行，需要在TestDaoImpl类的save方法中添加异常代码，例如“ int n = 10/0; ”。 运行结果： 前置通知：模拟权限控制，目标类对象：dynamic.jdk.TestDaoImpl@647fd8ce，被增强处理的方法：save 环绕开始：执行目标方法前，模拟开启事务 最终通知：模拟释放资源 异常通知：程序执行异常/ by zero","categories":[{"name":"Spring","slug":"spring","permalink":"https://topone233.github.io/categories/spring/"}],"tags":[{"name":"Java","slug":"java","permalink":"https://topone233.github.io/tags/java/"},{"name":"Spring","slug":"spring","permalink":"https://topone233.github.io/tags/spring/"}]},{"title":"Spring Bean","slug":"Spring Bean","date":"2020-08-22T08:14:36.429Z","updated":"2020-09-07T14:21:03.440Z","comments":true,"path":"2020/08/22/Spring Bean/","link":"","permalink":"https://topone233.github.io/2020/08/22/Spring%20Bean/","excerpt":"","text":"Spring IoC容器可以创建、装配、配置应用组件对象，这里的组件对象称为Bean。 1.Bean 的配置Spring可以看作一个工厂，用于生产和管理Spring容器中的Bean。 如果要使用这个工厂生产和管理Bean，需要将Bean配置在Spring的配置文件中。支持 XML 和 Properties 两种格式的配置文件，常用 XML格式。 元素的常用属性及其子元素： 属性或子元素 描述 id Bean在BeanFactory中的唯一标识，在代码中通过BeanFactory获取Bean实例时需要依次作为索引名称 class Bean的具体实现类，例如dao.TestDIDaoImpl scope 指定Bean实例的作用域 &lt; property&gt; 用于设置一个属性。name 指定Bean实例中相应的属性名称、value 指定Bean的属性值、ref 指定属性对BeanFactory中其他Bean的引用关系 &lt; constructor-arg&gt; 使用构造方法注入，指定构造方法的参数。index指定参数的序号，ref指定对BeanFactory中其他Bean的引用关系，type指定参数类型，value指定参数的常量值 &lt; map&gt;、 &lt; set&gt; 的子元素，封装对应类型的依赖注入 &lt; list&gt; 的子元素，封装List 、数组类型的依赖注入 &lt; entry&gt; 的子元素，用于设置一个键值对 2.Bean 的实例化在面向对象编程时，如果要使用某个对象，需要事先实例化该对象。Spring中，也需要先实例化Bean。 有3种方式：构造方法实例化、静态工厂实例化、实例工厂实例化。最常用构造方法实例化。 2.1构造方法实例化Spring容器调用Bean对应类中的无参数构造方法来实例化Bean。 创建BeanClass类 package instance; public class BeanClass { public String message; public BeanClass() { message = &quot;构造方法实例化Bean&quot;; } public BeanClass(String s) { message = s; } }创建配置文件applicationContext.xml &lt;!-- 构造方法实例化Bean --&gt; &lt;bean id=&quot;demo&quot; class=&quot;instance.BeanClass&quot;/&gt;创建测试类 package test; public class TestInstance { public static void mani(String[] args) { ApplicationContext appCon = new ClassPathXmlApplicationContext(&quot;applicationContext.xml&quot;); BeanClass b = (BeanClass)appCon.getBean(&quot;demo&quot;); System.out.println(b1 + b1.message); } } 结果：instance.BeanClass@490ab905构造方法实例化Bean3.Bean的作用域 scope参数 描述 singleton 默认的作用域，定义的Bean在Spring容器中只有一个Bean实例（返回同一个） prototype Spring容器每次获取Bean，都将创建一个新的Bean实例（每次都返回新的） request 每次HTTP请求都会返回一个Bean实例 session 在一个session中，将返回同一个Bean实例 application 为每个ServletContext对象创建一个实例，即同一个应用共享一个 websocket 为每个WebSocket对象创建一个实例 singleton 与 prototype是最常用的，后面4种仅在Web Spring应用上下文中使用。 4.Bean的生命周期一个对象的生命周期包括：创建（实例化与初始化）、使用、销毁。Bean也遵循这一过程。但是Spring通过了许多对外接口，允许开发者对 实例化（开辟空间）、初始化（属性初始化）、销毁 3个过程的前后做一些操作。 Spring容器可以管理singleton作用域下Bean的生命周期，能够精确知道Bean何时被创建，何时初始化完成，何时被销毁。而对于prototype作用域下的Bean，Spring只负责创建。创建之后Bean实例就交给客户端的代码管理，Spring将不再跟踪其生命周期，也不会管理这些Bean。 Bean的生命周期： 根据Bean的配置情况实例化一个Bean。 根据Spring上下文对实例化的Bean进行依赖注入，即对Bean的属性进行初始化。 如果Bean实现了 BeanNameAware接口，将调用它实现的 setBeanName(String beanId)方法，此处参数传递的是Bean的id，让实现这个接口的Bean知道自己在Spring容器中的的名字。 如果Bean实现了 BeanFactoryAware接口，将调用它实现的 setBeanFactory方法，此处参数传递的是当前Spring工厂实例的引用。此接口是在Bean实例化后、Setter方法之前调用。可以使得Bean获取容器的内部信息，从而进行某些定制化的操作。 如果Bean实现了 ApplicationContextAware接口，将调用它实现的setApplicationContext(ApplicationContext)方法，此处参数传递的是Spring上下文实例的引用。该方法会将容器本身作为参数传给该方法，将Spring传入的参数赋给该类对象的applicationContext实例变量，接下来可以通过该变量来访问容器本身。 如果Bean关联了 BeanPostProcessor接口，将调用初始化方法 postProcessBeforeInitialization(Object obj, String beanName)对Bean进行前置处理。BeanFactoryPostProcessor是Bean属性处理容器，管理所有未实例化的数据（修改属性）。 如果Bean实现了 InitializingBean接口，将调用 afterPropertiesSet方法。 如果Bean在Spring配置文件中配置了 init-method属性，将自动调用其配置的初始化方法。 注意：Spring为Bean提供了两种初始化方式：实现InitializingBean接口、init-method指定。 ​ 两种方式可以同时使用，但如果调用afterPropertiesSet时出错，则不会调用init-method指定的方法。 ​ 通过反射调用init-method指定的方法效率相对较低，但是消除了对Spring的依赖。 如果Bean关联了 BeanPostProcessor接口，将调用 postProcessAfterInitialization(Object obj, String beanName)方法进行后置处理，由于是在Bean初始化结束时调用After方法，也可用于内存或缓存技术。 注意：此时已经可以使用该Bean，由于该Bean的作用域是singleton，所以调用的是同一个Bean实例。 当Bean不再需要时将进入销毁阶段，如果Bean实现了 DisposableBean接口，则调用其实现的destroy方法将Bean销毁 如果在配置文件中通过 destroy-method属性指定了Bean的销毁方法，将调用其配置的销毁方法进行销毁 实例演示： package life; public class BeanLife { public void initMyself() { System.out.println(this.getClass().getName() + &quot;执行自定义的初始化方法&quot;); } public void destroyMyself() { System.out.println(this.getClass().getName() + &quot;执行自定义的销毁方法&quot;)； } }&lt;!-- 使用init-method属性指定初始化方法，使用destroy-method属性指定销毁方法--&gt; &lt;bean id=&quot;beanLife&quot; class=&quot;life.BeanLife&quot; init-method=&quot;initMyself&quot; destroy-method=&quot;destroyMyself&quot;/&gt;package test; public class TestLife { public static void main(String[] args) { ClassPathXmlApplicationContext ctx = new ClassPathXmlApplicationContext(&quot;applicationContext.xml&quot;); BeanLife blife = (BeanLife)ctx.genBean(&quot;beanLife&quot;); System.out.println(&quot;获得对象后&quot; + blife); // 关闭容器，销毁Bean对象 ctx.close(); } }5.Bean的装配Bean的装配可以理解为将Bean依赖注入到Spring容器中。Spring容器支持：基于XML配置、基于注解、自动装配等多种装配方式，最常见的是基于注解。 5.1基于注解的装配尽管使用XML配置文件可以很简单的装配Bean，但如果有大量的Bean，会导致XML配置文件过于庞大，不方便升级与维护，因此更推荐使用注解（annotation）。 @Repository 将数据访问层（DAO）的类标识为Bean。 @Service 将业务逻辑组件类（Service层）标注为Bean。 @Controller 将控制器组件类标注为Bean。 @Component 可以作用在任何层次上，标注一个Bean。为了更加层次化，不推荐使用。 @Autowired 对类成员变量、方法、构造方法进行标注，完成自动装配工作。可以消除setter和getter方法。默认按照Bean的类型进行装配，如果想按照名称装配，需要和@Qualifier 一起使用 @Resource(name=” “) 与@Autowired 功能一样，区别在于该注解默认是按照名称来装配注入的，只有找不到与名称匹配的Bean时才会按照Bean的类型来装配注入。@Resource有两个属性：name、type。name指定Bean实例名称，即按照名称来装配；type指定类型，即按照类型来装配。 @Qualifier 与@Autowired配合使用，当需要按照名称装配时。Bean的实例名称由@Qualifier 的参数指定。","categories":[{"name":"Spring","slug":"spring","permalink":"https://topone233.github.io/categories/spring/"}],"tags":[{"name":"Java","slug":"java","permalink":"https://topone233.github.io/tags/java/"},{"name":"Spring","slug":"spring","permalink":"https://topone233.github.io/tags/spring/"}]},{"title":"Spring IoC","slug":"Spring IoC","date":"2020-08-22T08:09:05.509Z","updated":"2020-09-07T14:20:56.782Z","comments":true,"path":"2020/08/22/Spring IoC/","link":"","permalink":"https://topone233.github.io/2020/08/22/Spring%20IoC/","excerpt":"","text":"1. IoC 的基本概念 IoC（Inversion of Control，控制反转）是一个比较抽象的概念，是Spring框架的核心，用来消减程序的耦合问题。DI（Dependency Injection，依赖注入）是IoC的另外一种说法，只是从不同的角度描述相同的概念。 想吃面包，你可以自己做。也可以选择在面包店下单，告诉店家你的需求，然后等着吃就行。 上面的例子包含了控制反转的思想：把制作面包的主动权交给面包店。 当某个Java对象（调用者，例如我），需要调用另一个Java对象（被调用者，即被依赖对象，例如面包）时，以前我们通常会“new 被调用者”来创建对象（例如我们自己做面包）。这种方式会增加调用者与被调用者之间的耦合性，不利于后期代码的升级和维护。 Spring出现后，对象的实例由Spring容器（例如面包店）来创建。Spring容器会负责控制程序之间的关系（例如面包店负责控制我们与面包的关系）。这样控制权就由调用者转移到Spring容器，控制权发生了反转。 依赖注入：Spring容器负责将依赖对象赋值给调用者的成员变量，相当于为调用者注入它所依赖的实例。这就是依赖注入。 综上所述，控制反转是一种通过描述（XML或者注解）并通过第三方去产生或获取特定对象的方式。实现控制反转的是IoC容器，其实现方式是依赖注入。 2.IoC 容器前面我们知道，实现控制反转的是IoC容器。IoC容器的设计主要是基于BeanFactory 和 ApplicationContext 两个接口。 2.1 BeanFactory 接口BeanFactory 由org.springframework.beans.factory.BeanFactory接口定义，提供了完整的IoC服务支持，是一个管理Bean的工厂，主要负责初始化各种Bean。 BeanFactory接口有很多实现类，常用的是XmlBeanFactory，根据XML配置文件中的定义来配置Bean。 使用BeanFactory实例加载Spring配置文件实际并不多见，仅作了解。 2.2 ApplicationContext 接口ApplicationContext 是BeanFactory的子接口，也称应用上下文。除了包含BeanFactory的所有功能以外，还添加了对国际化、资源访问、事件传播等内容的支持。 创建ApplicationContext接口实例通常有以下三种方法： 2.2.1 通过ClassPathXmlApplicationContextpublic static void main(String[] args) { // 初始化Spring容器ApplicationContext，加载指定的XML配置文件 ApplicationContext appCon = new ClassPathXmlApplicationContext(&quot;applicationContext.xml&quot;); // 通过容器获取test实例 TestDao tt = (TestDao)appCon.getBean(&quot;test&quot;); tt.sayHello(); }2.2.2通过FileSystemXmlApplicationContext创建// 仅需要修改这一行代码 ApplicationContext appCon = new FileSystemXmlApplicationContext(&quot;D:\\test\\applicationContext.xml&quot;);FileSystemXmlApplicationContext 将从指定文件的绝对路径中寻找XML配置文件，但是绝对路径会导致程序的灵活性变差，不推荐使用。通常Spring的Java应用采用ClassPathXmlApplicationContext类来实例化ApplicationContext容器，而Web应用中，将交给Web服务器完成。 2.2.3通过Web服务器实例化ApplicationContext容器Web服务器实例化ApplicationContext容器时，一般使用基于org.springframework.web.context.ContextLoaderListener的实现方式。 &lt;context-param&gt; &lt;!-- 加载src目录下的applicationContext.xml文件 --&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt; classpath:applicationContext.xml &lt;/param-value&gt; &lt;/context-param&gt; &lt;!-- 指定以ContextLoaderListener方式启动Spring容器 --&gt; &lt;listener&gt; &lt;listener-class&gt; org.springframework.web.context.ContextLoaderListener &lt;/listener-class&gt; &lt;/listener&gt;3.依赖注入 Spring中实现IoC容器的方法是依赖注入。依赖注入的作用是在使用Spring创建对象时，动态地将其所依赖的对象（例如属性值）注入Bean组件中。 3.1使用属性的setter方法注入依赖注入通常有两种实现方式：构造方法注入、属性的setter方法注入。（这两种方式都是基于Java的反射机制）。 使用setter方法注入是Spring中最主流的注入方式，利用Java Bean规范所定义的setter方法来完成注入，灵活且可读性高。 下面将两者放在一起进行，方便对比。 3.1.1创建dao包在dao包创建TestDIDao接口及其实现类TestDIDaoImpl package dao; public interface TestDIDao { public void sayHello(); }package dao; public class TestDIDaoImpl implements TestDIDao { @Override public void sayHello() { System.out.println(&quot;TestDIDao say: Hello&quot;); } }3.1.2创建service包service包中创建TestDIService接口及其实现类TestDIServiceImpl package service; public interface TestDIService { public void sayHello(); }package service; import dao.TestDIDao; public class TestDIServiceImpl implements TestDIService { private TestDIDao testDIDao; // 添加testDIDao属性的setter方法，用于实现依赖注入 public void setTestDIDao(TestDIDao testDIDao) { this.testDIDao = testDIDao; } /* 构造方法，用于实现依赖注入接口对象testDIDao public TestDIServiceImpl(TestDIDao testDIDao) { super(); this.testDIDao = testDIDao; } */ @Override public void sayHello() { // 调用testDIDao中的sayHelllo方法 testDIDao.sayHello(); System.out.println(&quot;TestDIService setter方法注入 say: Hello&quot;); } }3.1.3编写配置文件在src根目录下创建Spring配置文件 applicationContext.xml。将TestDIServiceImpl类托管给Spring，让Spring创建其对象，同时调用其setter方法完成依赖注入。 &lt;!-- 将TestDIDaoImpl类配置给Spring，让Spring创建其实例 --&gt; &lt;bean id=&quot;myTestDIDao&quot; class=&quot;dao.TestDIDaoImpl&quot;/&gt; &lt;!-- 使用setter方法注入 --&gt; &lt;bean id=&quot;testDIService&quot; class=&quot;service.TestDIServiceImpl&quot;&gt; &lt;!-- 调用TestDIServiceImpl类的setter方法，将myTestDIDao注入到TestDIServiceImpl类的属性testDIDao上--&gt; &lt;property name=&quot;testDIDao&quot; ref=&quot;myTestDIDao&quot;/&gt; &lt;/bean&gt; /* &lt;!-- 使用构造方法注入 --&gt; &lt;bean id=&quot;testDIService&quot; class=&quot;service.TestDIServiceImpl&quot;&gt; &lt;!-- 将myTestDIDao注入到TestDIServiceImpl类的属性testDIDao上--&gt; &lt;!-- constructor-arg元素用于定义类构造方法的参数，index定义参数的位置--&gt; &lt;!-- ref指定某个实例的引用，如果参数是常量值，ref由value代替--&gt; &lt;constructor-arg index=&quot;o&quot; ref=&quot;myTestDIDao&quot;/&gt; &lt;/bean&gt; */3.1.4测试创建test包，并创建TestDI测试类 package test; public class TestDI { public static void main(String[] args) { ApplicationContext appCon = new ClassPathXmlApplicationContext(&quot;applicationContext.xml&quot;) TestDIservice ts = (TestDIService)appCon.getBean(&quot;testDIService&quot;); ts.sayHello(); } }","categories":[{"name":"Spring","slug":"spring","permalink":"https://topone233.github.io/categories/spring/"}],"tags":[{"name":"Java","slug":"java","permalink":"https://topone233.github.io/tags/java/"},{"name":"Spring","slug":"spring","permalink":"https://topone233.github.io/tags/spring/"}]},{"title":"CORS RESTful Web Service","slug":"CORS RESTful Web Service","date":"2020-08-20T13:28:36.452Z","updated":"2020-09-07T14:18:21.653Z","comments":true,"path":"2020/08/20/CORS RESTful Web Service/","link":"","permalink":"https://topone233.github.io/2020/08/20/CORS%20RESTful%20Web%20Service/","excerpt":"","text":"Enabling Cross Origin Requests for a RESTful Web Service 直奔主题，将使用Spring Boot快速构建项目部分省略，如果需要请访问：https://spring.io/guides/gs/rest-service-cors/ 前言RESTfulRepresentational State Transfer 表述行状态转移，是一种设计风格和开发方式。 Web应用最重要的REST原则是，客户端与服务端之间的交互请求是无状态的。客户端到服务端的请求必须包含理解请求所必需的信息；请求可以由任何可用服务器回答。 资源与URL REST全称是表述性状态转移，那究竟指的是什么的表述? 其实指的就是资源。任何事物，只要有被引用到的必要，它就是一个资源。 要让一个资源可以被识别，需要有个唯一标识，在Web中这个唯一标识就是URI(Uniform Resource Identifier)。URI既可以看成是资源的地址，也可以看成是资源的名称。如果某些信息没有使用URI来表示，那它就不能算是一个资源， 只能算是资源的一些信息而已。 统一资源接口 RESTful架构应该遵循统一接口原则，统一接口包含了一组受限的预定义的操作，不论什么样的资源，都是通过使用相同的接口进行资源的访问。接口应该使用标准的HTTP方法如GET，PUT和POST，并遵循这些方法的语义。 如果按照HTTP方法的语义来暴露资源，那么接口将会拥有安全性和幂等性的特性，例如GET和HEAD请求都是安全的， 无论请求多少次，都不会改变服务器状态。而GET、HEAD、PUT和DELETE请求都是幂等的，无论对资源操作多少次， 结果总是一样的，后面的请求并不会产生比第一次更多的影响。 CORSCross Origin Resource Sharing 跨源资源共享。 是一种机制，它使用额外的 HTTP头来告诉浏览器 让运行在一个 origin (domain) 上的Web应用被准许访问来自不同源服务器上的指定的资源。当一个资源从与该资源本身所在的服务器不同的域、协议或端口请求一个资源时，资源会发起一个跨域 HTTP 请求。 1.Resource Representation Classpackage com.example.restservicecors; public class Greeting { private final long id; private final String content; public Greeting() { this.id = -1; this.content = &quot;&quot;; } public Greeting(long id, String content) { this.id = id; this.content = content; } public long getId() { return id; } public String getContent() { return content; } }Spring使用Jackson JSON库自动将Greeting类型的实例编组为JSON 2.Resource Controllerpackage com.example.restservicecors; import java.util.concurrent.atomic.AtomicLong; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.RequestParam; import org.springframework.web.bind.annotation.CrossOrigin; import org.springframework.web.bind.annotation.RestController; @RestController public class GreetingController { private static final String template = &quot;Hello, %s!&quot;; private final AtomicLong counter = new AtomicLong(); @GetMapping(&quot;/greeting&quot;) public Greeting greeting(@RequestParam(required=false, defaultValue=&quot;World&quot;) String name) { System.out.println(&quot;==== in greeting ====&quot;); /** * 创建并返回一个新的Greeting对象 * 具有基于计数器（counter）的下一个值的 id 和 context * 并使用Greeting模板格式化给定的name */ return new Greeting(counter.incrementAndGet(), String.format(template, name)); } }@RestController将类标记为控制器，其中每个方法返回域对象而不是视图。包含 @Controller 和 @ResponseBody @GetMapping使HTTP GET /greeting 的请求，映射到greeting() 方法。对于其他HTTP请求也有对应的注释（例如 @PostMapping）。它们都派生自@RequeMapping。@RequeMapping(method=GET) @RequestParam将查询字符串参数名的值绑定到greeting()方法的名称参数中。如果请求中没有name参数，则使用默认参数“World” @ResponseBody告诉SpringMVC 不需要通过视图层呈现greeting对象，返回的greeting对象是响应体，应该直接写入 传统MVC控制器和RESTful web服务控制器之间的一个关键区别创建HTTP响应体的方式。RESTful 将对象数据将以JSON的形式直接写入HTTP响应，不依赖视图。 Greeting对象必须转换为JSON。由于Spring的HTTP消息转换器支持，不需要手动转换。在类路径中的Jackson2会自动选择Spring的MappingJackson2HttpMessageConverter来将Greeting实例转换为JSON。 3.Enabling CORS为了使RESTful Web的响应中包含CORS访问控制头，必须添加@CrossOrigin 在处理方法中（也可以添加到控制器类，该类的所有处理方法都启用CORS） @CrossOrigin(origins = &quot;http://localhost:9000&quot;， maxAge = 3000) @GetMapping(&quot;/greeting&quot;) public Greeting greeting(@RequestParam(required=false, defaultValue=&quot;World&quot;) String name) { System.out.println(&quot;==== in greeting ====&quot;); return new Greeting(counter.incrementAndGet(), String.format(template, name)); }@CrossOrigin仅对这个特定的方法允许跨源资源共享。包含以下属性 origins methods allowedHeaders exposedHeaders allowCredentials maxAge （默认30分钟） 4.Creating the Application Classpackage com.example.restservicecors; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.context.annotation.Bean; import org.springframework.web.servlet.config.annotation.CorsRegistry; import org.springframework.web.servlet.config.annotation.WebMvcConfigurer; @SpringBootApplication public class RestServiceCorsApplication { public static void main(String[] args) { SpringApplication.run(RestServiceCorsApplication.class, args); } /** * 添加一种方法来配置如何处理跨域资源共享 */ @Bean public WebMvcConfigurer corsConfigurer() { return new WebMvcConfigurer() { @Override public void addCorsMappings(CorsRegistry registry) { registry.addMapping(&quot;/greeting-javaconfig&quot;).allowedOrigins(&quot;http://localhost:9000&quot;); } }; } }@SpringBootApplication添加了以下所有内容： @Configuration：将类标记为程序上下文的Bean定义的源 @EnableAutoConfiguration：告诉Spring Boot根据类路径设置、其他bean和各种属性设置开始添加bean @ComponentScan：告诉Spring在com/example包中寻找其他组件、配置、服务，让它找到控制器 5.Build an executable JAR// 运行 ./mvnw spring-boot: run //构建jar文件 ./mvnw clean //运行jar文件 java -jar target/demo.jar6.Test the Service访问：http://localhost:8080/greeting 结果：{&quot;id&quot;:1,&quot;content&quot;:&quot;Hello, World!&quot;} 访问：http://localhost:8080/greeting?name=User 结果：{&quot;id&quot;:2,&quot;content&quot;:&quot;Hello, User!&quot;}创建一个js客户端来使用服务 hello.js $(document).ready(function() { $.ajax({ url: &quot;http://localhost:8080/greeting&quot; }).then(function(data, status, jqxhr) { $(&#39;.greeting-id&#39;).append(data.id); $(&#39;.greeting-content&#39;).append(data.content); console.log(jqxhr); }); });index.html &lt;!DOCTYPE html&gt; &lt;html&gt; &lt;head&gt; &lt;title&gt;Hello CORS&lt;/title&gt; &lt;script src=&quot;https://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js&quot;&gt;&lt;/script&gt; &lt;script src=&quot;hello.js&quot;&gt;&lt;/script&gt; &lt;/head&gt; &lt;body&gt; &lt;div&gt; &lt;p class=&quot;greeting-id&quot;&gt;The ID is &lt;/p&gt; &lt;p class=&quot;greeting-content&quot;&gt;The content is &lt;/p&gt; &lt;/div&gt; &lt;/body&gt; &lt;/html&gt;./mvnw spring-boot:run -Dserver.port=9000 访问：http://localhost:9000/ 结果： The ID is 1 The content is Hello,World!","categories":[{"name":"Java","slug":"java","permalink":"https://topone233.github.io/categories/java/"}],"tags":[{"name":"Java","slug":"java","permalink":"https://topone233.github.io/tags/java/"},{"name":"Spring","slug":"spring","permalink":"https://topone233.github.io/tags/spring/"},{"name":"CORS","slug":"cors","permalink":"https://topone233.github.io/tags/cors/"},{"name":"RESTful","slug":"restful","permalink":"https://topone233.github.io/tags/restful/"}]},{"title":"Java 集合","slug":"Java 集合","date":"2020-07-31T16:00:00.000Z","updated":"2020-09-15T11:43:40.499Z","comments":true,"path":"2020/08/01/Java 集合/","link":"","permalink":"https://topone233.github.io/2020/08/01/Java%20%E9%9B%86%E5%90%88/","excerpt":"","text":"","categories":[{"name":"Java","slug":"java","permalink":"https://topone233.github.io/categories/java/"}],"tags":[{"name":"Java","slug":"java","permalink":"https://topone233.github.io/tags/java/"},{"name":"集合","slug":"集合","permalink":"https://topone233.github.io/tags/%E9%9B%86%E5%90%88/"}]},{"title":"Java IO","slug":"Java IO","date":"2020-07-26T16:00:00.000Z","updated":"2020-09-15T11:42:02.805Z","comments":true,"path":"2020/07/27/Java IO/","link":"","permalink":"https://topone233.github.io/2020/07/27/Java%20IO/","excerpt":"","text":"","categories":[{"name":"Java","slug":"java","permalink":"https://topone233.github.io/categories/java/"}],"tags":[{"name":"Java","slug":"java","permalink":"https://topone233.github.io/tags/java/"},{"name":"IO","slug":"io","permalink":"https://topone233.github.io/tags/io/"}]},{"title":"进程和线程基础知识全家桶，30 张图一套带走","slug":"进程和线程基础知识全家桶，30 张图一套带走","date":"2020-07-22T08:12:57.374Z","updated":"2020-09-11T13:00:25.203Z","comments":true,"path":"2020/07/22/进程和线程基础知识全家桶，30 张图一套带走/","link":"","permalink":"https://topone233.github.io/2020/07/22/%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%85%A8%E5%AE%B6%E6%A1%B6%EF%BC%8C30%20%E5%BC%A0%E5%9B%BE%E4%B8%80%E5%A5%97%E5%B8%A6%E8%B5%B0/","excerpt":"","text":"原文地址 前言 先来看看一则小故事 我们写好的一行行代码，为了让其工作起来，我们还得把它送进城（进程）里，那既然进了城里，那肯定不能胡作非为了。 城里人有城里人的规矩，城中有个专门管辖你们的城管（操作系统），人家让你休息就休息，让你工作就工作，毕竟摊位（CPU）就一个，每个人都要占这个摊位来工作，城里要工作的人多着去了。 所以城管为了公平起见，它使用一种策略（调度）方式，给每个人一个固定的工作时间（时间片），时间到了就会通知你去休息而换另外一个人上场工作。 另外，在休息时候你也不能偷懒，要记住工作到哪了，不然下次到你工作了，你忘记工作到哪了，那还怎么继续？ 有的人，可能还进入了县城（线程）工作，这里相对轻松一些，在休息的时候，要记住的东西相对较少，而且还能共享城里的资源。 进程和线程对于写代码的我们，真的天天见、日日见了，但见的多不代表你就熟悉它们，比如简单问你一句，你知道它们的工作原理和区别吗？ 不知道没关系，今天就要跟大家讨论操作系统的进程和线程。 提纲 正文进程我们编写的代码只是一个存储在硬盘的静态文件，通过编译后就会生成二进制可执行文件，当我们运行这个可执行文件后，它会被装载到内存中，接着 CPU 会执行程序中的每一条指令，那么这个运行中的程序，就被称为「进程」。 现在我们考虑有一个会读取硬盘文件数据的程序被执行了，那么当运行到读取文件的指令时，就会去从硬盘读取数据，但是硬盘的读写速度是非常慢的，那么在这个时候，如果 CPU 傻傻的等硬盘返回数据的话，那 CPU 的利用率是非常低的。 做个类比，你去煮开水时，你会傻傻的等水壶烧开吗？很明显，小孩也不会傻等。我们可以在水壶烧开之前去做其他事情。当水壶烧开了，我们自然就会听到 “嘀嘀嘀” 的声音，于是再把烧开的水倒入到水杯里就好了。 所以，当进程要从硬盘读取数据时，CPU 不需要阻塞等待数据的返回，而是去执行另外的进程。当硬盘数据返回时，CPU 会收到个中断，于是 CPU 再继续运行这个进程。 进程 1 与进程 2 切换 这种多个程序、交替执行的思想，就有 CPU 管理多个进程的初步想法。 对于一个支持多进程的系统，CPU 会从一个进程快速切换至另一个进程，其间每个进程各运行几十或几百个毫秒。 虽然单核的 CPU 在某一个瞬间，只能运行一个进程。但在 1 秒钟期间，它可能会运行多个进程，这样就产生并行的错觉，实际上这是并发。 并发和并行有什么区别？ 一图胜千言。 并发与并行 进程与程序的关系的类比 到了晚饭时间，一对小情侣肚子都咕咕叫了，于是男生见机行事，就想给女生做晚饭，所以他就在网上找了辣子鸡的菜谱，接着买了一些鸡肉、辣椒、香料等材料，然后边看边学边做这道菜。 突然，女生说她想喝可乐，那么男生只好把做菜的事情暂停一下，并在手机菜谱标记做到哪一个步骤，把状态信息记录了下来。 然后男生听从女生的指令，跑去下楼买了一瓶冰可乐后，又回到厨房继续做菜。 这体现了，CPU 可以从一个进程（做菜）切换到另外一个进程（买可乐），在切换前必须要记录当前进程中运行的状态信息，以备下次切换回来的时候可以恢复执行。 所以，可以发现进程有着「运行 - 暂停 - 运行」的活动规律。 进程的状态在上面，我们知道了进程有着「运行 - 暂停 - 运行」的活动规律。一般说来，一个进程并不是自始至终连续不停地运行的，它与并发执行中的其他进程的执行是相互制约的。 它有时处于运行状态，有时又由于某种原因而暂停运行处于等待状态，当使它暂停的原因消失后，它又进入准备运行状态。 所以，在一个进程的活动期间至少具备三种基本状态，即运行状态、就绪状态、阻塞状态。 进程的三种基本状态 上图中各个状态的意义： 运行状态（_Runing_）：该时刻进程占用 CPU； 就绪状态（_Ready_）：可运行，但因为其他进程正在运行而暂停停止； 阻塞状态（_Blocked_）：该进程正在等待某一事件发生（如等待输入 / 输出操作的完成）而暂时停止运行，这时，即使给它 CPU 控制权，它也无法运行； 当然，进程另外两个基本状态： 创建状态（_new_）：进程正在被创建时的状态； 结束状态（_Exit_）：进程正在从系统中消失时的状态； 于是，一个完整的进程状态的变迁如下图： 进程五种状态的变迁 再来详细说明一下进程的状态变迁： _NULL -&gt; 创建状态_：一个新进程被创建时的第一个状态； _创建状态 -&gt; 就绪状态_：当进程被创建完成并初始化后，一切就绪准备运行时，变为就绪状态，这个过程是很快的； _就绪态 -&gt; 运行状态_：处于就绪状态的进程被操作系统的进程调度器选中后，就分配给 CPU 正式运行该进程； _运行状态 -&gt; 结束状态_：当进程已经运行完成或出错时，会被操作系统作结束状态处理； _运行状态 -&gt; 就绪状态_：处于运行状态的进程在运行过程中，由于分配给它的运行时间片用完，操作系统会把该进程变为就绪态，接着从就绪态选中另外一个进程运行； _运行状态 -&gt; 阻塞状态_：当进程请求某个事件且必须等待时，例如请求 I/O 事件； _阻塞状态 -&gt; 就绪状态_：当进程要等待的事件完成时，它从阻塞状态变到就绪状态； 另外，还有一个状态叫挂起状态，它表示进程没有占有物理内存空间。这跟阻塞状态是不一样，阻塞状态是等待某个事件的返回。 由于虚拟内存管理原因，进程的所使用的空间可能并没有映射到物理内存，而是在硬盘上，这时进程就会出现挂起状态，另外调用 sleep 也会被挂起。 虚拟内存管理 - 换入换出 挂起状态可以分为两种： 阻塞挂起状态：进程在外存（硬盘）并等待某个事件的出现； 就绪挂起状态：进程在外存（硬盘），但只要进入内存，即刻立刻运行； 这两种挂起状态加上前面的五种状态，就变成了七种状态变迁（留给我的颜色不多了），见如下图： 七种状态变迁 进程的控制结构在操作系统中，是用进程控制块（_process control block，PCB_）数据结构来描述进程的。 那 PCB 是什么呢？打开知乎搜索你就会发现这个东西并不是那么简单。 知乎搜 PCB 的提示 打住打住，我们是个正经的人，怎么会去看那些问题呢？是吧，回来回来。 PCB 是进程存在的唯一标识，这意味着一个进程的存在，必然会有一个 PCB，如果进程消失了，那么 PCB 也会随之消失。 PCB 具体包含什么信息呢？ 进程描述信息： 进程标识符：标识各个进程，每个进程都有一个并且唯一的标识符； 用户标识符：进程归属的用户，用户标识符主要为共享和保护服务； 进程控制和管理信息： 进程当前状态，如 new、ready、running、waiting 或 blocked 等； 进程优先级：进程抢占 CPU 时的优先级； 资源分配清单： 有关内存地址空间或虚拟地址空间的信息，所打开文件的列表和所使用的 I/O 设备信息。 CPU 相关信息： CPU 中各个寄存器的值，当进程被切换时，CPU 的状态信息都会被保存在相应的 PCB 中，以便进程重新执行时，能从断点处继续执行。 可见，PCB 包含信息还是比较多的。 每个 PCB 是如何组织的呢？ 通常是通过链表的方式进行组织，把具有相同状态的进程链在一起，组成各种队列。比如： 将所有处于就绪状态的进程链在一起，称为就绪队列； 把所有因等待某事件而处于等待状态的进程链在一起就组成各种阻塞队列； 另外，对于运行队列在单核 CPU 系统中则只有一个运行指针了，因为单核 CPU 在某个时间，只能运行一个程序。 那么，就绪队列和阻塞队列链表的组织形式如下图： 就绪队列和阻塞队列 除了链接的组织方式，还有索引方式，它的工作原理：将同一状态的进程组织在一个索引表中，索引表项指向相应的 PCB，不同状态对应不同的索引表。 一般会选择链表，因为可能面临进程创建，销毁等调度导致进程状态发生变化，所以链表能够更加灵活的插入和删除。 进程的控制我们熟知了进程的状态变迁和进程的数据结构 PCB 后，再来看看进程的创建、终止、阻塞、唤醒的过程，这些过程也就是进程的控制。 01 创建进程 操作系统允许一个进程创建另一个进程，而且允许子进程继承父进程所拥有的资源，当子进程被终止时，其在父进程处继承的资源应当还给父进程。同时，终止父进程时同时也会终止其所有的子进程。 创建进程的过程如下： 为新进程分配一个唯一的进程标识号，并申请一个空白的 PCB，PCB 是有限的，若申请失败则创建失败； 为进程分配资源，此处如果资源不足，进程就会进入等待状态，以等待资源； 初始化 PCB； 如果进程的调度队列能够接纳新进程，那就将进程插入到就绪队列，等待被调度运行； 02 终止进程 进程可以有 3 种终止方式：正常结束、异常结束以及外界干预（信号 kill 掉）。 终止进程的过程如下： 查找需要终止的进程的 PCB； 如果处于执行状态，则立即终止该进程的执行，然后将 CPU 资源分配给其他进程； 如果其还有子进程，则应将其所有子进程终止； 将该进程所拥有的全部资源都归还给父进程或操作系统； 将其从 PCB 所在队列中删除； 03 阻塞进程 当进程需要等待某一事件完成时，它可以调用阻塞语句把自己阻塞等待。而一旦被阻塞等待，它只能由另一个进程唤醒。 阻塞进程的过程如下： 找到将要被阻塞进程标识号对应的 PCB； 如果该进程为运行状态，则保护其现场，将其状态转为阻塞状态，停止运行； 将该 PCB 插入的阻塞队列中去； 04 唤醒进程 进程由「运行」转变为「阻塞」状态是由于进程必须等待某一事件的完成，所以处于阻塞状态的进程是绝对不可能叫醒自己的。 如果某进程正在等待 I/O 事件，需由别的进程发消息给它，则只有当该进程所期待的事件出现时，才由发现者进程用唤醒语句叫醒它。 唤醒进程的过程如下： 在该事件的阻塞队列中找到相应进程的 PCB； 将其从阻塞队列中移出，并置其状态为就绪状态； 把该 PCB 插入到就绪队列中，等待调度程序调度； 进程的阻塞和唤醒是一对功能相反的语句，如果某个进程调用了阻塞语句，则必有一个与之对应的唤醒语句。 进程的上下文切换各个进程之间是共享 CPU 资源的，在不同的时候进程之间需要切换，让不同的进程可以在 CPU 执行，那么这个一个进程切换到另一个进程运行，称为进程的上下文切换。 在详细说进程上下文切换前，我们先来看看 CPU 上下文切换 大多数操作系统都是多任务，通常支持大于 CPU 数量的任务同时运行。实际上，这些任务并不是同时运行的，只是因为系统在很短的时间内，让各个任务分别在 CPU 运行，于是就造成同时运行的错觉。 任务是交给 CPU 运行的，那么在每个任务运行前，CPU 需要知道任务从哪里加载，又从哪里开始运行。 所以，操作系统需要事先帮 CPU 设置好 CPU 寄存器和程序计数器。 CPU 寄存器是 CPU 内部一个容量小，但是速度极快的内存（缓存）。我举个例子，寄存器像是你的口袋，内存像你的书包，硬盘则是你家里的柜子，如果你的东西存放到口袋，那肯定是比你从书包或家里柜子取出来要快的多。 再来，程序计数器则是用来存储 CPU 正在执行的指令位置、或者即将执行的下一条指令位置。 所以说，CPU 寄存器和程序计数是 CPU 在运行任何任务前，所必须依赖的环境，这些环境就叫做 CPU 上下文。 既然知道了什么是 CPU 上下文，那理解 CPU 上下文切换就不难了。 CPU 上下文切换就是先把前一个任务的 CPU 上下文（CPU 寄存器和程序计数器）保存起来，然后加载新任务的上下文到这些寄存器和程序计数器，最后再跳转到程序计数器所指的新位置，运行新任务。 系统内核会存储保持下来的上下文信息，当此任务再次被分配给 CPU 运行时，CPU 会重新加载这些上下文，这样就能保证任务原来的状态不受影响，让任务看起来还是连续运行。 上面说到所谓的「任务」，主要包含进程、线程和中断。所以，可以根据任务的不同，把 CPU 上下文切换分成：进程上下文切换、线程上下文切换和中断上下文切换。 进程的上下文切换到底是切换什么呢？ 进程是由内核管理和调度的，所以进程的切换只能发生在内核态。 所以，进程的上下文切换不仅包含了虚拟内存、栈、全局变量等用户空间的资源，还包括了内核堆栈、寄存器等内核空间的资源。 通常，会把交换的信息保存在进程的 PCB，当要运行另外一个进程的时候，我们需要从这个进程的 PCB 取出上下文，然后恢复到 CPU 中，这使得这个进程可以继续执行，如下图所示： 进程上下文切换 大家需要注意，进程的上下文开销是很关键的，我们希望它的开销越小越好，这样可以使得进程可以把更多时间花费在执行程序上，而不是耗费在上下文切换。 发生进程上下文切换有哪些场景？ 为了保证所有进程可以得到公平调度，CPU 时间被划分为一段段的时间片，这些时间片再被轮流分配给各个进程。这样，当某个进程的时间片耗尽了，就会被系统挂起，切换到其它正在等待 CPU 的进程运行； 进程在系统资源不足（比如内存不足）时，要等到资源满足后才可以运行，这个时候进程也会被挂起，并由系统调度其他进程运行； 当进程通过睡眠函数 sleep 这样的方法将自己主动挂起时，自然也会重新调度； 当有优先级更高的进程运行时，为了保证高优先级进程的运行，当前进程会被挂起，由高优先级进程来运行； 发生硬件中断时，CPU 上的进程会被中断挂起，转而执行内核中的中断服务程序； 以上，就是发生进程上下文切换的常见场景了。 线程在早期的操作系统中都是以进程作为独立运行的基本单位，直到后面，计算机科学家们又提出了更小的能独立运行的基本单位，也就是线程。 为什么使用线程？我们举个例子，假设你要编写一个视频播放器软件，那么该软件功能的核心模块有三个： 从视频文件当中读取数据； 对读取的数据进行解压缩； 把解压缩后的视频数据播放出来； 对于单进程的实现方式，我想大家都会是以下这个方式： 单进程实现方式 对于单进程的这种方式，存在以下问题： 播放出来的画面和声音会不连贯，因为当 CPU 能力不够强的时候，Read 的时候可能进程就等在这了，这样就会导致等半天才进行数据解压和播放； 各个函数之间不是并发执行，影响资源的使用效率； 那改进成多进程的方式： 多进程实现方式 对于多进程的这种方式，依然会存在问题： 进程之间如何通信，共享数据？ 维护进程的系统开销较大，如创建进程时，分配资源、建立 PCB；终止进程时，回收资源、撤销 PCB；进程切换时，保存当前进程的状态信息； 那到底如何解决呢？需要有一种新的实体，满足以下特性： 实体之间可以并发运行； 实体之间共享相同的地址空间； 这个新的实体，就是线程 ( Thread )，线程之间可以并发运行且共享相同的地址空间。 什么是线程？线程是进程当中的一条执行流程。 同一个进程内多个线程之间可以共享代码段、数据段、打开的文件等资源，但每个线程都有独立一套的寄存器和栈，这样可以确保线程的控制流是相对独立的。 多线程 线程的优缺点？ 线程的优点： 一个进程中可以同时存在多个线程； 各个线程之间可以并发执行； 各个线程之间可以共享地址空间和文件等资源； 线程的缺点： 当进程中的一个线程奔溃时，会导致其所属进程的所有线程奔溃。 举个例子，对于游戏的用户设计，则不应该使用多线程的方式，否则一个用户挂了，会影响其他同个进程的线程。 线程与进程的比较线程与进程的比较如下： 进程是资源（包括内存、打开的文件等）分配的单位，线程是 CPU 调度的单位； 进程拥有一个完整的资源平台，而线程只独享必不可少的资源，如寄存器和栈； 线程同样具有就绪、阻塞、执行三种基本状态，同样具有状态之间的转换关系； 线程能减少并发执行的时间和空间开销； 对于，线程相比进程能减少开销，体现在： 线程的创建时间比进程快，因为进程在创建的过程中，还需要资源管理信息，比如内存管理信息、文件管理信息，而线程在创建的过程中，不会涉及这些资源管理信息，而是共享它们； 线程的终止时间比进程快，因为线程释放的资源相比进程少很多； 同一个进程内的线程切换比进程切换快，因为线程具有相同的地址空间（虚拟内存共享），这意味着同一个进程的线程都具有同一个页表，那么在切换的时候不需要切换页表。而对于进程之间的切换，切换的时候要把页表给切换掉，而页表的切换过程开销是比较大的； 由于同一进程的各线程间共享内存和文件资源，那么在线程之间数据传递的时候，就不需要经过内核了，这就使得线程之间的数据交互效率更高了； 所以，线程比进程不管是时间效率，还是空间效率都要高。 线程的上下文切换在前面我们知道了，线程与进程最大的区别在于：线程是调度的基本单位，而进程则是资源拥有的基本单位。 所以，所谓操作系统的任务调度，实际上的调度对象是线程，而进程只是给线程提供了虚拟内存、全局变量等资源。 对于线程和进程，我们可以这么理解： 当进程只有一个线程时，可以认为进程就等于线程； 当进程拥有多个线程时，这些线程会共享相同的虚拟内存和全局变量等资源，这些资源在上下文切换时是不需要修改的； 另外，线程也有自己的私有数据，比如栈和寄存器等，这些在上下文切换时也是需要保存的。 线程上下文切换的是什么？ 这还得看线程是不是属于同一个进程： 当两个线程不是属于同一个进程，则切换的过程就跟进程上下文切换一样； 当两个线程是属于同一个进程，因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，只需要切换线程的私有数据、寄存器等不共享的数据； 所以，线程的上下文切换相比进程，开销要小很多。 线程的实现主要有三种线程的实现方式： 用户线程（_User Thread_）：在用户空间实现的线程，不是由内核管理的线程，是由用户态的线程库来完成线程的管理； 内核线程（_Kernel Thread_）：在内核中实现的线程，是由内核管理的线程； 轻量级进程（_LightWeight Process_）：在内核中来支持用户线程； 那么，这还需要考虑一个问题，用户线程和内核线程的对应关系。 首先，第一种关系是多对一的关系，也就是多个用户线程对应同一个内核线程： 多对一 第二种是一对一的关系，也就是一个用户线程对应一个内核线程： 一对一 第三种是多对多的关系，也就是多个用户线程对应到多个内核线程： 多对多 用户线程如何理解？存在什么优势和缺陷？ 用户线程是基于用户态的线程管理库来实现的，那么线程控制块（_Thread Control Block, TCB_） 也是在库里面来实现的，对于操作系统而言是看不到这个 TCB 的，它只能看到整个进程的 PCB。 所以，用户线程的整个线程管理和调度，操作系统是不直接参与的，而是由用户级线程库函数来完成线程的管理，包括线程的创建、终止、同步和调度等。 用户级线程的模型，也就类似前面提到的多对一的关系，即多个用户线程对应同一个内核线程，如下图所示： 用户级线程模型 用户线程的优点： 每个进程都需要有它私有的线程控制块（TCB）列表，用来跟踪记录它各个线程状态信息（PC、栈指针、寄存器），TCB 由用户级线程库函数来维护，可用于不支持线程技术的操作系统； 用户线程的切换也是由线程库函数来完成的，无需用户态与内核态的切换，所以速度特别快； 用户线程的缺点： 由于操作系统不参与线程的调度，如果一个线程发起了系统调用而阻塞，那进程所包含的用户线程都不能执行了。 当一个线程开始运行后，除非它主动地交出 CPU 的使用权，否则它所在的进程当中的其他线程无法运行，因为用户态的线程没法打断当前运行中的线程，它没有这个特权，只有操作系统才有，但是用户线程不是由操作系统管理的。 由于时间片分配给进程，故与其他进程比，在多线程执行时，每个线程得到的时间片较少，执行会比较慢； 以上，就是用户线程的优缺点了。 那内核线程如何理解？存在什么优势和缺陷？ 内核线程是由操作系统管理的，线程对应的 TCB 自然是放在操作系统里的，这样线程的创建、终止和管理都是由操作系统负责。 内核线程的模型，也就类似前面提到的一对一的关系，即一个用户线程对应一个内核线程，如下图所示： 内核线程模型 内核线程的优点： 在一个进程当中，如果某个内核线程发起系统调用而被阻塞，并不会影响其他内核线程的运行； 分配给线程，多线程的进程获得更多的 CPU 运行时间； 内核线程的缺点： 在支持内核线程的操作系统中，由内核来维护进程和线程的上下问信息，如 PCB 和 TCB； 线程的创建、终止和切换都是通过系统调用的方式来进行，因此对于系统来说，系统开销比较大； 以上，就是内核线的优缺点了。 最后的轻量级进程如何理解？ 轻量级进程（_Light-weight process，LWP_）是内核支持的用户线程，一个进程可有一个或多个 LWP，每个 LWP 是跟内核线程一对一映射的，也就是 LWP 都是由一个内核线程支持。 另外，LWP 只能由内核管理并像普通进程一样被调度，Linux 内核是支持 LWP 的典型例子。 在大多数系统中，LWP 与普通进程的区别也在于它只有一个最小的执行上下文和调度程序所需的统计信息。一般来说，一个进程代表程序的一个实例，而 LWP 代表程序的执行线程，因为一个执行线程不像进程那样需要那么多状态信息，所以 LWP 也不带有这样的信息。 在 LWP 之上也是可以使用用户线程的，那么 LWP 与用户线程的对应关系就有三种： 1 : 1，即一个 LWP 对应 一个用户线程； N : 1，即一个 LWP 对应多个用户线程； N : N，即多个 LMP 对应多个用户线程； 接下来针对上面这三种对应关系说明它们优缺点。先下图的 LWP 模型： LWP 模型 1 : 1 模式 一个线程对应到一个 LWP 再对应到一个内核线程，如上图的进程 4，属于此模型。 优点：实现并行，当一个 LWP 阻塞，不会影响其他 LWP； 缺点：每一个用户线程，就产生一个内核线程，创建线程的开销较大。 N : 1 模式 多个用户线程对应一个 LWP 再对应一个内核线程，如上图的进程 2，线程管理是在用户空间完成的，此模式中用户的线程对操作系统不可见。 优点：用户线程要开几个都没问题，且上下文切换发生用户空间，切换的效率较高； 缺点：一个用户线程如果阻塞了，则整个进程都将会阻塞，另外在多核 CPU 中，是没办法充分利用 CPU 的。 M : N 模式 根据前面的两个模型混搭一起，就形成 M:N 模型，该模型提供了两级控制，首先多个用户线程对应到多个 LWP，LWP 再一一对应到内核线程，如上图的进程 3。 优点：综合了前两种优点，大部分的线程上下文发生在用户空间，且多个线程又可以充分利用多核 CPU 的资源。 组合模式 如上图的进程 5，此进程结合 1:1 模型和 M:N 模型。开发人员可以针对不同的应用特点调节内核线程的数目来达到物理并行性和逻辑并行性的最佳方案。 调度进程都希望自己能够占用 CPU 进行工作，那么这涉及到前面说过的进程上下文切换。 一旦操作系统把进程切换到运行状态，也就意味着该进程占用着 CPU 在执行，但是当操作系统把进程切换到其他状态时，那就不能在 CPU 中执行了，于是操作系统会选择下一个要运行的进程。 选择一个进程运行这一功能是在操作系统中完成的，通常称为调度程序（_scheduler_）。 那到底什么时候调度进程，或以什么原则来调度进程呢？ 调度时机在进程的生命周期中，当进程从一个运行状态到另外一状态变化的时候，其实会触发一次调度。 比如，以下状态的变化都会触发操作系统的调度： _从就绪态 -&gt; 运行态_：当进程被创建时，会进入到就绪队列，操作系统会从就绪队列选择一个进程运行； _从运行态 -&gt; 阻塞态_：当进程发生 I/O 事件而阻塞时，操作系统必须另外一个进程运行； _从运行态 -&gt; 结束态_：当进程退出结束后，操作系统得从就绪队列选择另外一个进程运行； 因为，这些状态变化的时候，操作系统需要考虑是否要让新的进程给 CPU 运行，或者是否让当前进程从 CPU 上退出来而换另一个进程运行。 另外，如果硬件时钟提供某个频率的周期性中断，那么可以根据如何处理时钟中断，把调度算法分为两类： 非抢占式调度算法挑选一个进程，然后让该进程运行直到被阻塞，或者直到该进程退出，才会调用另外一个进程，也就是说不会理时钟中断这个事情。 抢占式调度算法挑选一个进程，然后让该进程只运行某段时间，如果在该时段结束时，该进程仍然在运行时，则会把它挂起，接着调度程序从就绪队列挑选另外一个进程。这种抢占式调度处理，需要在时间间隔的末端发生时钟中断，以便把 CPU 控制返回给调度程序进行调度，也就是常说的时间片机制。 调度原则_原则一_：如果运行的程序，发生了 I/O 事件的请求，那 CPU 使用率必然会很低，因为此时进程在阻塞等待硬盘的数据返回。这样的过程，势必会造成 CPU 突然的空闲。所以，为了提高 CPU 利用率，在这种发送 I/O 事件致使 CPU 空闲的情况下，调度程序需要从就绪队列中选择一个进程来运行。 _原则二_：有的程序执行某个任务花费的时间会比较长，如果这个程序一直占用着 CPU，会造成系统吞吐量（CPU 在单位时间内完成的进程数量）的降低。所以，要提高系统的吞吐率，调度程序要权衡长任务和短任务进程的运行完成数量。 _原则三_：从进程开始到结束的过程中，实际上是包含两个时间，分别是进程运行时间和进程等待时间，这两个时间总和就称为周转时间。进程的周转时间越小越好，如果进程的等待时间很长而运行时间很短，那周转时间就很长，这不是我们所期望的，调度程序应该避免这种情况发生。 _原则四_：处于就绪队列的进程，也不能等太久，当然希望这个等待的时间越短越好，这样可以使得进程更快的在 CPU 中执行。所以，就绪队列中进程的等待时间也是调度程序所需要考虑的原则。 _原则五_：对于鼠标、键盘这种交互式比较强的应用，我们当然希望它的响应时间越快越好，否则就会影响用户体验了。所以，对于交互式比较强的应用，响应时间也是调度程序需要考虑的原则。 五种调度原则 针对上面的五种调度原则，总结成如下： CPU 利用率：调度程序应确保 CPU 是始终匆忙的状态，这可提高 CPU 的利用率； 系统吞吐量：吞吐量表示的是单位时间内 CPU 完成进程的数量，长作业的进程会占用较长的 CPU 资源，因此会降低吞吐量，相反，短作业的进程会提升系统吞吐量； 周转时间：周转时间是进程运行和阻塞时间总和，一个进程的周转时间越小越好； 等待时间：这个等待时间不是阻塞状态的时间，而是进程处于就绪队列的时间，等待的时间越长，用户越不满意； 响应时间：用户提交请求到系统第一次产生响应所花费的时间，在交互式系统中，响应时间是衡量调度算法好坏的主要标准。 说白了，这么多调度原则，目的就是要使得进程要「快」。 调度算法不同的调度算法适用的场景也是不同的。 接下来，说说在单核 CPU 系统中常见的调度算法。 01 先来先服务调度算法 最简单的一个调度算法，就是非抢占式的先来先服务（_First Come First Severd, FCFS_）算法了。 FCFS 调度算法 顾名思义，先来后到，每次从就绪队列选择最先进入队列的进程，然后一直运行，直到进程退出或被阻塞，才会继续从队列中选择第一个进程接着运行。 这似乎很公平，但是当一个长作业先运行了，那么后面的短作业等待的时间就会很长，不利于短作业。 FCFS 对长作业有利，适用于 CPU 繁忙型作业的系统，而不适用于 I/O 繁忙型作业的系统。 02 最短作业优先调度算法 最短作业优先（_Shortest Job First, SJF_）调度算法同样也是顾名思义，它会优先选择运行时间最短的进程来运行，这有助于提高系统的吞吐量。 SJF 调度算法 这显然对长作业不利，很容易造成一种极端现象。 比如，一个长作业在就绪队列等待运行，而这个就绪队列有非常多的短作业，那么就会使得长作业不断的往后推，周转时间变长，致使长作业长期不会被运行。 03 高响应比优先调度算法 前面的「先来先服务调度算法」和「最短作业优先调度算法」都没有很好的权衡短作业和长作业。 那么，高响应比优先 （_Highest Response Ratio Next, HRRN_）调度算法主要是权衡了短作业和长作业。 每次进行进程调度时，先计算「响应比优先级」，然后把「响应比优先级」最高的进程投入运行，「响应比优先级」的计算公式： 从上面的公式，可以发现： 如果两个进程的「等待时间」相同时，「要求的服务时间」越短，「响应比」就越高，这样短作业的进程容易被选中运行； 如果两个进程「要求的服务时间」相同时，「等待时间」越长，「响应比」就越高，这就兼顾到了长作业进程，因为进程的响应比可以随时间等待的增加而提高，当其等待时间足够长时，其响应比便可以升到很高，从而获得运行的机会； 04 时间片轮转调度算法 最古老、最简单、最公平且使用最广的算法就是时间片轮转（_Round Robin, RR_）调度算法。。 RR 调度算法 每个进程被分配一个时间段，称为时间片（_Quantum_），即允许该进程在该时间段中运行。 如果时间片用完，进程还在运行，那么将会把此进程从 CPU 释放出来，并把 CPU 分配另外一个进程； 如果该进程在时间片结束前阻塞或结束，则 CPU 立即进行切换； 另外，时间片的长度就是一个很关键的点： 如果时间片设得太短会导致过多的进程上下文切换，降低了 CPU 效率； 如果设得太长又可能引起对短作业进程的响应时间变长。将 通常时间片设为 20ms~50ms 通常是一个比较合理的折中值。 05 最高优先级调度算法 前面的「时间片轮转算法」做了个假设，即让所有的进程同等重要，也不偏袒谁，大家的运行时间都一样。 但是，对于多用户计算机系统就有不同的看法了，它们希望调度是有优先级的，即希望调度程序能从就绪队列中选择最高优先级的进程进行运行，这称为最高优先级（_Highest Priority First，HPF_）调度算法。 进程的优先级可以分为，静态优先级或动态优先级： 静态优先级：创建进程时候，就已经确定了优先级了，然后整个运行时间优先级都不会变化； 动态优先级：根据进程的动态变化调整优先级，比如如果进程运行时间增加，则降低其优先级，如果进程等待时间（就绪队列的等待时间）增加，则升高其优先级，也就是随着时间的推移增加等待进程的优先级。 该算法也有两种处理优先级高的方法，非抢占式和抢占式： 非抢占式：当就绪队列中出现优先级高的进程，运行完当前进程，再选择优先级高的进程。 抢占式：当就绪队列中出现优先级高的进程，当前进程挂起，调度优先级高的进程运行。 但是依然有缺点，可能会导致低优先级的进程永远不会运行。 06 多级反馈队列调度算法 多级反馈队列（_Multilevel Feedback Queue_）调度算法是「时间片轮转算法」和「最高优先级算法」的综合和发展。 顾名思义： 「多级」表示有多个队列，每个队列优先级从高到低，同时优先级越高时间片越短。 「反馈」表示如果有新的进程加入优先级高的队列时，立刻停止当前正在运行的进程，转而去运行优先级高的队列； 多级反馈队列 来看看，它是如何工作的： 设置了多个队列，赋予每个队列不同的优先级，每个队列优先级从高到低，同时优先级越高时间片越短； 新的进程会被放入到第一级队列的末尾，按先来先服务的原则排队等待被调度，如果在第一级队列规定的时间片没运行完成，则将其转入到第二级队列的末尾，以此类推，直至完成； 当较高优先级的队列为空，才调度较低优先级的队列中的进程运行。如果进程运行时，有新进程进入较高优先级的队列，则停止当前运行的进程并将其移入到原队列末尾，接着让较高优先级的进程运行； 可以发现，对于短作业可能可以在第一级队列很快被处理完。对于长作业，如果在第一级队列处理不完，可以移入下次队列等待被执行，虽然等待的时间变长了，但是运行时间也会更长了，所以该算法很好的兼顾了长短作业，同时有较好的响应时间。 看的迷迷糊糊？那我拿去银行办业务的例子，把上面的调度算法串起来，你还不懂，你锤我！ 办理业务的客户相当于进程，银行窗口工作人员相当于 CPU。 现在，假设这个银行只有一个窗口（单核 CPU ），那么工作人员一次只能处理一个业务。 银行办业务 那么最简单的处理方式，就是先来的先处理，后面来的就乖乖排队，这就是先来先服务（_FCFS_）调度算法。但是万一先来的这位老哥是来贷款的，这一谈就好几个小时，一直占用着窗口，这样后面的人只能干等，或许后面的人只是想简单的取个钱，几分钟就能搞定，却因为前面老哥办长业务而要等几个小时，你说气不气人？ 先来先服务 有客户抱怨了，那我们就要改进，我们干脆优先给那些几分钟就能搞定的人办理业务，这就是短作业优先（_SJF_）调度算法。听起来不错，但是依然还是有个极端情况，万一办理短业务的人非常的多，这会导致长业务的人一直得不到服务，万一这个长业务是个大客户，那不就捡了芝麻丢了西瓜 最短作业优先 那就公平起见，现在窗口工作人员规定，每个人我只处理 10 分钟。如果 10 分钟之内处理完，就马上换下一个人。如果没处理完，依然换下一个人，但是客户自己得记住办理到哪个步骤了。这个也就是时间片轮转（_RR_）调度算法。但是如果时间片设置过短，那么就会造成大量的上下文切换，增大了系统开销。如果时间片过长，相当于退化成退化成 FCFS 算法了。 时间片轮转 既然公平也可能存在问题，那银行就对客户分等级，分为普通客户、VIP 客户、SVIP 客户。只要高优先级的客户一来，就第一时间处理这个客户，这就是最高优先级（_HPF_）调度算法。但依然也会有极端的问题，万一当天来的全是高级客户，那普通客户不是没有被服务的机会，不把普通客户当人是吗？那我们把优先级改成动态的，如果客户办理业务时间增加，则降低其优先级，如果客户等待时间增加，则升高其优先级。 最高优先级（静态） 那有没有兼顾到公平和效率的方式呢？这里介绍一种算法，考虑的还算充分的，多级反馈队列（_MFQ_）调度算法，它是时间片轮转算法和优先级算法的综合和发展。它的工作方式： 多级反馈队列 银行设置了多个排队（就绪）队列，每个队列都有不同的优先级，各个队列优先级从高到低，同时每个队列执行时间片的长度也不同，优先级越高的时间片越短。 新客户（进程）来了，先进入第一级队列的末尾，按先来先服务原则排队等待被叫号（运行）。如果时间片用完客户的业务还没办理完成，则让客户进入到下一级队列的末尾，以此类推，直至客户业务办理完成。 当第一级队列没人排队时，就会叫号二级队列的客户。如果客户办理业务过程中，有新的客户加入到较高优先级的队列，那么此时办理中的客户需要停止办理，回到原队列的末尾等待再次叫号，因为要把窗口让给刚进入较高优先级队列的客户。 可以发现，对于要办理短业务的客户来说，可以很快的轮到并解决。对于要办理长业务的客户，一下子解决不了，就可以放到下一个队列，虽然等待的时间稍微变长了，但是轮到自己的办理时间也变长了，也可以接受，不会造成极端的现象，可以说是综合上面几种算法的优点。","categories":[{"name":"操作系统","slug":"操作系统","permalink":"https://topone233.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"https://topone233.github.io/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"进程与线程","slug":"进程与线程","permalink":"https://topone233.github.io/tags/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B/"}]},{"title":"十大经典排序算法(Java)","slug":"十大经典排序算法(Java)","date":"2020-07-21T06:14:54.671Z","updated":"2020-09-14T12:30:39.341Z","comments":true,"path":"2020/07/21/十大经典排序算法(Java)/","link":"","permalink":"https://topone233.github.io/2020/07/21/%E5%8D%81%E5%A4%A7%E7%BB%8F%E5%85%B8%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95(Java)/","excerpt":"","text":"1.排序算法说明1.1 排序的定义对一序列对象根据某个关键字进行排序。本文对十大排序算法进行解读。 1.2 术语说明 稳定：如果 a 原本在 b 前面，而 a=b，排序之后 a 仍然在 b 的前面； 不稳定：如果 a 原本在 b 的前面，而 a=b，排序之后 a 可能会出现在 b 的后面； 内排序：所有排序操作都在内存中完成； 外排序：由于数据太大，因此把数据放在磁盘中，而排序通过磁盘和内存的数据传输才能进行； 时间复杂度： 一个算法执行所耗费的时间。 空间复杂度：运行完一个程序所需内存的大小。 1.3 算法总结 图片名词解释： n: 数据规模 k: “桶” 的个数 In-place: 占用常数内存，不占用额外内存 Out-place: 占用额外内存 1.4 算法分类 1.5 比较和非比较的区别常见的快速排序、归并排序、堆排序、冒泡排序等属于比较排序。在排序的最终结果里，元素之间的次序依赖于它们之间的比较。每个数都必须和其他数进行比较，才能确定自己的位置。在冒泡排序之类的排序中，问题规模为 n，又因为需要比较 n 次，所以平均时间复杂度为 O(n²)。在归并排序、快速排序之类的排序中，问题规模通过分治法消减为 logN 次，所以时间复杂度平均 O(nlogn)。比较排序的优势是，适用于各种规模的数据，也不在乎数据的分布，都能进行排序。可以说，比较排序适用于一切需要排序的情况。 计数排序、基数排序、桶排序则属于非比较排序。非比较排序是通过确定每个元素之前，应该有多少个元素来排序。针对数组 arr，计算 arr[i] 之前有多少个元素，则唯一确定了 arr[i] 在排序后数组中的位置。非比较排序只要确定每个元素之前的已有的元素个数即可，所有一次遍历即可解决。算法时间复杂度 O(n)。非比较排序时间复杂度底，但由于非比较排序需要占用空间来确定唯一位置。所以对数据规模和数据分布有一定的要求。 2.冒泡排序（Bubble Sort）冒泡排序是一种简单的排序算法。它重复地走访过要排序的数列，一次比较两个元素，如果它们的顺序错误就把它们交换过来。走访数列的工作是重复地进行直到没有再需要交换，也就是说该数列已经排序完成。这个算法的名字由来是因为越小的元素会经由交换慢慢 “浮” 到数列的顶端。 2.1 算法描述 比较相邻的元素。如果第一个比第二个大，就交换它们两个； 对每一对相邻元素作同样的工作，从开始第一对到结尾的最后一对，这样在最后的元素应该会是最大的数； 针对所有的元素重复以上的步骤，除了最后一个； 重复步骤 1~3，直到排序完成。 2.2 动图演示 2.3 代码实现 /** * 冒泡排序 * 依次比较相邻两个元素，并调整位置 * 一趟排序后最大的数“冒泡”成功，到最右边 * 重复“冒泡” * @param array * @return */ public static int[] bubbleSort(int[] array) { if (array == null || array.length == 0) { return array; } // 外层：length-1次循环 for (int i = 0; i &lt; array.length - 1; i++) { for (int j = 0; j &lt; array.length - 1 - i; j++) { // 将较小的与大的交换位置 if (array[j + 1] &lt; array[j]) { // 采用临时变量法交换 int temp = array[j + 1]; array[j + 1] = array[j]; array[j] = temp; } } } return array; }2.4 算法分析冒泡排序是稳定的排序算法，最容易实现的排序, 最坏的情况是每次都需要交换, 共需遍历并交换将近n²/2次, 时间复杂度为O(n²). 最佳的情况是内循环遍历一次后发现排序是对的, 因此退出循环, 时间复杂度为O(n). 平均来讲, 时间复杂度为O(n²). 由于冒泡排序中只有缓存的temp变量需要内存空间, 因此空间复杂度为常量O(1)。 3.选择排序（Selection Sort）无论什么数据进去都是 O(n^2) 的时间复杂度，所以用到它的时候，数据规模越小越好。唯一的好处可能就是不占用额外的内存空间了吧。理论上讲，选择排序可能也是平时排序一般人想到的最多的排序方法了吧。 选择排序 (Selection-sort) 是一种简单直观的排序算法。它的工作原理：首先在未排序序列中找到最小（大）元素，存放到排序序列的起始位置，然后，再从剩余未排序元素中继续寻找最小（大）元素，然后放到已排序序列的末尾。以此类推，直到所有元素均排序完毕。 3.1 算法描述n 个记录的直接选择排序可经过 n-1 趟直接选择排序得到有序结果。具体算法描述如下： 初始状态：无序区为 R[1..n]，有序区为空； 第 i 趟排序 (i=1,2,3…n-1) 开始时，当前有序区和无序区分别为 R[1..i-1]和 R(i..n）。该趟排序从当前无序区中 - 选出关键字最小的记录 R[k]，将它与无序区的第 1 个记录 R 交换，使 R[1..i]和 R[i+1..n)分别变为记录个数增加 1 个的新有序区和记录个数减少 1 个的新无序区； n-1 趟结束，数组有序化了。 3.2 动图演示 3.3 代码实现 /** * 选择排序 * 遍历数组，在未排序的队列，找到最小或最大的数，放在左边形成有序队列 * @param array * @return */ public static int[] selectionSort(int[] array) { if (array.length == 0) { return array; } for (int i = 0; i &lt; array.length - 1; i++) { int minIndex = i; for (int j = i + 1; j &lt; array.length; j++) { // 找到最小的数 if (array[j] &lt; array[minIndex]) // 将最小数的索引保存 minIndex = j; } // 将i位置元素与找到的最小数，交换位置 if (minIndex != i) { int temp = array[minIndex]; array[minIndex] = array[i]; array[i] = temp; } } return array; }3.4 算法分析最佳情况：O(n^2) 最差情况：O(n^2) 平均情况： O(n^2) 4.插入排序（Insertion Sort）插入排序（Insertion-Sort）的算法描述是一种简单直观的排序算法。它的工作原理是通过构建有序序列，对于未排序数据，在已排序序列中从后向前扫描，找到相应位置并插入。插入排序在实现上，通常采用 in-place 排序（即只需用到 O(1) 的额外空间的排序），因而在从后向前扫描过程中，需要反复把已排序元素逐步向后挪位，为最新元素提供插入空间。 4.1 算法描述一般来说，插入排序都采用 in-place 在数组上实现。具体算法描述如下： 从第一个元素开始，该元素可以认为已经被排序； 取出下一个元素，在已经排序的元素序列中从后向前扫描； 如果该元素（已排序）大于新元素，将该元素移到下一位置； 重复步骤 3，直到找到已排序的元素小于或者等于新元素的位置； 将新元素插入到该位置后； 重复步骤 2~5。 4.2 动图演示 4.3 代码实现提供两种写法，一种是移位法，一种是交换法。移位法是完全按照以上算法描述实，再插入过程中将有序序列中比待插入数字大的数据向后移动，由于移动时会覆盖待插入数据，所以需要额外的临时变量保存待插入数据，代码实现如下： /** * 插入排序-移位法 * 每次在右侧未排序队列，选中一个元素，在左侧有序队列中，找适合自己的位置，并插入 * @param array * @return */ public static int[] insertionSort(int[] arr) { if (arr == null || arr.length == 0) { return arr; } for (int i = 0; i &lt; arr.length; i++) { int j = i - 1; // temp即被选中，进行操作的元素 int temp = a[i]; // 如果比待插入数据大，就后移 while (j &gt;= 0 &amp;&amp; temp &lt; arr[j]) { // j位置元素大，后移，腾出位置 arr[j + 1] = arr[j]; // 一直向前，直到找到合适的位置 j--; } // 找到比待插入数据小的位置，将待插入数据插入 arr[j + 1] = temp; } return arr; }而交换法不需求额外的保存待插入数据，通过不停的向前交换带插入数据，类似冒泡法，直到找到比它小的值，也就是待插入数据找到了自己的位置: public static void insertionSort(int[] arr) { if (arr == null || arr.length == 0) { return; } for (int i = 1; i &lt; arr.length; i++) { int j = i - 1; while (j &gt;= 0 &amp;&amp; arr[j] &gt; arr[i]) { // 只要大就交换操作 arr[j + 1] = arr[j] + arr[j+1]; arr[j] = arr[j + 1] - arr[j]; arr[j + 1] = arr[j + 1] - arr[j]; System.out.println(&quot;Sorting: &quot; + Arrays.toString(arr)); } } }4.4 算法分析最佳情况： O(n) 最坏情况： O(n^2) 平均情况： O(n^2) 空间复杂度：O(1) 5.希尔排序（Shell Sort）希尔排序是希尔（Donald Shell）于 1959 年提出的一种排序算法。希尔排序也是一种插入排序，它是简单插入排序经过改进之后的一个更高效的版本，也称为缩小增量排序，同时该算法是冲破 O(n2）的第一批算法之一。它与插入排序的不同之处在于，它会优先比较距离较远的元素; 直接插入排序是稳定的；而希尔排序是不稳定的。希尔排序又叫缩小增量排序。 希尔排序是把记录按一定增量分组，对每组使用直接插入排序算法排序；随着增量逐渐减少，每组包含的关键词越来越多，当增量减至 1 时，整个文件恰被分成一组，算法便终止。 5.1 算法描述我们来看下希尔排序的基本步骤，在此我们选择增量 gap=length/2，缩小增量继续以 gap = gap/2 的方式，这种增量选择我们可以用一个序列来表示，{n/2,(n/2)/2…1}，称为增量序列。希尔排序的增量序列的选择与证明是个数学难题，我们选择的这个增量序列是比较常用的，也是希尔建议的增量，称为希尔增量，但其实这个增量序列不是最优的。此处我们做示例使用希尔增量。 先将整个待排序的记录序列分割成为若干子序列分别进行直接插入排序，具体算法描述： 选择一个增量序列 t1，t2，…，tk，其中 ti&gt;tj，tk=1； 按增量序列个数 k，对序列进行 k 趟排序； 每趟排序，根据对应的增量 ti，将待排序列分割成若干长度为 m 的子序列，分别对各子表进行直接插入排序。仅增量因子为 1 时，整个序列作为一个表来处理，表长度即为整个序列的长度。 5.2 过程演示 5.3 代码实现 /** * 希尔排序 * * @param array * @return */ public static int[] ShellSort(int[] array) { int len = array.length; // 初始增量gap int temp, gap = len / 2; while (gap &gt; 0) { for (int i = gap; i &lt; len; i++) { // temp放分组的第二个数，即中位数gap右边元素 temp = array[i]; // preIndex：分组第一个数 = i与中位数gap的差 = i自增的次数 = 左侧下标 int preIndex = i - gap; //如果左侧元素大，交换位置 while (preIndex &gt;= 0 &amp;&amp; array[preIndex] &gt; temp) { array[preIndex + gap] = array[preIndex]; preIndex -= gap; } array[preIndex + gap] = temp; } gap /= 2; } return array; } 第二种写法： public static int[] ShellSort(int[] arr) { int gap = arr.length / 2; // 不断缩小gap，直到1为止 for (;gap &gt; 0; gap = gap/2) { // j用来控制分组内多个元素时，比较的次数 for (int j = 0; (j + gap) &lt; arr.length; j++) { // k左侧元素，k+gap=右侧元素。依次调整每个分组 for (int k = 0; (k + gap) &lt; arr.length; k++) { if (arr[k] &gt; arr[k+gap]) { // 交换操作 arr[k] = arr[k] + arr[k+gap]; arr[k+gap] = arr[k] - arr[k+gap]; arr[k] = arr[k] - arr[k+gap]; System.out.println(&quot; Sorting: &quot; + Arrays.toString(arr)); }5.4 算法分析*最佳情况： O(nlog n) 最坏情况： O(nlog n) 平均情况：O(nlog n) * 6.归并排序（Merge Sort）和选择排序一样，归并排序的性能不受输入数据的影响，但表现比选择排序好的多，因为始终都是 O(n log n）的时间复杂度。代价是需要额外的内存空间。 归并排序是建立在归并操作上的一种有效的排序算法。该算法是采用分治法（Divide and Conquer）的一个非常典型的应用。归并排序是一种稳定的排序方法。将已有序的子序列合并，得到完全有序的序列；即先使每个子序列有序，再使子序列段间有序。若将两个有序表合并成一个有序表，称为 2 - 路归并。 6.1 算法描述 把长度为 n 的输入序列分成两个长度为 n/2 的子序列； 对这两个子序列分别采用归并排序； 将两个排序好的子序列合并成一个最终的排序序列。 6.2 动图演示 6.3 代码实现 /** * 归并排序 * 先分治，在合并 * @param array * @return */ public static int[] MergeSort(int[] array) { if (array.length &lt;= 1) { return array; } // &gt;&gt; 1 等价于 /2 int mid = array.length &gt;&gt; 1; int[] left = Arrays.copyOfRange(array, 0, mid); int[] right = Arrays.copyOfRange(array, mid, array.length); return merge(MergeSort(left), MergeSort(right)); } /** * 归并排序——将两段排序好的数组结合成一个排序数组 * * @param left * @param right * @return */ public static int[] merge(int[] left, int[] right) { int[] result = new int[left.length + right.length]; int i = 0, j = 0, k = 0; while (i &lt; left.length &amp;&amp; j &lt; right.length) { if (left[i] &lt;= right[j]) { result[k++] = left[i++]; }else { result[k++] = right[j++]; } } // left中的剩余元素移入结果数组 while (i &lt; left.length) { result[k++] = left[i++]； } // right中的剩余元素移入结果数组 while (j &lt; right.length) { result[k++] = right[j++]; } return result; }6.4 算法分析最佳情况：O(nlog n) 最差情况：O(nlog n) 平均情况： O(nlog n) 空间复杂度：O(n) 7.快速排序（Quick Sort）快速排序的基本思想：通过一趟排序将待排记录分隔成独立的两部分，其中一部分记录的关键字均比另一部分的关键字小，则可分别对这两部分记录继续进行快速排序，以达到整个序列有序。 7.1 算法描述快速排序使用分治法来把一个串（list）分为两个子串（sub-lists）。具体算法描述如下： 从数列中挑出一个元素，称为 “基准”（pivot）； 重新排序数列，所有元素比基准值小的摆放在基准前面，所有元素比基准值大的摆在基准的后面（相同的数可以到任一边）。在这个分区退出之后，该基准就处于数列的中间位置。这个称为分区（partition）操作； 递归地（recursive）把小于基准值元素的子数列和大于基准值元素的子数列排序。 7.2 动图演示 7.3 代码实现 /** * 快速排序方法（左右指针法） * 从左至右依次选择元素作为基准，比较之后的元素 * 将小于基准的元素一起放到基准左边（无须排序）， * @param array * @param start * @param end * @return */ public static int[] QuickSort(int[] array, int start, int end) { if (array.length &lt; 1 || start &lt; 0 || end &gt;= array.length || start &gt; end) { return null; } int smallIndex = partition(array, start, end); if (smallIndex &gt; start) QuickSort(array, start, smallIndex - 1); if (smallIndex &lt; end) QuickSort(array, smallIndex + 1, end); return array; } /** * 快速排序算法——partition * @param array * @param start * @param end * @return */ public static int partition(int[] array, int start, int end) { int pivot = (int) (start + Math.random() * (end - start + 1)); int smallIndex = start - 1; swap(array, pivot, end); for (int i = start; i &lt;= end; i++) if (array[i] &lt;= array[end]) { smallIndex++; if (i &gt; smallIndex) swap(array, i, smallIndex); } return smallIndex; } /** * 交换数组内两个元素 * @param array * @param i * @param j */ public static void swap(int[] array, int i, int j) { int temp = array[i]; array[i] = array[j]; array[j] = temp; }7.4 算法分析最佳情况： O(nlog n) 最差情况： O(n^2) 平均情况： O(nlog n) 空间复杂度：O(1) 8.堆排序（Heap Sort）堆排序（Heapsort）是指利用堆这种数据结构所设计的一种排序算法。堆积是一个近似完全二叉树的结构，并同时满足堆积的性质：即子结点的键值或索引总是小于（或者大于）它的父节点。 8.1 算法描述 将初始待排序关键字序列 (R1,R2….Rn) 构建成大顶堆，此堆为初始的无序区；（一般升序采用大顶堆，降序采用小顶堆）； 将堆顶元素 R[1]与最后一个元素 R[n]交换，此时得到新的无序区 (R1,R2,……Rn-1) 和新的有序区(Rn，), 且满足 R[1,2…n-1]&lt;=R[n]； 恢复堆。由于交换后新的堆顶 R[1]可能违反堆的性质，因此需要对当前无序区 (R1,R2,……Rn-1) 调整为新堆，然后再次将 R[1]与无序区最后一个元素交换，得到新的无序区 (R1,R2….Rn-2) 和新的有序区(Rn-1,Rn)。不断重复此过程直到有序区的元素个数为 n-1，则整个排序过程完成。 8.2 动图演示 8.3 代码实现注意：这里用到了完全二叉树的部分性质：详情见《数据结构二叉树知识点总结》 /** * 堆排序 * 构建大顶堆，交换堆顶元素与末尾元素，恢复大顶堆 * 每次将最大值“沉”到数组末端，升序 * @param arr */ public static void sort(int[] arr) { // 1.构建大顶堆 // 从最后一个非叶子节点开始 for (int i = arr.length / 2 - 1; i &gt;= 0; i--) { // 第一个非叶子节点i，从下至上、从左至右调整结构 adjustHeap(arr, i, arr.length); } // 2.交换堆顶与末尾 + 调整堆结构 // j就是末尾元素 for (int j = arr.length-1; j &gt; 0; j--) { // swap方法，交换操作 swap(arr, i, j); // adjustHeap方法，重新调整堆结构 adjustHeap(arr, i, j); } } /** * 调整大顶堆（仅是调整过程，建立在大顶堆已构建的基础上） * @param arr * @param i * @param length */ public static void adjustHeap(int[] arr, int i, int length) { // 以i节点为父节点，先将值放到temp保存 int temp = arr[i]; // 从i节点的左子节点开始，找出最大值，放到父节点位置 for (int k = i*2+1; k &lt; length; k = k*2+1) { // 如果左子节点小于右子节点，k指向右子节点 if (k+1 &lt; length &amp;&amp; arr[k] &lt; arr[k + 1]) { k++; } // 如果子节点大于父节点，将子节点值赋给父节点，最终使i为最大值 // 注意，这里k覆盖了i位置元素 if (arr[k] &gt; temp) { arr[i] = arr[k]; i = k; }else { break; } } // 此时才真正确定i的位置，将保存的值还给i arr[i] = temp; } /** * 交换元素 * @param arr * @param a * @param b */ public static void swap(int[] arr, int a, int b) { int temp = arr[a]; arr[a] = arr[b]; arr[b] = temp; }8.4 算法分析由于堆排序中初始化堆的过程比较次数较多, 因此它不太适用于小序列。同时由于多次任意下标相互交换位置, 相同元素之间原本相对的顺序被破坏了, 因此, 它是不稳定的排序。 最佳情况： O(nlogn) 最差情况： O(nlogn) 平均情况： O(nlogn) 空间复杂度：O(1) 9.计数排序（Counting Sort）计数排序的核心在于将输入的数据值转化为键存储在额外开辟的数组空间中。 作为一种线性时间复杂度的排序，计数排序要求输入的数据必须是有确定范围的整数。 计数排序 (Counting sort) 是一种稳定的排序算法。计数排序使用一个额外的数组 C，其中第 i 个元素是待排序数组 A 中值等于 i 的元素的个数。然后根据数组 C 来将 A 中的元素排到正确的位置。它只能对整数进行排序。 9.1 算法描述 找出待排序的数组中最大和最小的元素； 统计数组中每个值为 i 的元素出现的次数，存入数组 C 的第 i 项； 对所有的计数累加（从 C 中的第一个元素开始，每一项和前一项相加）； 反向填充目标数组：将每个元素 i 放在新数组的第 C(i) 项，每放一个元素就将 C(i) 减去 1。 9.2 动图演示 9.3 代码实现/** * 计数排序 * * @param array * @return */ public static int[] CountingSort(int[] array) { if (array.length == 0) return array; int bias, min = array[0], max = array[0]; for (int i = 1; i &lt; array.length; i++) { if (array[i] &gt; max) max = array[i]; if (array[i] &lt; min) min = array[i]; } bias = 0 - min; int[] bucket = new int[max - min + 1]; Arrays.fill(bucket, 0); for (int i = 0; i &lt; array.length; i++) { bucket[array[i] + bias]++; } int index = 0, i = 0; while (index &lt; array.length) { if (bucket[i] != 0) { array[index] = i - bias; bucket[i]--; index++; } else i++; } return array; }9.4 算法分析当输入的元素是 n 个 0 到 k 之间的整数时，它的运行时间是 O(n + k)。计数排序不是比较排序，排序的速度快于任何比较排序算法。由于用来计数的数组 C 的长度取决于待排序数组中数据的范围（等于待排序数组的最大值与最小值的差加上 1），这使得计数排序对于数据范围很大的数组，需要大量时间和内存。 最佳情况： O(n+k) 最差情况： O(n+k) 平均情况： O(n+k) 10.桶排序（Bucket Sort）桶排序是计数排序的升级版。它利用了函数的映射关系，高效与否的关键就在于这个映射函数的确定。 桶排序 (Bucket sort) 的工作的原理：假设输入数据服从均匀分布，将数据分到有限数量的桶里，每个桶再分别排序（有可能再使用别的排序算法或是以递归方式继续使用桶排序进行排 10.1 算法描述 人为设置一个 BucketSize，作为每个桶所能放置多少个不同数值（例如当 BucketSize==5 时，该桶可以存放｛1,2,3,4,5｝这几种数字，但是容量不限，即可以存放 100 个 3）； 遍历输入数据，并且把数据一个一个放到对应的桶里去； 对每个不是空的桶进行排序，可以使用其它排序方法，也可以递归使用桶排序； 从不是空的桶里把排好序的数据拼接起来。 注意，如果递归使用桶排序为各个桶排序，则当桶数量为 1 时要手动减小 BucketSize 增加下一循环桶的数量，否则会陷入死循环，导致内存溢出。 10.2 图片演示 10.3 代码实现 /** * 桶排序 * * @param array * @param bucketSize * @return */ public static ArrayList&lt;Integer&gt; BucketSort(ArrayList&lt;Integer&gt; array, int bucketSize) { if (array == null || array.size() &lt; 2) return array; int max = array.get(0), min = array.get(0); // 找到最大值最小值 for (int i = 0; i &lt; array.size(); i++) { if (array.get(i) &gt; max) max = array.get(i); if (array.get(i) &lt; min) min = array.get(i); } int bucketCount = (max - min) / bucketSize + 1; ArrayList&lt;ArrayList&lt;Integer&gt;&gt; bucketArr = new ArrayList&lt;&gt;(bucketCount); ArrayList&lt;Integer&gt; resultArr = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; bucketCount; i++) { bucketArr.add(new ArrayList&lt;Integer&gt;()); } for (int i = 0; i &lt; array.size(); i++) { bucketArr.get((array.get(i) - min) / bucketSize).add(array.get(i)); } for (int i = 0; i &lt; bucketCount; i++) { if (bucketSize == 1) { // 如果带排序数组中有重复数字时 感谢 @见风任然是风 朋友指出错误 for (int j = 0; j &lt; bucketArr.get(i).size(); j++) resultArr.add(bucketArr.get(i).get(j)); } else { if (bucketCount == 1) bucketSize--; ArrayList&lt;Integer&gt; temp = BucketSort(bucketArr.get(i), bucketSize); for (int j = 0; j &lt; temp.size(); j++) resultArr.add(temp.get(j)); } } return resultArr; }10.4 算法分析桶排序最好情况下使用线性时间 O(n)，桶排序的时间复杂度，取决与对各个桶之间数据进行排序的时间复杂度，因为其它部分的时间复杂度都为 O(n)。很显然，桶划分的越小，各个桶之间的数据越少，排序所用的时间也会越少。但相应的空间消耗就会增大。 *最佳情况： O(n+k) 最差情况： O(n+k) 平均情况： O(n^2) * 11.基数排序（Radix Sort）将所有待比较数值（正整数）统一为同样的数位长度，数位较短的数前面补零。然后，从最低位开始，依次进行一次排序。这样从最低位排序一直到最高位排序完成以后，数列就变成一个有序序列。 基数排序按照优先从高位或低位来排序有两种实现方案： MSD（Most significant digital） 从最左侧高位开始进行排序。先按k1排序分组, 同一组中记录, 关键码k1相等, 再对各组按k2排序分成子组, 之后, 对后面的关键码继续这样的排序分组, 直到按最次位关键码kd对各子组排序后. 再将各组连接起来, 便得到一个有序序列。MSD方式适用于位数多的序列。 LSD（Least significant digital） 从最右侧低位开始进行排序。先从kd开始排序，再对kd-1进行排序，依次重复，直到对k1排序后便得到一个有序序列。LSD方式适用于位数少的序列。 基数排序基于分别排序，分别收集，不改变相同元素之间的相对顺序，所以是稳定的。 下面以LSD为例。 11.1 算法描述 取得数组中的最大数，并取得位数； arr 为原始数组，从最低位开始取每个位组成 radix 数组； 对 radix 进行计数排序（利用计数排序适用于小范围数的特点）； 11.2 动图演示 11.3 代码实现 /** * 基数排序 * @param array * @return */ public static int[] RadixSort(int[] array) { if (array == null || array.length &lt; 2) { return array; } // 1.先算出最大数的位数； int max = array[0]; for (int i = 1; i &lt; array.length; i++) { if (a[i] &gt; max) { max = a[i]; } } int maxDigit = 0; while (max != 0) { max /= 10; maxDigit++; } int[][] buckets = new int[10][a.length]; int base = 10; //从低位到高位，对每一位遍历，将所有元素分配到桶中 for (int i = 0; i &lt; maxDigit; i++) { //存储各个桶中存储元素的数量 int[] bucketLen = new int[10]; //收集：将不同桶里数据挨个捞出来,为下一轮高位排序做准备,由于靠近桶底的元素排名靠前,因此从桶底先捞 for (int j = 0; j &lt; a.length; j++) { int whichBucket = (a[j] % base) / (base / 10); buckets[whichBucket][bucketLen[whichBucket]] = a[j]; bucketLen[whichBucket]++; } int k = 0; //收集：将不同桶里数据挨个捞出来,为下一轮高位排序做准备,由于靠近桶底的元素排名靠前,因此从桶底先捞 for (int l = 0; l &lt; buckets.length; l++) { for (int m =0; m &lt; bucketLen[l]; m++) { a[k++] = buckets[l][m]; } } System.out.println(&quot;Sorting: &quot; + Arrays.toString(a)); base *= 10; } return array; }11.4 算法分析最佳情况：O(d(n+r)) 最差情况：O(d(n+r)) 平均情况：O(d*(n+r)) 空间复杂度: O(n+r) 其中，d 为位数，r 为基数，n 为原数组个数。在基数排序中，因为没有比较操作，所以在复杂上，最好的情况与最坏的情况在时间上是一致的，均为 O(d*(n + r))。 基数排序更适合用于对时间, 字符串等这些整体权值未知的数据进行排序，适用于。 (1)数据范围较小，建议在小于1000 (2)每个数值都要大于等于0 基数排序 vs 计数排序 vs 桶排序 这三种排序算法都利用了桶的概念，但对桶的使用方法上有明显差异： 基数排序：根据键值的每位数字来分配桶 计数排序：每个桶只存储单一键值 桶排序：每个桶存储一定范围的数值 参考资料：https://juejin.im/post/5b95da8a5188255c775d8124 https://www.cnblogs.com/guoyaohua/p/8600214.html https://www.cnblogs.com/Young111/p/11300929.html","categories":[{"name":"数据结构","slug":"数据结构","permalink":"https://topone233.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}],"tags":[{"name":"Java","slug":"java","permalink":"https://topone233.github.io/tags/java/"},{"name":"数据结构","slug":"数据结构","permalink":"https://topone233.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"排序算法","slug":"排序算法","permalink":"https://topone233.github.io/tags/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/"}]},{"title":"反射、注解和动态代理","slug":"反射、注解和动态代理","date":"2020-07-20T08:48:44.137Z","updated":"2020-09-07T14:19:58.249Z","comments":true,"path":"2020/07/20/反射、注解和动态代理/","link":"","permalink":"https://topone233.github.io/2020/07/20/%E5%8F%8D%E5%B0%84%E3%80%81%E6%B3%A8%E8%A7%A3%E5%92%8C%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86/","excerpt":"","text":"原文地址 一、Java 反射机制及基本用法反射是指计算机程序在运行时访问、检测和修改它本身状态或行为的一种能力，是一种元编程语言特性，有很多语言都提供了对反射机制的支持，它使程序能够编写程序。Java 的反射机制使得 Java 能够动态的获取类的信息和调用对象的方法。 在 Java 中，Class（类类型）是反射编程的起点，代表运行时类型信息（RTTI，Run-Time Type Identification）。java.lang.reflect 包含了 Java 支持反射的主要组件，如 Constructor、Method 和 Field 等，分别表示类的构造器、方法和域，它们的关系如下图所示。 Constructor 和 Method 与 Field 的区别在于前者继承自抽象类 Executable，是可以在运行时动态调用的，而 Field 仅仅具备可访问的特性，且默认为不可访问。下面了解下它们的基本用法： 获取 Class 对象有三种方式，Class.forName 适合于已知类的全路径名，典型应用如加载 JDBC 驱动。对同一个类，不同方式获得的 Class 对象是相同的。 // 1. 采用Class.forName获取类的Class对象 Class clazz0 = Class.forName(&quot;com.yhthu.java.ClassTest&quot;); System.out.println(&quot;clazz0:&quot; + clazz0); // 2. 采用.class方法获取类的Class对象 Class clazz1 = ClassTest.class; System.out.println(&quot;clazz1:&quot; + clazz1); // 3. 采用getClass方法获取类的Class对象 ClassTest classTest = new ClassTest(); Class clazz2 = classTest.getClass(); System.out.println(&quot;clazz2:&quot; + clazz2); // 4. 判断Class对象是否相同 System.out.println(&quot;Class对象是否相同:&quot; + ((clazz0.equals(clazz1)) &amp;&amp; (clazz1.equals(clazz2)))); 注意：三种方式获取的 Class 对象相同的前提是使用了相同的类加载器，比如上述代码中默认采用应用程序类加载器（sun.misc.Launcher$AppClassLoader）。不同类加载器加载的同一个类，也会获取不同的 Class 对象： // 自定义类加载器 ClassLoader myLoader = new ClassLoader() { @Override public Class&lt;?&gt; loadClass(String name) throws ClassNotFoundException { try { String fileName = name.substring(name.lastIndexOf(&quot;.&quot;) + 1) + &quot;.class&quot;; InputStream is = getClass().getResourceAsStream(fileName); if (is == null) { return super.loadClass(name); } byte[] b = new byte[is.available()]; is.read(b); return defineClass(name, b, 0, b.length); } catch (IOException e) { throw new ClassNotFoundException(name); } } }; // 采用自定义类加载器加载 Class clazz3 = Class.forName(&quot;com.yhthu.java.ClassTest&quot;, true, myLoader); // clazz0与clazz3并不相同 System.out.println(&quot;Class对象是否相同:&quot; + clazz0.equals(clazz3)); 通过 Class 的 getDeclaredXxxx 和 getXxx 方法获取构造器、方法和域对象，两者的区别在于前者返回的是当前 Class 对象申明的构造器、方法和域，包含修饰符为 private 的；后者只返回修饰符为 public 的构造器、方法和域，但包含从基类中继承的。 // 返回申明为public的方法，包含从基类中继承的 for (Method method: String.class.getMethods()) { System.out.println(method.getName()); } // 返回当前类申明的所有方法，包含private的 for (Method method: String.class.getDeclaredMethods()) { System.out.println(method.getName()); } 通过 Class 的 newInstance 方法和 Constructor 的 newInstance 方法方法均可新建类型为 Class 的对象，通过 Method 的 invoke 方法可以在运行时动态调用该方法，通过 Field 的 set 方法可以在运行时动态改变域的值，但需要首先设置其为可访问（setAccessible）。 二、注解注解（Annotation）是 Java5 引入的一种代码辅助工具，它的核心作用是对类、方法、变量、参数和包进行标注，通过反射来访问这些标注信息，以此在运行时改变所注解对象的行为。Java 中的注解由内置注解和元注解组成。内置注解主要包括： @Override - 检查该方法是否是重载方法。如果发现其父类，或者是引用的接口中并没有该方法时，会报编译错误。 @Deprecated - 标记过时方法。如果使用该方法，会报编译警告。 @SuppressWarnings - 指示编译器去忽略注解中声明的警告。 @SafeVarargs - Java 7 开始支持，忽略任何使用参数为泛型变量的方法或构造函数调用产生的警告。 @FunctionalInterface - Java 8 开始支持，标识一个匿名函数或函数式接口。 这里，我们重点关注元注解，元注解位于 java.lang.annotation 包中，主要用于自定义注解。元注解包括： @Retention - 标识这个注解怎么保存，是只在代码中，还是编入 class 文件中，或者是在运行时可以通过反射访问，枚举类型分为别 SOURCE、CLASS 和 RUNTIME； @Documented - 标记这些注解是否包含在用户文档中。 @Target - 标记这个注解应该是哪种 Java 成员，枚举类型包括 TYPE、FIELD、METHOD、CONSTRUCTOR 等； @Inherited - 标记这个注解可以继承超类注解，即子类 Class 对象可使用 getAnnotations() 方法获取父类被 @Inherited 修饰的注解，这个注解只能用来申明类。 @Repeatable - Java 8 开始支持，标识某注解可以在同一个声明上使用多次。 自定义元注解需重点关注两点：1）注解的数据类型；2）反射获取注解的方法。首先，注解中的方法并不支持所有的数据类型，仅支持八种基本数据类型、String、Class、enum、Annotation 和它们的数组。比如以下代码会产生编译时错误： @Documented @Inherited @Target(ElementType.TYPE) @Retention(RetentionPolicy.RUNTIME) public @interface AnnotationTest { // 1. 注解数据类型不能是Object；2. 默认值不能为null Object value() default null; // 支持的定义方式 String value() default &quot;&quot;; }其次，上节中提到的反射相关类（Class、Constructor、Method 和 Field）和 Package 均实现了 AnnotatedElement 接口，该接口定义了访问反射信息的方法，主要如下： // 获取指定注解类型 getAnnotation(Class&lt;T&gt;):T; // 获取所有注解，包括从父类继承的 getAnnotations():Annotation[]; // 获取指定注解类型，不包括从父类继承的 getDeclaredAnnotation(Class&lt;T&gt;):T // 获取所有注解，不包括从父类继承的 getDeclaredAnnotations():Annotation[]; // 判断是否存在指定注解 isAnnotationPresent(Class&lt;? extends Annotation&gt;:boolean当使用上例中的 AnnotationTest 标注某个类后，便可在运行时通过该类的反射方法访问注解信息了。 @AnnotationTest(&quot;yhthu&quot;) public class AnnotationReflection { public static void main(String[] args) { AnnotationReflection ar = new AnnotationReflection(); Class clazz = ar.getClass(); // 判断是否存在指定注解 if (clazz.isAnnotationPresent(AnnotationTest.class)) { // 获取指定注解类型 Annotation annotation = clazz.getAnnotation(AnnotationTest.class); // 获取该注解的值 System.out.println(((AnnotationTest) annotation).value()); } } } 当自定义注解只有一个方法 value() 时，使用注解可只写值，例如：@AnnotationTest(“yhthu”) 三、动态代理参考上一篇：动态代理 代理是一种结构型设计模式，当无法或不想直接访问某个对象，或者访问某个对象比较复杂的时候，可以通过一个代理对象来间接访问，代理对象向客户端提供和真实对象同样的接口功能。经典设计模式中，代理模式有四种角色： Subject 抽象主题类——申明代理对象和真实对象共同的接口方法； RealSubject 真实主题类——实现了 Subject 接口，真实执行业务逻辑的地方； ProxySubject 代理类——实现了 Subject 接口，持有对 RealSubject 的引用，在实现的接口方法中调用 RealSubject 中相应的方法执行； Cliect 客户端类——使用代理对象的类。 在实现上，代理模式分为静态代理和动态代理，静态代理的代理类二进制文件是在编译时生成的，而动态代理的代理类二进制文件是在运行时生成并加载到虚拟机环境的。JDK 提供了对动态代理接口的支持，开源的动态代理库（Cglib、Javassist 和 Byte Buddy）提供了对接口和类的代理支持，本节将简单比较 JDK 和 Cglib 实现动态代理的异同，后续章节会对 Java 字节码编程做详细分析。 3.1 JDK 动态代理接口JDK 实现动态代理是通过 Proxy 类的 newProxyInstance 方法实现的，该方法的三个入参分别表示： public static Object newProxyInstance(ClassLoader loader, Class&lt;?&gt;[] interfaces, InvocationHandler h) ClassLoader loader，定义代理生成的类的加载器，可以自定义类加载器，也可以复用当前 Class 的类加载器； Class&lt;?&gt;[] interfaces，定义代理对象需要实现的接口； InvocationHandler h，定义代理对象调用方法的处理，其 invoke 方法中的 Object proxy 表示生成的代理对象，Method 表示代理方法， Object[] 表示方法的参数。 通常的使用方法如下： private Object getProxy() { return Proxy.newProxyInstance(JDKProxyTest.class.getClassLoader(), new Class&lt;?&gt;[]{Subject.class}, new MyInvocationHandler(new RealSubject())); } private static class MyInvocationHandler implements InvocationHandler { private Object realSubject; public MyInvocationHandler(Object realSubject) { this.realSubject = realSubject; } @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { System.out.println(&quot;Some thing before method invoke&quot;); Object result = method.invoke(realSubject, args); System.out.println(&quot;Some thing after method invoke&quot;); return result; } }类加载器采用当前类的加载器，默认为应用程序类加载器（sun.misc.Launcher$AppClassLoader）；接口数组以 Subject.class 为例，调用方法处理类 MyInvocationHandler 实现 InvocationHandler 接口，并在构造器中传入 Subject 的真正的业务功能服务类 RealSubject，在执行 invoke 方法时，可以在实际方法调用前后织入自定义的处理逻辑，这也就是 AOP（面向切面编程）的原理。关于 JDK 动态代理，有两个问题需要清楚： Proxy.newProxyInstance 的代理类是如何生成的？Proxy.newProxyInstance 生成代理类的核心分成两步： // 1. 获取代理类的Class对象 Class&lt;?&gt; cl = getProxyClass0(loader, intfs); // 2. 利用Class获取Constructor，通过反射生成对象 cons.newInstance(new Object[]{h});与反射获取 Class 对象时搜索 classpath 路径的. class 文件不同的是，这里的 Class 对象完全是 “无中生有” 的。getProxyClass0 根据类加载器和接口集合返回了 Class 对象，这里采用了缓存的处理。 // 缓存(key, sub-key) -&gt; value，其中key为类加载器，sub-key为代理的接口，value为Class对象 private static final WeakCache&lt;ClassLoader, Class&lt;?&gt;[], Class&lt;?&gt;&gt; proxyClassCache = new WeakCache&lt;&gt;(new KeyFactory(), new ProxyClassFactory()); // 如果实现了代理接口的类已存在就返回缓存对象，否则就通过ProxyClassFactory生成 private static Class&lt;?&gt; getProxyClass0(ClassLoader loader, Class&lt;?&gt;... interfaces) { if (interfaces.length &gt; 65535) { throw new IllegalArgumentException(&quot;interface limit exceeded&quot;); } return proxyClassCache.get(loader, interfaces); }如果实现了代理接口的类已存在就返回缓存对象，否则就通过 ProxyClassFactory 生成。ProxyClassFactory 又是通过下面的代码生成 Class 对象的。 // 生成代理类字节码文件 byte[] proxyClassFile = ProxyGenerator.generateProxyClass(proxyName, interfaces, accessFlags); try { // defineClass0为native方法，生成Class对象 return defineClass0(loader, proxyName, proxyClassFile, 0, proxyClassFile.length); } catch (ClassFormatError e) { throw new IllegalArgumentException(e.toString()); }generateProxyClass 方法是用来生成字节码文件的，根据生成的字节码文件，再在 native 层生成 Class 对象。 InvocationHandler 的 invoke 方法是怎样调用的？回答这个问题得先看下上面生成的 Class 对象究竟是什么样的，将 ProxyGenerator 生成的字节码保存成文件，然后反编译打开（IDEA 直接打开），可见生成的 Proxy.class 主要包含 equals、toString、hashCode 和代理接口的 request 方法实现。 public final class $Proxy extends Proxy implements Subject { // m1 = Object的equals方法 private static Method m1; // m2 = Object的toString方法 private static Method m2; // Subject的request方法 private static Method m3; // Object的hashCode方法 private static Method m0; // 省略m1/m2/m0，此处只列出request方法实现 public final void request() throws { try { super.h.invoke(this, m3, (Object[])null); } catch (RuntimeException | Error var2) { throw var2; } catch (Throwable var3) { throw new UndeclaredThrowableException(var3); } } }由于生成的代理类继承自 Proxy，super.h 即是 Prxoy 的 InvocationHandler，即代理类的 request 方法直接调用了 InvocationHandler 的实现，这就回答了 InvocationHandler 的 invoke 方法是如何被调用的了。 3.2 Cglib 动态代理接口和类Cglib 的动态代理是通过 Enhancer 类实现的，其 create 方法生成动态代理的对象，有五个重载方法： create():Object create(Class, Callback):Object create(Class, Class[], Callback):Object create(Class, Class[], CallbackFilter, Callback):Object create(Class[], Object):Object常用的是第二个和第三个方法，分别用于动态代理类和动态代理接口，其使用方法如下： private Object getProxy() { // 1. 动态代理类 return Enhancer.create(RealSubject.class, new MyMethodInterceptor()); // 2. 动态代理接口 return Enhancer.create(Object.class, new Class&lt;?&gt;[]{Subject.class}, new MyMethodInterceptor()); } private static class MyMethodInterceptor implements MethodInterceptor { @Override public Object intercept(Object obj, Method method, Object[] args, MethodProxy proxy) throws Throwable { System.out.println(&quot;Some thing before method invoke&quot;); Object result = proxy.invokeSuper(obj, args); System.out.println(&quot;Some thing after method invoke&quot;); return result; } }从上小节可知，JDK 只能代理接口，代理生成的类实现了接口的方法；而 Cglib 是通过继承被代理的类、重写其方法来实现的，如：create 方法入参的第一个参数就是被代理类的类型。当然，Cglib 也能代理接口，比如 getProxy() 方法中的第二种方式。","categories":[{"name":"Java","slug":"java","permalink":"https://topone233.github.io/categories/java/"}],"tags":[{"name":"Java","slug":"java","permalink":"https://topone233.github.io/tags/java/"}]},{"title":"动态代理","slug":"动态代理","date":"2020-07-20T07:51:44.059Z","updated":"2020-09-07T14:20:25.604Z","comments":true,"path":"2020/07/20/动态代理/","link":"","permalink":"https://topone233.github.io/2020/07/20/%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86/","excerpt":"","text":"原文地址 代理模式为其他对象提供一个代理以控制对某个对象的访问。代理类主要负责为委托了（真实对象）预处理：消息、过滤消息、传递消息给委托类，代理类不现实具体服务，而是利用委托类来完成服务，并将执行结果封装处理。类似于生活中的中介。 有一个打印机的类 public class Printer { public void print(){ System.out.println(&quot;打印！&quot;); } }我想在打印之前先记录一下日志怎么做？ 最简单的方法：在打印的功能前面直接加上记录日志的功能。 public class Printer { public void print(){ System.out.println(&quot;记录日志！&quot;); System.out.println(&quot;打印！&quot;); } }看上去好像没有问题，但是我们修改了打印机的源代码，破坏了面向对象的开闭原则，有可能影响到其它功能。怎么解决呢？很容易可以想到，既然不能修改原来的代码，那我新建一个类吧。 public class LogPrinter extends Printer { public void print(){ System.out.println(&quot;记录日志！&quot;); System.out.println(&quot;打印！&quot;); } }这个类继承了打印机的类，重写了打印机的 print 方法，提供了记录日志的功能，以后需要打印机的时候使用这个类就好。问题似乎得到了解决，我们可以在这个解决方案的基础上进一步的优化： 静态代理先抽象出一个接口: public interface IPrinter { void print(); }打印机类（被代理类）实现这个接口: public class Printer implements IPrinter { @Override public void print(){ System.out.println(&quot;打印！&quot;); } }创建打印机代理类也实现该接口 被代理类被传递给了代理类PrinterProxy，代理类在执行具体方法时通过所持用的被代理类完成调用。 在构造函数中将打印机对象传进去，实现接口的打印方法时调用打印机对象的打印方法并在前面加上记录日志的功能: public class PrinterProxy implements IPrinter { private Printer printer; public PrinterProxy(){ this.printer = new printer(); } @Override public void print() { System.out.println(&quot;记录日志&quot;); printer.print(); } }试一把： public class Test { public static void main(String[] args) { PrinterProxy proxy = new PrinterProxy(); proxy.print(); } }结果出来了： 记录日志 打印以后我们就可以直接实例化 PrinterProxy 对象调用它的打印方法了，这就是静态代理模式，通过抽象出接口让程序的扩展性和灵活性更高了。 静态代理的缺点静态代理是完美无缺的吗？ 考虑一下，如果我的打印机类中还有别的方法，也需要加上记录日志的功能，但是静态代理只能为一个类服务，就不得不将记录日志的功能写 n 遍。进一步如果我还有电视机，电冰箱的类里面的所有方法也需要加上记录日志的功能，那要重复的地方就更多了。 怎么办？ 动态代理闪亮登场： 动态代理要想不重复写记录日志的功能，针对每一个接口实现一个代理类的做法肯定不可行了，可不可以让这些代理类的对象自动生成呢？ 利用反射机制在运行时创建代理类。 Jdk 提供了 invocationHandler 接口和 Proxy 类，借助这两个工具可以达到我们想要的效果。 invocationHandler 接口上场： //Object proxy:被代理的对象 //Method method:要调用的方法 //Object[] args:方法调用时所需要参数 public interface InvocationHandler { public Object invoke(Object proxy, Method method, Object[] args) throws Throwable; }接口里只有一个方法 invoke，这个方法非常重要，先混个脸熟，稍后解释。 Proxy 类上场，它里面有一个很重要的方法 newProxyInstance： //CLassLoader loader:被代理对象的类加载器 //Class&lt;?&gt; interfaces:被代理类全部的接口 //InvocationHandler h:实现InvocationHandler接口的对象 public static Object newProxyInstance(ClassLoader loader, Class&lt;?&gt;[] interfaces, InvocationHandler h) throws IllegalArgumentException 调用 Proxy 的 newProxyInstance 方法可以生成代理对象 一切准备就绪动态代理模式千呼万唤始出来： 接口 IPrinter 和 该接口的实现类 Printer 的代码同前。 实现一个类，该类用来创建代理对象，_它实现了_InvocationHandler 接口： public class ProxyHandler implements InvocationHandler { private Object targetObject;//被代理的对象 //将被代理的对象传入获得它的类加载器和实现接口作为Proxy.newProxyInstance方法的参数。 public Object newProxyInstance(Object targetObject){ this.targetObject = targetObject; //targetObject.getClass().getClassLoader()：被代理对象的类加载器 //targetObject.getClass().getInterfaces()：被代理对象的实现接口 //this 当前对象，该对象实现了InvocationHandler接口所以有invoke方法，通过invoke方法可以调用被代理对象的方法 return Proxy.newProxyInstance(targetObject.getClass().getClassLoader(),targetObject.getClass().getInterfaces(),this); } //该方法在代理对象调用方法时调用 @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { System.out.println(&quot;记录日志&quot;); return method.invoke(targetObject,args); } }被代理的对象 targetObject 可以通过方法参数传进来： public Object newProxyInstance(Object targetObject){ this.targetObject=targetObject;我们重点来分析一下这段代码： return Proxy.newProxyInstance(targetObject.getClass().getClassLoader(),targetObject.getClass().getInterfaces(),this);动态代理对象就是通过调用这段代码被创建并返回的。 方法有三个参数： 第一个参数： targetObject.getClass().getClassLoader()：targetObject 对象的类加载器。 第二个参数: targetObject.getClass().getInterfaces()：targetObject 对象的所有接口 第三个参数: this：也就是当前对象即实现了 InvocationHandler 接口的类的对象，在调用方法时会调用它的 invoke 方法。 再来看一下这段代码： public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { //在这里可以通过判断方法名来决定执行什么功能 System.out.println(&quot;记录日志&quot;); //调用被代理对象的方法 return method.invoke(targetObject, args); }这个方法就是生成的代理类中的方法被调用时会去自动调用的方法，可以看到在这个方法中调用了被代理对象的方法: method.invoke(targetObject, args); 我们可以在这里加上需要的业务逻辑，比如调用方法前记录日志功能. 见证奇迹的时刻到了： public class Test { public static void main(String[] args){ ProxyHandler proxyHandler=new ProxyHandler(); IPrinter printer = (IPrinter) proxyHandler.newProxyInstance(new Printer()); printer.print(); } }打印结果： 记录日志 打印当执行 printer.print(); 时会自动调用 invoke 方法，很多初学者不理解为什么能调用这个方法，回忆一下创建代理对象的时候是通过 return Proxy.newProxyInstance(targetObject.getClass().getClassLoader(),targetObject.getClass().getInterfaces(),this);来创建的，方法的第三个参数 this 是实现了 InvocationHandler 接口的对象， InvocationHandler 接口有 invoke 方法。现在有点思路了吧~ 将被代理的对象作为参数传入就可以执行里面的任意方法，所有的方法调用都通过 invoke 来完成。不用对每个方法进行处理，动态代理是不是很简洁。 动态代理的优势 Proxy 类的代码量被固定下来，不会因为业务的逐渐庞大而庞大； 可以实现 AOP 编程，实际上静态代理也可以实现，总的来说，AOP 可以算作是代理模式的一个典型应用； 解耦，通过参数就可以判断真实类，不需要事先实例化，更加灵活多变。 复习对象的创建很多初学 Java 的朋友眼中创建对象的过程 实际上可以换个角度，也说得通 所谓的 Class 对象，是 Class 类的实例，而 Class 类是描述所有类的，比如 Person 类，Student 类 可以看出，要创建一个实例，最关键的就是得到对应的 Class 对象。只不过对于初学者来说，new 这个关键字配合构造方法，实在太好用了，底层隐藏了太多细节，一句 Person p = new Person(); 直接把对象返回给你了。我自己刚开始学 Java 时，也没意识到 Class 对象的存在。 分析到这里，貌似有了思路： 能否不写代理类，而直接得到代理 Class 对象，然后根据它创建代理实例（反射) ? Class 对象包含了一个类的所有信息，比如构造器、方法、字段等。如果我们不写代理类，这些信息从哪获取呢？苦思冥想，突然灵光一现：代理类和目标类理应实现同一组接口。之所以实现相同接口，是为了尽可能保证代理对象的内部结构和目标对象一致，这样我们对代理对象的操作最终都可以转移到目标对象身上，代理对象只需专注于增强代码的编写。还是上面这幅图： 所以，可以这样说：接口拥有代理对象和目标对象共同的类信息。所以，我们可以从接口那得到理应由代理类提供的信息。但是别忘了，接口是无法创建对象的，怎么办？ JDK 提供了 java.lang.reflect.InvocationHandler 接口和 java.lang.reflect.Proxy 类，这两个类相互配合，入口是 Proxy，所以我们先聊它。 ProxyProxy 有个静态方法：getProxyClass(ClassLoader, interfaces)，只要你给它传入类加载器和一组接口，它就给你返回代理 Class 对象。 用通俗的话说，getProxyClass() 这个方法，会从你传入的接口 Class 中，“拷贝” 类结构信息到一个新的 Class 对象中，但新的 Class 对象带有构造器，是可以创建对象的。打个比方，一个大内太监（接口 Class），空有一身武艺（类信息），但是无法传给后人。现在江湖上有个妙手神医（Proxy 类），发明了克隆大法（getProxyClass），不仅能克隆太监的一身武艺，还保留了小 DD（构造器）…（这到底是道德の沦丧，还是人性的扭曲，欢迎走进动态代理） 所以，一旦我们明确接口，完全可以通过接口的 Class 对象，创建一个代理 Class，通过代理 Class 即可创建代理对象。 所以，按我理解，Proxy.getProxyClass() 这个方法的本质就是：以 Class 造 Class。 有了 Class 对象，就很好办了，具体看代码： 完美。 根据代理 Class 的构造器创建对象时，需要传入 InvocationHandler。每次调用代理对象的方法，最终都会调用 InvocationHandler 的 invoke() 方法： 怎么做到的呢？ 上面不是说了吗，根据代理 Class 的构造器创建对象时，需要传入 InvocationHandler。通过构造器传入一个引用，那么必然有个成员变量去接收。没错，代理对象的内部确实有个成员变量 invocationHandler，而且代理对象的每个方法内部都会调用 handler.invoke()！InvocationHandler 对象成了代理对象和目标对象的桥梁，不像静态代理这么直接。 大家仔细看上图右侧的动态代理，我在 invocationHandler 的 invoke() 方法中并没有写目标对象。因为一开始 invocationHandler 的 invoke() 里确实没有目标对象，需要我们手动 new。 但这种写法不够优雅，属于硬编码。我这次代理 A 对象，下次想代理 B 对象还要进来改 invoke() 方法，太差劲了。改进一下，让调用者把目标对象作为参数传进来： public class ProxyTest { public static void main(String[] args) throws Throwable { CalculatorImpl target = new CalculatorImpl(); //传入目标对象 //目的：1.根据它实现的接口生成代理对象 2.代理对象调用目标对象方法 Calculator calculatorProxy = (Calculator) getProxy(target); calculatorProxy.add(1, 2); calculatorProxy.subtract(2, 1); } private static Object getProxy(final Object target) throws Exception { //参数1：随便找个类加载器给它， 参数2：目标对象实现的接口，让代理对象实现相同接口 Class proxyClazz = Proxy.getProxyClass(target.getClass().getClassLoader(), target.getClass().getInterfaces()); Constructor constructor = proxyClazz.getConstructor(InvocationHandler.class); Object proxy = constructor.newInstance(new InvocationHandler() { @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { System.out.println(method.getName() + &quot;方法开始执行...&quot;); Object result = method.invoke(target, args); System.out.println(result); System.out.println(method.getName() + &quot;方法执行结束...&quot;); return result; } }); return proxy; } } 这样就非常灵活，非常优雅了。无论现在系统有多少类，只要你把实例传进来，getProxy() 都能给你返回对应的代理对象。就这样，我们完美地跳过了代理类，直接创建了代理对象！ 不过实际编程中，一般不用 getProxyClass()，而是使用 Proxy 类的另一个静态方法：Proxy.newProxyInstance()，直接返回代理实例，连中间得到代理 Class 对象的过程都帮你隐藏： public class ProxyTest { public static void main(String[] args) throws Throwable { CalculatorImpl target = new CalculatorImpl(); Calculator calculatorProxy = (Calculator) getProxy(target); calculatorProxy.add(1, 2); calculatorProxy.subtract(2, 1); } private static Object getProxy(final Object target) throws Exception { Object proxy = Proxy.newProxyInstance( target.getClass().getClassLoader(),/*类加载器*/ target.getClass().getInterfaces(),/*让代理对象和目标对象实现相同接口*/ new InvocationHandler(){/*代理对象的方法最终都会被JVM导向它的invoke方法*/ public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { System.out.println(method.getName() + &quot;方法开始执行...&quot;); Object result = method.invoke(target, args); System.out.println(result); System.out.println(method.getName() + &quot;方法执行结束...&quot;); return result; } } ); return proxy; } } 现在，我想应该能看懂动态代理了。 最后讨论一下代理对象是什么类型。 首先，请区分两个概念：代理 Class 对象和代理对象。 单从名字看，代理 Class 和 Calculator 的接口确实相去甚远，但是我们却能将代理对象赋值给接口类型： 千万别觉得名字奇怪，就怀疑它不能用接口接收，只要实现该接口就是该类型。 代理对象的本质就是：和目标对象实现相同接口的实例。代理 Class 可以叫任何名字，whatever，只要它实现某个接口，就能成为该接口类型。 我写了一个 MyProxy 类，那么它的 Class 名字必然叫 MyProxy。但这和能否赋值给接口没有任何关系。由于它实现了 Serializable 和 Collection，所以 myProxy（代理实例）同时是这两个接口的类型。 小结我想了个很骚的比喻，希望能解释清楚： 接口 Class 对象是大内太监，里面的方法和字段比做他的一身武艺，但是他没有小 DD（构造器），所以不能 new 实例。一身武艺后继无人。 那怎么办呢？ 正常途径（implements）： 写一个类，实现该接口。这个就相当于大街上拉了一个人，认他做干爹。一身武艺传给他，只是比他干爹多了小 DD，可以 new 实例。 非正常途径（动态代理）： 通过妙手圣医 Proxy 的克隆大法（Proxy.getProxyClass()），克隆一个 Class，但是有小 DD。所以这个克隆人 Class 可以创建实例，也就是代理对象。 代理 Class 其实就是附有构造器的接口 Class，一样的类结构信息，却能创建实例。 JDK 动态代理生成的实例 CGLib 动态代理生成的实例 如果说继承的父类是亲爹（只有一个），那么实现的接口是干爹（可以有多个）。 实现接口是一个类认干爹的过程。接口无法创建对象，但实现该接口的类可以。 比如 class Student extends Person implements A, B这个类 new 一个实例出来，你问它：你爸爸是谁啊？它会告诉你：我只有一个爸爸 Person。 但是 student instanceof A interface，或者 student instanceof B interface，它会告诉你两个都是它干爹（true），都可以用来接收它。 然而，凡是有利必有弊。 也就是说，动态代理生成的代理对象，最终都可以用接口接收，和目标对象一起形成了多态，可以随意切换展示不同的功能。但是切换的同时，只能使用该接口定义的方法。 类加载器初学者可能对诸如 “字节码文件”、Class 对象比较陌生。所以这里花一点点篇幅介绍一下类加载器的部分原理。如果我们要定义类加载器，需要继承 ClassLoader 类，并覆盖 findClass() 方法： @Override public Class&lt;?&gt; findClass(String name) throws ClassNotFoundException { try { /*自己另外写一个getClassData() 通过IO流从指定位置读取xxx.class文件得到字节数组*/ byte[] datas = getClassData(name); if(datas == null) { throw new ClassNotFoundException(&quot;类没有找到：&quot; + name); } //调用类加载器本身的defineClass()方法，由字节码得到Class对象 return this.defineClass(name, datas, 0, datas.length); } catch (IOException e) { e.printStackTrace(); throw new ClassNotFoundException(&quot;类找不到：&quot; + name); } } 所以，这就是类加载之所以能把 xxx.class 文件加载进内存，并创建对应 Class 对象的深层原因。","categories":[{"name":"Java","slug":"java","permalink":"https://topone233.github.io/categories/java/"}],"tags":[{"name":"Java","slug":"java","permalink":"https://topone233.github.io/tags/java/"},{"name":"动态代理","slug":"动态代理","permalink":"https://topone233.github.io/tags/%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86/"}]},{"title":"HashMap 剖析 (基于 jdk1.8)","slug":"HashMap 剖析 (基于 jdk1.8)","date":"2020-07-10T09:07:59.406Z","updated":"2020-09-15T08:29:01.440Z","comments":true,"path":"2020/07/10/HashMap 剖析 (基于 jdk1.8)/","link":"","permalink":"https://topone233.github.io/2020/07/10/HashMap%20%E5%89%96%E6%9E%90%20(%E5%9F%BA%E4%BA%8E%20jdk1.8)/","excerpt":"","text":"原文地址 www.cnblogs.com 本文的源码是基于 JDK1.8 版本，在学习 HashMap 之前，先了解数组和链表的知识。 数组数组具有遍历快，增删慢的特点。数组在堆中是一块连续的存储空间，遍历时数组的首地址是知道的（首地址 = 首地址 + 元素字节数 * 下标），所以遍历快（数组遍历的时间复杂度为 O(1) ）；增删慢是因为，当在中间插入或删除元素时，会造成该元素后面所有元素地址的改变，所以增删慢（增删的时间复杂度为 O(n) ）。 链表链表具有增删快，遍历慢的特点。链表中各元素的内存空间是不连续的，一个节点至少包含节点数据与后继节点的引用，所以在插入删除时，只需修改该位置的前驱节点与后继节点即可，链表在插入删除时的时间复杂度为 O(1)。但是在遍历时，get(n) 元素时，需要从第一个开始，依次拿到后面元素的地址，进行遍历，直到遍历到第 n 个元素（时间复杂度为 O(n) ），所以效率极低。 HashMapHash 表是一个数组 + 链表的结构，这种结构能够保证在遍历与增删的过程中，如果不产生 hash 碰撞，仅需一次定位就可完成，时间复杂度能保证在 O(1)。 在 jdk1.7 中，只是单纯的数组 + 链表的结构，但是如果散列表中的 hash 碰撞过多时，会造成效率的降低，所以在 JKD1.8 中对这种情况进行了控制，当一个 hash 值上的链表长度大于 8 时，该节点上的数据就不再以链表进行存储，而是转成了一个红黑树。 红黑树: static final class TreeNode&lt;K,V&gt; extends LinkedHashMap.Entry&lt;K,V&gt; { TreeNode&lt;K,V&gt; parent; // red-black tree links TreeNode&lt;K,V&gt; left; TreeNode&lt;K,V&gt; right; TreeNode&lt;K,V&gt; prev; // needed to unlink next upon deletion boolean red; } hash 碰撞hash 是指，两个元素通过 hash 函数计算出的值是一样的，是同一个存储地址。当后面的元素要插入到这个地址时，发现已经被占用了，这时候就产生了 hash 冲突 hash 冲突的解决方法开放定址法 (查询产生冲突的地址的下一个地址是否被占用，直到寻找到空的地址)，再散列法，链地址法等。hashmap 采用的就是链地址法，jdk1.7 中，当冲突时，在冲突的地址上生成一个链表，将冲突的元素的 key，通过 equals 进行比较，相同即覆盖，不同则添加到链表上，此时如果链表过长，效率就会大大降低，查找和添加操作的时间复杂度都为 O(n)；但是在 jdk1.8 中如果链表长度大于 8，链表就会转化为红黑树，下图就是 1.8 版本的（图片来源 https://segmentfault.com/a/1190000012926722），时间复杂度也降为了 O(logn)，性能得到了很大的优化。 HashMap 的底层实现首先，hashMap 的主干是一个 Node 数组（jdk1.7 及之前为 Entry 数组）每一个 Node 包含一个 key 与 value 的键值对，与一个 next 指向下一个 node，hashMap 由多个 Node 对象组成。 Node 是 HhaspMap 中的一个静态内部类 ： static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; { final int hash; final K key; V value; Node&lt;K,V&gt; next; Node(int hash, K key, V value, Node&lt;K,V&gt; next) { this.hash = hash; this.key = key; this.value = value; this.next = next; } public final K getKey() { return key; } public final V getValue() { return value; } public final String toString() { return key + &quot;=&quot; + value; } //hashCode等其他代码 } 再看下 hashMap 中几个重要的字段： //默认初始容量为16，0000 0001 左移4位 0001 0000为16，主干数组的初始容量为16，而且这个数组 //必须是2的倍数(后面说为什么是2的倍数) static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // aka 16 //最大容量为int的最大值除2 static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30; //默认加载因子为0.75 static final float DEFAULT_LOAD_FACTOR = 0.75f; //阈值，如果主干数组上的链表的长度大于8，链表转化为红黑树 static final int TREEIFY_THRESHOLD = 8; //hash表扩容后，如果发现某一个红黑树的长度小于6，则会重新退化为链表 static final int UNTREEIFY_THRESHOLD = 6; //当hashmap容量大于64时，链表才能转成红黑树 static final int MIN_TREEIFY_CAPACITY = 64; //临界值=主干数组容量*负载因子 int threshold； HashMap 的构造方法//initialCapacity为初始容量，loadFactor为负载因子 public HashMap(int initialCapacity, float loadFactor) { //初始容量小于0，抛出非法数据异常 if (initialCapacity &lt; 0) throw new IllegalArgumentException(&quot;Illegal initial capacity: &quot; + initialCapacity); //初始容量最大为MAXIMUM_CAPACITY if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; //负载因子必须大于0，并且是合法数字 if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(&quot;Illegal load factor: &quot; + loadFactor); this.loadFactor = loadFactor; //将初始容量转成2次幂 this.threshold = tableSizeFor(initialCapacity); } //tableSizeFor的作用就是，如果传入A，当A大于0，小于定义的最大容量时， //如果A是2次幂则返回A，否则将A转化为一个比A大且差距最小的2次幂。 //例如传入7返回8，传入8返回8，传入9返回16 static final int tableSizeFor(int cap) { int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1; } //调用上面的构造方法，自定义初始容量，负载因子为默认的0.75 public HashMap(int initialCapacity) { this(initialCapacity, DEFAULT_LOAD_FACTOR); } //默认构造方法，负载因子为0.75，初始容量为DEFAULT_INITIAL_CAPACITY=16，初始容量在第一次put时才会初始化 public HashMap() { this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted } //传入一个MAP集合的构造方法 public HashMap(Map&lt;? extends K, ? extends V&gt; m) { this.loadFactor = DEFAULT_LOAD_FACTOR; putMapEntries(m, false); } HashMap 的 put() 方法put 方法的源码分析是本篇的一个重点，因为通过该方法我们可以窥探到 HashMap 在内部是如何进行数据存储的，所谓的数组 + 链表 + 红黑树的存储结构是如何形成的，又是在何种情况下将链表转换成红黑树来优化性能的。带着一系列的疑问，我们看这个 put 方法： public V put(K key, V value) { return putVal(hash(key), key, value, false, true); } 也就是 put 方法调用了 putVal 方法，其中传入一个参数位 hash(key)，我们首先来看看 hash() 这个方法。 static final int hash(Object key) { int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16); } 此处如果传入的 int 类型的值：①向一个 Object 类型赋值一个 int 的值时，会将 int 值自动封箱为 Integer。②integer 类型的 hashcode 都是他自身的值，即 h=key；h &gt;&gt;&gt; 16 为无符号右移 16 位，低位挤走，高位补 0；^ 为按位异或，即转成二进制后，相异为 1，相同为 0，由此可发现，当传入的值小于 2 的 16 次方 - 1 时，调用这个方法返回的值，都是自身的值。然后再执行 putVal 方法： //onlyIfAbsent是true的话，不要改变现有的值 //evict为true的话，表处于创建模式 final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) { Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; //如果主干上的table为空，长度为0，调用resize方法，调整table的长度（resize方法在下图中） if ((tab = table) == null || (n = tab.length) == 0) /* 这里调用resize，其实就是第一次put时，对数组进行初始化。 如果是默认构造方法会执行resize中的这几句话： newCap = DEFAULT_INITIAL_CAPACITY; 新的容量等于默认值16 newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); threshold = newThr; 临界值等于16*0.75 Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; 将新的node数组赋值给table，然后return newTab 如果是自定义的构造方法则会执行resize中的： int oldThr = threshold; newCap = oldThr; 新的容量等于threshold，这里的threshold都是2的倍数，原因在 于传入的数都经过tableSizeFor方法，返回了一个新值，上面解释过 float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); threshold = newThr; 新的临界值等于 (int)(新的容量*负载因子) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; return newTab; */ n = (tab = resize()).length; //将调用resize后构造的数组的长度赋值给n if ((p = tab[i = (n - 1) &amp; hash]) == null) //将数组长度与计算得到的hash值比较 tab[i] = newNode(hash, key, value, null);//位置为空，将i位置上赋值一个node对象 else { //位置不为空 Node&lt;K,V&gt; e; K k; if (p.hash == hash &amp;&amp; // 如果这个位置的old节点与new节点的key完全相同 ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; // 则e=p else if (p instanceof TreeNode) // 如果p已经是树节点的一个实例，既这里已经是树了 e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else { //p与新节点既不完全相同，p也不是treenode的实例 for (int binCount = 0; ; ++binCount) { //一个死循环 if ((e = p.next) == null) { //e=p.next,如果p的next指向为null p.next = newNode(hash, key, value, null); //指向一个新的节点 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // 如果链表长度大于等于8 treeifyBin(tab, hash); //将链表转为红黑树 break; } if (e.hash == hash &amp;&amp; //如果遍历过程中链表中的元素与新添加的元素完全相同，则跳出循环 ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; //将p中的next赋值给p,即将链表中的下一个node赋值给p， //继续循环遍历链表中的元素 } } if (e != null) { //这个判断中代码作用为：如果添加的元素产生了hash冲突，那么调用 //put方法时，会将他在链表中他的上一个元素的值返回 V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) //判断条件成立的话，将oldvalue替换 //为newvalue，返回oldvalue；不成立则不替换，然后返回oldvalue e.value = value; afterNodeAccess(e); //这个方法在后面说 return oldValue; } } ++modCount; //记录修改次数 if (++size &gt; threshold) //如果元素数量大于临界值，则进行扩容 resize(); //下面说 afterNodeInsertion(evict); return null; } 在 Java 8 中，如果一个桶中的元素个数超过 TREEIFY_THRESHOLD(默认是 8)，就使用红黑树来替换链表，从而提高速度。上诉代码这个替换的方法叫 treeifyBin() 即树形化。 看一下 treeifyBin() 的源码: //将桶内所有的 链表节点 替换成 红黑树节点 final void treeifyBin(Node&lt;K,V&gt;[] tab, int hash) { int n, index; Node&lt;K,V&gt; e; //如果当前哈希表为空，或者哈希表中元素的个数小于 进行树形化的阈值(默认为 64)，就去新建/扩容 if (tab == null || (n = tab.length) &lt; MIN_TREEIFY_CAPACITY) resize(); else if ((e = tab[index = (n - 1) &amp; hash]) != null) { //如果哈希表中的元素个数超过了 树形化阈值，进行树形化 // e 是哈希表中指定位置桶里的链表节点，从第一个开始 TreeNode&lt;K,V&gt; hd = null, tl = null; //红黑树的头、尾节点 do { //新建一个树形节点，内容和当前链表节点 e 一致 TreeNode&lt;K,V&gt; p = replacementTreeNode(e, null); if (tl == null) //确定树头节点 hd = p; else { p.prev = tl; tl.next = p; } tl = p; } while ((e = e.next) != null); //让桶的第一个元素指向新建的红黑树头结点，以后这个桶里的元素就是红黑树而不是链表了 if ((tab[index] = hd) != null) hd.treeify(tab); } } TreeNode&lt;K,V&gt; replacementTreeNode(Node&lt;K,V&gt; p, Node&lt;K,V&gt; next) { return new TreeNode&lt;&gt;(p.hash, p.key, p.value, next); } 注释已经很详细了，咱们说一下这个初始化的问题 //如果 table 还未被初始化，那么初始化它 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; resize() 扩容机制，单元素如何散列到新的数组中，链表中的元素如何散列到新的数组中，红黑树中的元素如何散列到新的数组中？ //上图中说了默认构造方法与自定义构造方法第一次执行resize的过程，这里再说一下扩容的过程 final Node&lt;K,V&gt;[] resize() { Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; if (oldCap &gt; 0) { //扩容肯定执行这个分支 if (oldCap &gt;= MAXIMUM_CAPACITY) { //当容量超过最大值时，临界值设置为int最大值 threshold = Integer.MAX_VALUE; return oldTab; } else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) //扩容容量为2倍，临界值为2倍 newThr = oldThr &lt;&lt; 1; } else if (oldThr &gt; 0) // 不执行 newCap = oldThr; else { // 不执行 newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); } if (newThr == 0) { // 不执行 float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); } threshold = newThr; //将新的临界值赋值赋值给threshold @SuppressWarnings({&quot;rawtypes&quot;,&quot;unchecked&quot;}) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; //新的数组赋值给table //扩容后，重新计算元素新的位置 if (oldTab != null) { //原数组 for (int j = 0; j &lt; oldCap; ++j) { //通过原容量遍历原数组 Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) { //判断node是否为空，将j位置上的节点 //保存到e,然后将oldTab置为空，这里为什么要把他置为空呢，置为空有什么好处吗？？ //难道是吧oldTab变为一个空数组，便于垃圾回收？？ 这里不是很清楚 oldTab[j] = null; if (e.next == null) //判断node上是否有链表 newTab[e.hash &amp; (newCap - 1)] = e; //无链表，确定元素存放位置， //扩容前的元素地址为 (oldCap - 1) &amp; e.hash ,所以这里的新的地址只有两种可能，一是地址不变， //二是变为 老位置+oldCap else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else { // preserve order Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; /* 这里如果判断成立，那么该元素的地址在新的数组中就不会改变。因为oldCap的最高位的1，在e.hash对应的位上为0，所以扩容后得到的地址是一样的，位置不会改变 ，在后面的代码的执行中会放到loHead中去，最后赋值给newTab[j]； 如果判断不成立，那么该元素的地址变为 原下标位置+oldCap，也就是lodCap最高位的1，在e.hash对应的位置上也为1，所以扩容后的地址改变了，在后面的代码中会放到hiHead中，最后赋值给newTab[j + oldCap] 举个栗子来说一下上面的两种情况： 设：oldCap=16 二进制为：0001 0000 oldCap-1=15 二进制为：0000 1111 e1.hash=10 二进制为：0000 1010 e2.hash=26 二进制为：0101 1010 e1在扩容前的位置为：e1.hash &amp; oldCap-1 结果为：0000 1010 e2在扩容前的位置为：e2.hash &amp; oldCap-1 结果为：0000 1010 结果相同，所以e1和e2在扩容前在同一个链表上，这是扩容之前的状态。 现在扩容后，需要重新计算元素的位置，在扩容前的链表中计算地址的方式为e.hash &amp; oldCap-1 那么在扩容后应该也这么计算呀，扩容后的容量为oldCap*2=32 0010 0000 newCap=32，新的计算 方式应该为 e1.hash &amp; newCap-1 即：0000 1010 &amp; 0001 1111 结果为0000 1010与扩容前的位置完全一样。 e2.hash &amp; newCap-1 即：0101 1010 &amp; 0001 1111 结果为0001 1010,为扩容前位置+oldCap。 而这里却没有e.hash &amp; newCap-1 而是 e.hash &amp; oldCap，其实这两个是等效的，都是判断倒数第五位 是0，还是1。如果是0，则位置不变，是1则位置改变为扩容前位置+oldCap。 再来分析下loTail loHead这两个的执行过程（假设(e.hash &amp; oldCap) == 0成立）： 第一次执行： e指向oldTab[j]所指向的node对象，即e指向该位置上链表的第一个元素 loTail为空,所以loHead指向与e相同的node对象，然后loTail也指向了同一个node对象。 最后，在判断条件e指向next，就是指向oldTab链表中的第二个元素 第二次执行： lotail不为null，所以lotail.next指向e，这里其实是lotail指向的node对象的next指向e， 也可以说是，loHead的next指向了e，就是指向了oldTab链表中第二个元素。此时loHead指向 的node变成了一个长度为2的链表。然后lotail=e也就是指向了链表中第二个元素的地址。 第三次执行： 与第二次执行类似，loHead上的链表长度变为3，又增加了一个node，loTail指向新增的node ...... hiTail与hiHead的执行过程与以上相同，这里就不再做解释了。 由此可以看出，loHead是用来保存新链表上的头元素的，loTail是用来保存尾元素的，直到遍 历完链表。 这是(e.hash &amp; oldCap) == 0成立的时候。 (e.hash &amp; oldCap) == 0不成立的情况也相同，其实就是把oldCap遍历成两个新的链表， 通过loHead和hiHead来保存链表的头结点，然后将两个头结点放到newTab[j]与 newTab[j+oldCap]上面去 */ do { next = e.next; if ((e.hash &amp; oldCap) == 0) { if (loTail == null) loHead = e; else loTail.next = e; loTail = e; } else { if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; } } while ((e = next) != null); if (loTail != null) { loTail.next = null; //尾节点的next设置为空 newTab[j] = loHead; } if (hiTail != null) { hiTail.next = null; //尾节点的next设置为空 newTab[j + oldCap] = hiHead; } } } } } return newTab; } 有关 JDK1.7 扩容出现的死循环的问题: /** * Transfers all entries from current table to newTable. */ void transfer(Entry[] newTable) { Entry[] src = table; int newCapacity = newTable.length; for (int j = 0; j &lt; src.length; j++) { Entry&lt;K,V&gt; e = src[j]; if (e != null) { src[j] = null; do { // B线程执行到这里之后就暂停了 Entry&lt;K,V&gt; next = e.next; int i = indexFor(e.hash, newCapacity); e.next = newTable[i]; newTable[i] = e; e = next; } while (e != null); } } } 并发下的 Rehash 1）假设我们有两个线程。我用红色和浅蓝色标注了一下。我们再回头看一下我们的 transfer 代码中的这个细节： do { Entry&lt;K,V&gt; next = e.next; // &lt;--假设线程一执行到这里就被调度挂起了 int i = indexFor(e.hash, newCapacity); e.next = newTable[i]; newTable[i] = e; e = next; } while (e != null); 而我们的线程二执行完成了。于是我们有下面的这个样子。 注意，因为 Thread1 的 e 指向了 key(3)，而 next 指向了 key(7)，其在线程二 rehash 后，指向了线程二重组后的链表。我们可以看到链表的顺序被反转后。 2）线程一被调度回来执行。 先是执行 newTalbe[i] = e; 然后是 e = next，导致了 e 指向了 key(7)， 而下一次循环的 next = e.next 导致了 next 指向了 key(3) 3）一切安好。 线程一接着工作。把 key(7) 摘下来，放到 newTable[i] 的第一个，然后把 e 和 next 往下移。 4）环形链接出现。 e.next = newTable[i] 导致 key(3).next 指向了 key(7) 注意：此时的 key(7).next 已经指向了 key(3)， 环形链表就这样出现了。 于是，当我们的线程一调用到，HashTable.get(11) 时，悲剧就出现了——Infinite Loop。 因为 HashMap 本来就不支持并发。要并发就用 ConcurrentHashmap HashMap 的 get() 方法public V get(Object key) { Node&lt;K,V&gt; e; //直接调用了getNode() return (e = getNode(hash(key), key)) == null ? null : e.value; } final Node&lt;K,V&gt; getNode(int hash, Object key) { Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; //先判断数组是否为空，长度是否大于0，那个node节点是否存在 if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) { //如果找到，直接返回 if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; if ((e = first.next) != null) { //如果是红黑树，去红黑树找 if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); //链表找 do { if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; } while ((e = e.next) != null); } } return null; } 这里关于first = tab[(n - 1) &amp; hash] 这里通过(n - 1)&amp; hash即可算出桶的在桶数组中的位置，可能有的朋友不太明白这里为什么这么做，这里简单解释一下。HashMap 中桶数组的大小 length 总是 2 的幂，此时，(n - 1) &amp; hash 等价于对 length 取余。但取余的计算效率没有位运算高，所以(n - 1) &amp; hash也是一个小的优化。举个例子说明一下吧，假设 hash = 185，n = 16。计算过程示意图如下 在上面源码中，除了查找相关逻辑，还有一个计算 hash 的方法。这个方法源码如下： /** * 计算键的 hash 值 */ static final int hash(Object key) { int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16); } 看这个方法的逻辑好像是通过位运算重新计算 hash，那么这里为什么要这样做呢？为什么不直接用键的 hashCode 方法产生的 hash 呢？大家先可以思考一下，我把答案写在下面。 这样做有两个好处，我来简单解释一下。我们再看一下上面求余的计算图，图中的 hash 是由键的 hashCode 产生。计算余数时，由于 n 比较小，hash 只有低 4 位参与了计算，高位的计算可以认为是无效的。这样导致了计算结果只与低位信息有关，高位数据没发挥作用。为了处理这个缺陷，我们可以上图中的 hash 高 4 位数据与低 4 位数据进行异或运算，即 hash ^ (hash &gt;&gt;&gt; 4)。通过这种方式，让高位数据与低位数据进行异或，以此加大低位信息的随机性，变相的让高位数据参与到计算中。此时的计算过程如下： 在 Java 中，hashCode 方法产生的 hash 是 int 类型，32 位宽。前 16 位为高位，后 16 位为低位，所以要右移 16 位。 上面所说的是重新计算 hash 的一个好处，除此之外，重新计算 hash 的另一个好处是可以增加 hash 的复杂度。当我们覆写 hashCode 方法时，可能会写出分布性不佳的 hashCode 方法，进而导致 hash 的冲突率比较高。通过移位和异或运算，可以让 hash 变得更复杂，进而影响 hash 的分布性。这也就是为什么 HashMap 不直接使用键对象原始 hash 的原因了。 由于个人能力问题, 先学习这些, 数据结构这个大山, 我一定要刨平它。 基于 jdk1.7 版本的 HashMap https://www.jianshu.com/p/dde9b12343c1 参考博客: https://www.cnblogs.com/wenbochang/archive/2018/02/22/8458756.html https://segmentfault.com/a/1190000012926722 https://blog.csdn.net/pange1991/article/details/82377980","categories":[{"name":"数据结构","slug":"数据结构","permalink":"https://topone233.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}],"tags":[{"name":"Java","slug":"java","permalink":"https://topone233.github.io/tags/java/"},{"name":"数据结构","slug":"数据结构","permalink":"https://topone233.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"HashMap","slug":"hashmap","permalink":"https://topone233.github.io/tags/hashmap/"}]},{"title":"HashMap 面试必问总结","slug":"HashMap 面试必问总结","date":"2020-07-10T09:07:59.400Z","updated":"2020-09-15T08:28:49.083Z","comments":true,"path":"2020/07/10/HashMap 面试必问总结/","link":"","permalink":"https://topone233.github.io/2020/07/10/HashMap%20%E9%9D%A2%E8%AF%95%E5%BF%85%E9%97%AE%E6%80%BB%E7%BB%93/","excerpt":"","text":"原文地址 www.cnblogs.com 1.HashMap 的数据结构？​ 哈希表结构（链表散列：数组 + 链表）实现，结合数组和链表的优点。当链表长度超过 8 时，链表转换为红黑树。transient Node&lt;K,V&gt;[] table; 2.HashMap 的工作原理？ HashMap 底层是 hash 数组和单向链表实现，数组中的每个元素都是链表，由 Node 内部类（实现 Map.Entry&lt;K,V&gt; 接口）实现，HashMap 通过 put &amp; get 方法存储和获取。 存储对象时，将 K/V 键值传给 put() 方法： ​ ①、调用 hash(K) 方法计算 K 的 hash 值，然后结合数组长度，计算得数组下标； ​ ②、调整数组大小（当容器中的元素个数大于 capacity * loadfactor 时，容器会进行扩容 resize 为 2n）； ​ ③、如果 K 的 hash 值在 HashMap 中不存在，则执行插入，若存在，则发生碰撞； 如果 K 的 hash 值在 HashMap 中存在，且它们两者 equals 返回 true，则更新键值对； 如果 K 的 hash 值在 HashMap 中存在，且它们两者 equals 返回 false，则插入链表的尾部（尾插法）或者红黑树中。 （JDK 1.7 之前使用头插法、JDK 1.8 使用尾插法）（注意：当碰撞导致链表大于 TREEIFY_THRESHOLD = 8 时，就把链表转换成红黑树） 获取对象时，将 K 传给 get() 方法： ①、调用 hash(K) 方法（计算 K 的 hash 值）从而获取该键值所在链表的数组下标； ②、顺序遍历链表，equals() 方法查找相同 Node 链表中 K 值对应的 V 值。 hashCode 是定位的，找到存储位置；equals 是定性的，比较两者是否相等。 3. 当两个对象的 hashCode 相同会发生什么？ 因为 hashCode 相同，不一定就是相等的（equals 方法比较），如果两个对象所在数组的下标相同，”碰撞” 就此发生。又因为 HashMap 使用链表存储对象，这个 Node 会存储到链表中。 4. 你知道 hash 的实现吗？为什么要这样实现？ JDK 1.8 中，是通过 hashCode() 的高 16 位异或低 16 位实现的：(h = k.hashCode()) ^ (h &gt;&gt;&gt; 16)，主要是从速度，功效和质量来考虑的，减少系统的开销，也不会造成因为高位没有参与下标的计算，从而引起的碰撞。 5. 为什么要用异或运算符？​ 保证了对象的 hashCode 的 32 位值只要有一位发生改变，整个 hash() 返回值就会改变。尽可能的减少碰撞。 6. HashMap 的 table 的容量如何确定？loadFactor 是什么？ 该容量如何变化？这种变化会带来什么问题？​ ①、table 数组大小是由capacity这个参数确定的，默认是 16，也可以构造时传入，最大限制是 1&lt;&lt;30； ​ ②、loadFactor 是装载因子，主要目的是用来确认 table 数组是否需要动态扩展，默认值是 0.75，比如 table 数组大小为 16，装载 因子为 0.75 时，threshold 就是 12，当 table 的实际大小超过 12 时，table 就需要动态扩容； ​ ③、扩容时，调用 resize() 方法，将 table 长度变为原来的两倍（注意是 table 长度，而不是 threshold） ​ ④、如果数据很大的情况下，扩展时将会带来性能的损失，在性能要求很高的地方，这种损失很可能很致命。 7.HashMap 中 put 方法的过程？ 答：“调用哈希函数获取 Key 对应的 hash 值，再计算其数组下标； 如果没有出现哈希冲突，则直接放入数组；如果出现哈希冲突，则以链表的方式放在链表后面； 如果链表长度超过阀值 (TREEIFY THRESHOLD==8)，就把链表转成红黑树，链表长度低于 6，就把红黑树转回链表; 如果结点的 key 已经存在，则替换其 value 即可； 如果集合中的键值对大于 12，调用 resize 方法进行数组扩容。” 8. 数组扩容的过程？ 创建一个新的数组，其容量为旧数组的两倍，并重新计算旧数组中结点的存储位置。结点在新数组中的位置只有两种，原下标位置或原下标 + 旧数组的大小。 9. 拉链法导致的链表过深问题为什么不用二叉查找树代替，而选择红黑树？为什么不一直使用红黑树？​ 之所以选择红黑树是为了解决二叉查找树的缺陷，二叉查找树在特殊情况下会变成一条线性结构（这就跟原来使用链表结构一样了，造成很深的问题），遍历查找会非常慢。而红黑树在插入新数据后可能需要通过左旋，右旋、变色这些操作来保持平衡，引入红黑树就是为了查找数据快，解决链表查询深度的问题，我们知道红黑树属于平衡二叉树，但是为了保持 “平衡” 是需要付出代价的，但是该代价所损耗的资源要比遍历线性链表要少，所以当长度大于 8 的时候，会使用红黑树，如果链表长度很短的话，根本不需要引入红黑树，引入反而会慢。 10. 说说你对红黑树的见解？ 1、每个节点非红即黑 2、根节点总是黑色的 3、如果节点是红色的，则它的子节点必须是黑色的（反之不一定） 4、每个叶子节点都是黑色的空节点（NIL 节点） 5、从根节点到叶节点或空子节点的每条路径，必须包含相同数目的黑色节点（即相同的黑色高度） 11.jdk8 中对 HashMap 做了哪些改变？ 在 java 1.8 中，如果链表的长度超过了 8，那么链表将转换为红黑树。（桶的数量必须大于 64，小于 64 的时候只会扩容） 发生 hash 碰撞时，java 1.7 会在链表的头部插入，而 java 1.8 会在链表的尾部插入 在 java 1.8 中，Entry 被 Node 替代 (换了一个马甲)。 12.HashMap，LinkedHashMap，TreeMap 有什么区别？ HashMap 参考其他问题： LinkedHashMap 保存了记录的插入顺序，在用 Iterator 遍历时，先取到的记录肯定是先插入的；遍历比 HashMap 慢； TreeMap 实现 SortMap 接口，能够把它保存的记录根据键排序（默认按键值升序排序，也可以指定排序的比较器） 13.HashMap &amp; TreeMap &amp; LinkedHashMap 使用场景？ 一般情况下，使用最多的是 HashMap。 HashMap：在 Map 中插入、删除和定位元素时； TreeMap：在需要按自然顺序或自定义顺序遍历键的情况下； LinkedHashMap：在需要输出的顺序和输入的顺序相同的情况下。 14.HashMap 和 HashTable 有什么区别？ ①、HashMap 是线程不安全的，HashTable 是线程安全的； ②、由于线程安全，所以 HashTable 的效率比不上 HashMap； ③、HashMap 最多只允许一条记录的键为 null，允许多条记录的值为 null，而 HashTable 不允许； ④、HashMap 默认初始化数组的大小为 16，HashTable 为 11，前者扩容时，扩大两倍，后者扩大两倍 + 1； ⑤、HashMap 需要重新计算 hash 值，而 HashTable 直接使用对象的 hashCode 15.Java 中的另一个线程安全的与 HashMap 极其类似的类是什么？同样是线程安全，它与 HashTable 在线程同步上有什么不同？ ConcurrentHashMap 类（是 Java 并发包 java.util.concurrent 中提供的一个线程安全且高效的 HashMap 实现）。 HashTable 是使用 synchronize 关键字加锁的原理（就是对对象加锁）； 而针对 ConcurrentHashMap，在 JDK 1.7 中采用 分段锁的方式；JDK 1.8 中直接采用了 CAS（无锁算法）+ synchronized。 16.HashMap &amp; ConcurrentHashMap 的区别？ 除了加锁，原理上无太大区别。另外，HashMap 的键值对允许有 null，但是 ConCurrentHashMap 都不允许。 17. 为什么 ConcurrentHashMap 比 HashTable 效率要高？ HashTable 使用一把锁（锁住整个链表结构）处理并发问题，多个线程竞争一把锁，容易阻塞； ConcurrentHashMap JDK 1.7 中使用分段锁（ReentrantLock + Segment + HashEntry），相当于把一个 HashMap 分成多个段，每段分配一把锁，这样支持多线程访问。锁粒度：基于 Segment，包含多个 HashEntry。 JDK 1.8 中使用 CAS + synchronized + Node + 红黑树。锁粒度：Node（首结点）（实现 Map.Entry&lt;K,V&gt;）。锁粒度降低了。 18. 针对 ConcurrentHashMap 锁机制具体分析（JDK 1.7 VS JDK 1.8）？ JDK 1.7 中，采用分段锁的机制，实现并发的更新操作，底层采用数组 + 链表的存储结构，包括两个核心静态内部类 Segment 和 HashEntry。 ①、Segment 继承 ReentrantLock（重入锁） 用来充当锁的角色，每个 Segment 对象守护每个散列映射表的若干个桶； ②、HashEntry 用来封装映射表的键 - 值对； ③、每个桶是由若干个 HashEntry 对象链接起来的链表 JDK 1.8 中，采用 Node + CAS + Synchronized 来保证并发安全。取消类 Segment，直接用 table 数组存储键值对；当 HashEntry 对象组成的链表长度超过 TREEIFY_THRESHOLD 时，链表转换为红黑树，提升性能。底层变更为数组 + 链表 + 红黑树。 19.ConcurrentHashMap 在 JDK 1.8 中，为什么要使用内置锁 synchronized 来代替重入锁 ReentrantLock？​ ①、粒度降低了；​ ②、JVM 开发团队没有放弃 synchronized，而且基于 JVM 的 synchronized 优化空间更大，更加自然。​ ③、在大量的数据操作下，对于 JVM 的内存压力，基于 API 的 ReentrantLock 会开销更多的内存。 20.ConcurrentHashMap 简单介绍？①、重要的常量： private transient volatile int sizeCtl; 当为负数时，-1 表示正在初始化，-N 表示 N - 1 个线程正在进行扩容； 当为 0 时，表示 table 还没有初始化； 当为其他正数时，表示初始化或者下一次进行扩容的大小。 ②、数据结构： Node 是存储结构的基本单元，继承 HashMap 中的 Entry，用于存储数据； TreeNode 继承 Node，但是数据结构换成了二叉树结构，是红黑树的存储结构，用于红黑树中存储数据； TreeBin 是封装 TreeNode 的容器，提供转换红黑树的一些条件和锁的控制。 ③、存储对象时（put() 方法）： 1. 如果没有初始化，就调用 initTable() 方法来进行初始化； 2. 如果没有 hash 冲突就直接 CAS 无锁插入； 3. 如果需要扩容，就先进行扩容； 4. 如果存在 hash 冲突，就加锁来保证线程安全，两种情况：一种是链表形式就直接遍历到尾端插入，一种是红黑树就按照红黑树结构插入； 5. 如果该链表的数量大于阀值 8，就要先转换成红黑树的结构，break 再一次进入循环 6. 如果添加成功就调用 addCount() 方法统计 size，并且检查是否需要扩容。 ④、扩容方法 transfer()：默认容量为 16，扩容时，容量变为原来的两倍。 helpTransfer()：调用多个工作线程一起帮助进行扩容，这样的效率就会更高。 ⑤、获取对象时（get() 方法）： 1. 计算 hash 值，定位到该 table 索引位置，如果是首结点符合就返回； 2. 如果遇到扩容时，会调用标记正在扩容结点 ForwardingNode.find() 方法，查找该结点，匹配就返回； 3. 以上都不符合的话，就往下遍历结点，匹配就返回，否则最后就返回 null。 21.ConcurrentHashMap 的并发度是什么？ 程序运行时能够同时更新 ConccurentHashMap 且不产生锁竞争的最大线程数。默认为 16，且可以在构造函数中设置。当用户设置并发度时，ConcurrentHashMap 会使用大于等于该值的最小 2 幂指数作为实际并发度（假如用户设置并发度为 17，实际并发度则为 32） 有时间会对 HashTable，ConcurrentHashmap 解析。 22.为什么要重写hashcode和equals方法？​ 用HashMap存入自定义的类时，如果不重写这个自定义类的hashcode和equals方法，得到的结果会和预期的不一样。 ​ 重写hashcode和equals方法，来覆盖Object里的同名方法。Object的固有方法是根据两个对象的内存地址来判断，两个不同的对象，内存地址一定不会相同，所以无论值是否相等，结果都一定不会相等 参考博客：https://www.cnblogs.com/heqiyoujing/p/11143298.html https://www.jianshu.com/p/75adf47958a7","categories":[{"name":"数据结构","slug":"数据结构","permalink":"https://topone233.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}],"tags":[{"name":"Java","slug":"java","permalink":"https://topone233.github.io/tags/java/"},{"name":"数据结构","slug":"数据结构","permalink":"https://topone233.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"HashMap","slug":"hashmap","permalink":"https://topone233.github.io/tags/hashmap/"}]},{"title":"浅谈HashMap","slug":"浅谈HashMap","date":"2020-07-10T09:07:59.392Z","updated":"2020-09-07T14:19:32.451Z","comments":true,"path":"2020/07/10/浅谈HashMap/","link":"","permalink":"https://topone233.github.io/2020/07/10/%E6%B5%85%E8%B0%88HashMap/","excerpt":"","text":"HashMap 什么是哈希表 HashMap的实现原理 为何HashMap的数组长度一定是2的次幂 重写equals方法需同时重写hashCode方法 JDK1.8中HashMap的性能优化 参考自：https://blog.csdn.net/woshimaxiao1/article/details/83661464 1.什么是哈希表讨论哈希表之前，先大概了解下其他数据结构 数组采用一段连续的存储单元来存储数据。 通过指定下标查找，时间复杂度为O(1)； 通过给定值查找，需要遍历数组，逐一对比给定关键字和数组元素，时间复杂度O(n)。 对于有序数组，则可采用二分查找、插值查找、斐波那契查找等方式，可将复杂度提高到O(logn)；一般的插入删除操作，涉及到数组元素的移动，评价复杂度也为O(n)。 线性链表对于链表的新增、删除等操作，在找到指定操作位置后，仅需处理结点间的引用即可，时间复杂度为O(1),而查找操作需要遍历链表逐一进行对比，复杂度为O(n)。 二叉树对一棵相对平衡的有序二叉树，CRUD，平均复杂度均为O(logn)。 哈希表哈希表(hash table)进行CRUD，性能十分之高，不考虑哈希冲突的情况下，仅需一次定位即可完成，时间复杂度为O(1)。 数据结构的物理存储结构只有两种：顺序存储结构和链式存储结构。栈、队列、树、图等都是从逻辑结构去抽象，映射到内存中，也是这两种物理组织形式。 哈希表主干是数组。如果要新增或查找某个元素，把元素的关键字，通过某个函数映射到数组中的某个位置，通过数组下标一次定位就可以完成。这个函数可以简单描述为：存储位置=f(关键字)。函数f一般成为哈希函数，直接影响到哈希表的优劣。 哈希冲突如果两个不同的元素，通过哈希函数得出的实际存储地址相同；或者元素哈希运算得到一个存储地址，进行插入的时候发现已经被其他元素占用了，这就是所谓的哈希冲突，也叫哈希碰撞。 好的哈希函数会尽可能使计算简单和散列地址分布均匀。但是，数组是一块连续的固定长度的内存空间，再好的哈希函数也不能保证得到的存储地址绝对不发生冲突。 哈希冲突的解决方案有多种：开放定址法(发生冲突，继续寻找下一块未被占用的存储地址)、再散列函数法、链地址法。HashMap采用的即是链地址法，也就是数组+链表的方式。 2.HashMap的实现原理HashMap的主干是一个Entry数组。Entry是HashMap的基本组成单元，每一个Entry包含一个key-value键值对。（其实所谓的Map就是保存了两个对象之间的映射关系的一种集合）。 //主干是一个Entry数组，初始值为空数组，长度一定是2的次幂 transient Entry&lt;K,V&gt;[] table = (Entry&lt;K,V&gt;[]) EMPty_TABLE;Entry是HashMap中的一个静态内部类。代码如下: static class Entry&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; { final K key; V value; //存储执向下一个Entry的引用，单链表结构 Entry&lt;K,V&gt; next; //对key的hashcode值进行hash运算后得到的值，存储在Entry，避免重复计算 int hash; //creats new entry Entry(int h, k K, V v, Entry&lt;K,V&gt; n) { value = v; next = n; key = k; hash = h; }总结一下：HashMap由数组+链表组成，Entry数组是HashMap的主体，链表用于解决哈希冲突。如果定位到的数组位置不含链表(当前entry的next指向null)，那么CRUD很快，O(1)，仅需一次寻址即可；如果定位到的数组包含链表，添加操作，复杂度O(n)，先遍历链表，存在即覆盖，否则新增；查找操作，仍需遍历链表，然后通过key对象的equals方法逐一对比查找。所以，HashMap中的链表出现越少，性能越好。 构造器HashMap的4个构造器size、threshold、loadFactor、modCount //实际存储key-value键值对的个数 transient int size; //阈值，当table == {}时，该值为初始容量(默认16) //当table被填充了，也就是为table分配内存空间后，threshold一般为capacity*loadFactory //HashMap在进行扩容时需要参考threshold int threshold; //负载因子，代表了table的填充度，默认是0.75 //负载因子存在的原因，还是为了减缓哈希冲突 //如果初始桶为16，等到满16个才扩容，某些桶可能就有不止一个元素了 //所以加载因子默认为0.75，也就是说大小为16的HashMap，到了第13个元素，就会扩容成32 final float loadFactor; //HashMap被改变的次数 //由于HashMap非线程安全，在对HashMap进行迭代时，如果其他线程的参与导致HashMap的结构发生了变化(put、remove等操作)，需要抛出异常ConcurrentModificationException transient int modeCount;示例代码: public HashMap(int initialCapacity, float loadFactor) { //此处对传入的初始容量进行校验，最大不能超过MAXIMUM_CAPACITY = 1&lt;&lt;30(230) if (initialCapacity &lt; 0) throw new IllegalArgumentException(&quot;Illegal initial capacity: &quot; + initialCapacity); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(&quot;Illegal load factor: &quot; + loadFactor); this.loadFactor = loadFactor; threshold = initialCapacity; //init方法在HashMap中没有实际实现，不过在其子类如 linkedHashMap中就会有对应实现 init(); } 从上面这段代码我们可以看出，在常规构造器中，没有为数组table分配内存空间（有一个入参为指定Map的构造器例外），而是在执行put操作的时候才真正构建table数组 putput操作的实现: public V put(K key, V value) { //如果table数组为空数组{}，进行数组填充（为table分配实际内存空间），入参为threshold， //此时threshold为initialCapacity 默认是1&lt;&lt;4(24=16) if (table == EMPTY_TABLE) { inflateTable(threshold); } //如果key为null，存储位置为table[0]或table[0]的冲突链上 if (key == null) return putForNullKey(value); int hash = hash(key);//对key的hashcode进一步计算，确保散列均匀 int i = indexFor(hash, table.length);//获取在table中的实际位置 for (Entry&lt;K,V&gt; e = table[i]; e != null; e = e.next) { //如果该对应数据已存在，执行覆盖操作。用新value替换旧value，并返回旧value Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) { V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; } } modCount++;//保证并发访问时，若HashMap内部结构发生变化，快速响应失败 addEntry(hash, key, value, i);//新增一个entry return null; } inflateTable这个方法用于为主干数组table在内存中分配存储空间，通过roundUpToPowerOf2(toSize)可以确保capacity为大于或等于toSize的最接近toSize的二次幂，比如toSize=13,则capacity=16;to_size=16,capacity=16;to_size=17,capacity=32。 private void inflateTable(int toSize) { //capacity一定是2的次幂 int capacity = roundUpToPowerOf2(toSize); //此处为threshold赋值，取capacity*loadFactor和MAXIMUM_CAPACITY+1的最小值， //capaticy一定不会超过MAXIMUM_CAPACITY，除非loadFactor大于1 threshold = (int) Math.min(capacity * loadFactor, MAXIMUM_CAPACITY + 1); table = new Entry[capacity]; initHashSeedAsNeeded(capacity); } roundUpToPowerOf2中的这段处理使得数组长度一定为2的次幂，Integer.highestOneBit是用来获取最左边的bit（其他bit位为0）所代表的数值 private static int roundUpToPowerOf2(int number) { // assert number &gt;= 0 : &quot;number must be non-negative&quot;; return number &gt;= MAXIMUM_CAPACITY ? MAXIMUM_CAPACITY : (number &gt; 1) ? Integer.highestOneBit((number - 1) &lt;&lt; 1) : 1; } hash函数: //这是一个神奇的函数，用了很多的异或，移位等运算 //对key的hashcode进一步进行计算以及二进制位的调整等来保证最终获取的存储位置尽量分布均匀 final int hash(Object k) { int h = hashSeed; if (0 != h &amp;&amp; k instanceof String) { return sun.misc.Hashing.stringHash32((String) k); } h ^= k.hashCode(); h ^= (h &gt;&gt;&gt; 20) ^ (h &gt;&gt;&gt; 12); return h ^ (h &gt;&gt;&gt; 7) ^ (h &gt;&gt;&gt; 4); } 以上hash函数计算出的值，通过indexFor进一步处理来获取实际的存储位置 //返回数组下标 static int indexFor(int h, int length) { return h &amp; (length-1); }h&amp;（length-1）保证获取的index一定在数组范围内，举个例子，默认容量16，length-1=15，h=18,转换成二进制计算为index=2。位运算对计算机来说，性能更高一些（HashMap中有大量位运算） 所以最终存储位置的确定流程是这样的： hashCode() hash() indexFor() key ----------&gt; hashcode ----------&gt; h ------------&gt; 存储下标 h&amp;(length-1)再来看看addEntry的实现： void addEntry(int hash, K key, V value, int bucketIndex) { if ((size &gt;= threshold) &amp;&amp; (null != table[bucketIndex])) { //当size超过临界阈值threshold，并且即将发生哈希冲突时进行扩容 resize(2 * table.length); hash = (null != key) ? hash(key) : 0; bucketIndex = indexFor(hash, table.length); } createEntry(hash, key, value, bucketIndex); } 通过以上代码能够得知，当发生哈希冲突并且size大于阈值的时候，需要进行数组扩容，扩容时，需要新建一个长度为之前数组2倍的新的数组，然后将当前的Entry数组中的元素全部传输过去，扩容后的新数组长度为之前的2倍，所以扩容相对来说是个耗资源的操作 3.为何HashMap的数组长度一定是2的次幂我们来继续看上面提到的resize方法: void resize(int newCapacity) { Entry[] oldTable = table; int oldCapacity = oldTable.length; if (oldCapacity == MAXIMUM_CAPACITY) { threshold = Integer.MAX_VALUE; return; } Entry[] newTable = new Entry[newCapacity]; transfer(newTable, initHashSeedAsNeeded(newCapacity)); table = newTable; threshold = (int)Math.min(newCapacity * loadFactor, MAXIMUM_CAPACITY + 1); } 如果数组进行扩容，数组长度发生变化，而存储位置 index = h&amp;(length-1),index也可能会发生变化，需要重新计算index，我们先来看看transfer这个方法: void transfer(Entry[] newTable, boolean rehash) { int newCapacity = newTable.length; //for循环中的代码，逐个遍历链表，重新计算索引位置，将老数组数据复制到新数组中去（数组不存储实际数据，所以仅仅是拷贝引用而已） for (Entry&lt;K,V&gt; e : table) { while(null != e) { Entry&lt;K,V&gt; next = e.next; if (rehash) { e.hash = null == e.key ? 0 : hash(e.key); } int i = indexFor(e.hash, newCapacity); //将当前entry的next链指向新的索引位置,newTable[i]有可能为空，有可能也是个entry链，如果是entry链，直接在链表头部插入。 e.next = newTable[i]; newTable[i] = e; e = next; } } } 这个方法将老数组中的数据逐个链表地遍历，扔到新的扩容后的数组中，我们的数组索引位置的计算是通过 对key值的hashcode进行hash扰乱运算后，再通过和 length-1进行位运算得到最终数组索引位置。 HashMap的数组长度一定保持2的次幂，比如16的二进制表示为 10000，那么length-1就是15，二进制为01111，同理扩容后的数组长度为32，二进制表示为100000，length-1为31，二进制表示为011111。从下图可以我们也能看到这样会保证低位全为1，而扩容后只有一位差异，也就是多出了最左位的1，这样在通过 h&amp;(length-1)的时候，只要h对应的最左边的那一个差异位为0，就能保证得到的新的数组索引和老数组索引一致(大大减少了之前已经散列良好的老数组的数据位置重新调换)，个人理解。 还有，数组长度保持2的次幂，length-1的低位都为1，会使得获得的数组索引index更加均匀 我们看到，上面的&amp;运算，高位是不会对结果产生影响的（hash函数采用各种位运算可能也是为了使得低位更加散列），我们只关注低位bit，如果低位全部为1，那么对于h低位部分来说，任何一位的变化都会对结果产生影响，也就是说，要得到index=21这个存储位置，h的低位只有这一种组合。这也是数组长度设计为必须为2的次幂的原因。 如果不是2的次幂，也就是低位不是全为1此时，要使得index=21，h的低位部分不再具有唯一性了，哈希冲突的几率会变的更大，同时，index对应的这个bit位无论如何不会等于1了，而对应的那些数组位置也就被白白浪费了。 getget方法: public V get(Object key) { //如果key为null,则直接去table[0]处去检索即可。 if (key == null) return getForNullKey(); Entry&lt;K,V&gt; entry = getEntry(key); return null == entry ? null : entry.getValue(); } get方法通过key值返回对应value，如果key为null，直接去table[0]处检索。 我们再看一下getEntry方法: final Entry&lt;K,V&gt; getEntry(Object key) { if (size == 0) { return null; } //通过key的hashcode值计算hash值 int hash = (key == null) ? 0 : hash(key); //indexFor (hash&amp;length-1) 获取最终数组索引，然后遍历链表，通过equals方法比对找出对应记录 for (Entry&lt;K,V&gt; e = table[indexFor(hash, table.length)]; e != null; e = e.next) { Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; } return null; } 可以看出，get方法的实现相对简单，key(hashcode)–&gt;hash–&gt;indexFor–&gt;最终索引位置，找到对应位置table[i]，再查看是否有链表，遍历链表，通过key的equals方法比对查找对应的记录。要注意的是，有人觉得上面在定位到数组位置之后然后遍历链表的时候，e.hash == hash这个判断没必要，仅通过equals判断就可以。其实不然，试想一下，如果传入的key对象重写了equals方法却没有重写hashCode，而恰巧此对象定位到这个数组位置，如果仅仅用equals判断可能是相等的，但其hashCode和当前对象不一致，这种情况，根据Object的hashCode的约定，不能返回当前对象，而应该返回null，后面的例子会做出进一步解释。 4.重写equals方法需同时重写hashCode方法先来看下如果重写equals而不重写hashcode会发生什么: public class MyTest { private static class Person{ int idCard; String name; public Person(int idCard, String name) { this.idCard = idCard; this.name = name; } @Override public boolean equals(Object o) { if (this == o) { return true; } if (o == null || getClass() != o.getClass()){ return false; } Person person = (Person) o; //两个对象是否等值，通过idCard来确定 return this.idCard == person.idCard; } } public static void main(String []args){ HashMap&lt;Person,String&gt; map = new HashMap&lt;Person, String&gt;(); Person person = new Person(1234,&quot;乔峰&quot;); //put到hashmap中去 map.put(person,&quot;天龙八部&quot;); //get取出，从逻辑上讲应该能输出“天龙八部” System.out.println(&quot;结果:&quot;+map.get(new Person(1234,&quot;萧峰&quot;))); } } 实际输出结果：null如果我们已经对HashMap的原理有了一定了解，这个结果就不难理解了。尽管我们在进行get和put操作的时候，使用的key从逻辑上讲是等值的（通过equals比较是相等的），但由于没有重写hashCode方法，所以put操作时，key(hashcode1)–&gt;hash–&gt;indexFor–&gt;最终索引位置 ，而通过key取出value的时候 key(hashcode1)–&gt;hash–&gt;indexFor–&gt;最终索引位置，由于hashcode1不等于hashcode2，导致没有定位到一个数组位置而返回逻辑上错误的值null(也有可能碰巧定位到一个数组位置，但是也会判断其entry的hash值是否相等，上面get方法中有提到) 所以，在重写equals的方法的时候，必须注意重写hashCode方法，同时还要保证通过equals判断相等的两个对象，调用hashCode方法要返回同样的整数值。而如果equals判断不相等的两个对象，其hashCode可以相同(只不过会发生哈希冲突，应尽量避免) 5.JDK1.8中HashMap的性能优化假如一个数组槽位上链上数据过多（即拉链过长的情况）导致性能下降该怎么办？ JDK1.8在JDK1.7的基础上针对增加了红黑树来进行优化。即当链表超过8时，链表就转换为红黑树，利用红黑树快速增删改查的特点提高HashMap的性能，其中会用到红黑树的插入、删除、查找等算法","categories":[{"name":"数据结构","slug":"数据结构","permalink":"https://topone233.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}],"tags":[{"name":"Java","slug":"java","permalink":"https://topone233.github.io/tags/java/"},{"name":"数据结构","slug":"数据结构","permalink":"https://topone233.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"HashMap","slug":"hashmap","permalink":"https://topone233.github.io/tags/hashmap/"}]},{"title":"九大常见数据结构","slug":"九大常见数据结构","date":"2020-07-10T09:07:59.386Z","updated":"2020-09-07T14:19:46.836Z","comments":true,"path":"2020/07/10/九大常见数据结构/","link":"","permalink":"https://topone233.github.io/2020/07/10/%E4%B9%9D%E5%A4%A7%E5%B8%B8%E8%A7%81%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/","excerpt":"","text":"参考：https://mp.weixin.qq.com/s/lnMvB3zgWZTmCfCvnNwTbA 数据结构想必大家都不会陌生，对于一个成熟的程序员而言，熟悉和掌握数据结构和算法也是基本功之一。数据结构本身其实不过是数据按照特点关系进行存储或者组织的集合，特殊的结构在不同的应用场景中往往会带来不一样的处理效率。 常用的数据结构可根据数据访问的特点分为线性结构和非线性结构。线性结构包括常见的链表、栈、队列等，非线性结构包括树、图等。数据结构种类繁多，本文将通过图解的方式对常用的数据结构进行理论上的介绍和讲解，以方便大家掌握常用数据结构的基本知识。 1 数组数组可以说是最基本最常见的数据结构。数组一般用来存储相同类型的数据，可通过数组名和下标进行数据的访问和更新。数组中元素的存储是按照先后顺序进行的，同时在内存中也是按照这个顺序进行连续存放。数组相邻元素之间的内存地址的间隔一般就是数组数据类型的大小。 2 链表链表相较于数组，除了数据域，还增加了指针域用于构建链式的存储数据。链表中每一个节点都包含此节点的数据和指向下一节点地址的指针。由于是通过指针进行下一个数据元素的查找和访问，使得链表的自由度更高。 这表现在对节点进行增加和删除时，只需要对上一节点的指针地址进行修改，而无需变动其它的节点。不过事物皆有两极，指针带来高自由度的同时，自然会牺牲数据查找的效率和多余空间的使用。 一般常见的是有头有尾的单链表，对指针域进行反向链接，还可以形成双向链表或者循环链表。 链表和数组对比链表和数组在实际的使用过程中需要根据自身的优劣势进行选择。链表和数组的异同点也是面试中高频的考察点之一。这里对单链表和数组的区别进行了对比和总结。 3 跳表从上面的对比中可以看出，链表虽然通过增加指针域提升了自由度，但是却导致数据的查询效率恶化。特别是当链表长度很长的时候，对数据的查询还得从头依次查询，这样的效率会更低。跳表的产生就是为了解决链表过长的问题，通过增加链表的多级索引来加快原始链表的查询效率。这样的方式可以让查询的时间复杂度从 O(n) 提升至 O(logn)。 跳表通过增加的多级索引能够实现高效的动态插入和删除，其效率和红黑树和平衡二叉树不相上下。目前 redis 和 levelDB 都有用到跳表。 从上图可以看出，索引级的指针域除了指向下一个索引位置的指针，还有一个 down 指针指向低一级的链表位置，这样才能实现跳跃查询的目的。 4 栈栈是一种比较简单的数据结构，常用一句话描述其特性，后进先出。栈本身是一种线性结构，但是在这个结构中只有一个口子允许数据的进出。这种模式可以参考腔肠动物… 即进食和排泄都用一个口… 栈的常用操作包括入栈 push 和出栈 pop，对应于数据的压入和压出。还有访问栈顶数据、判断栈是否为空和判断栈的大小等。由于栈后进先出的特性，常可以作为数据操作的临时容器，对数据的顺序进行调控，与其它数据结构相结合可获得许多灵活的处理。 5 队列队列是栈的兄弟结构，与栈的后进先出相对应，队列是一种先进先出的数据结构。顾名思义，队列的数据存储是如同排队一般，先存入的数据先被压出。常与栈一同配合，可发挥最大的实力。 6 树树作为一种树状的数据结构，其数据节点之间的关系也如大树一样，将有限个节点根据不同层次关系进行排列，从而形成数据与数据之间的父子关系。常见的数的表示形式更接近 “倒挂的树”，因为它将根朝上，叶朝下。 树是图的一种，树与图的区别在于：树是没有环的，而图是可以有环的。 树的数据存储在结点中，每个结点有零个或者多个子结点。没有父结点的结点在最顶端，成为根节点；没有非根结点有且只有一个父节点；每个非根节点又可以分为多个不相交的子树。 这意味着树是具备层次关系的，父子关系清晰，家庭血缘关系明朗；这也是树与图之间最主要的区别。 别看树好像很高级，其实可看作是链表的高配版。树的实现就是对链表的指针域进行了扩充，增加了多个地址指向子结点。同时将 “链表” 竖起来，从而凸显了结点之间的层次关系，更便于分析和理解。 树可以衍生出许多的结构，若将指针域设置为双指针，那么即可形成最常见的二叉树，即每个结点最多有两个子树的树结构。二叉树根据结点的排列和数量还可进一度划分为完全二叉树、满二叉树、平衡二叉树、红黑树等。 完全二叉树：除了最后一层结点，其它层的结点数都达到了最大值；同时最后一层的结点都是按照从左到右依次排布。 满二叉树：除了最后一层，其它层的结点都有两个子结点。 平衡二叉树平衡二叉树又被称为 AVL 树，它是一棵二叉排序树，且具有以下性质：它是一棵空树或它的左右两个子树的高度差的绝对值不超过 1，并且左右两个子树都是一棵平衡二叉树。 二叉排序树：是一棵空树，或者：若它的左子树不空，则左子树上所有结点的值均小于它的根结点的值；若它的右子树不空，则右子树上所有结点的值均大于它的根结点的值；它的左、右子树也分别为二叉排序树。 树的高度：结点层次的最大值 平衡因子：左子树高度 - 右子树高度 二叉排序树意味着二叉树中的数据是排好序的，顺序为左结点 &lt;根节点&lt;右结点，这表明二叉排序树的中序遍历结果是有序的。 （二叉树四种遍历方式[前序遍历、中序遍历、后序遍历、层序遍历] ） 平衡二叉树的产生是为了解决二叉排序树在插入时发生线性排列的现象。由于二叉排序树本身为有序，当插入一个有序程度十分高的序列时，生成的二叉排序树会持续在某个方向的字数上插入数据，导致最终的二叉排序树会退化为链表，从而使得二叉树的查询和插入效率恶化。 平衡二叉树的出现能够解决上述问题，但是在构造平衡二叉树时，却需要采用不同的调整方式，使得二叉树在插入数据后保持平衡。主要的四种调整方式有 LL（左旋）、RR（右旋）、LR（先左旋再右旋）、RL（先右旋再左旋）。这里先给大家介绍下简单的单旋转操作，左旋和右旋。LR 和 RL 本质上只是 LL 和 RR 的组合。 在插入一个结点后应该沿搜索路径将路径上的结点平衡因子进行修改，当平衡因子大于 1 时，就需要进行平衡化处理。从发生不平衡的结点起，沿刚才回溯的路径取直接下两层的结点，如果这三个结点在一条直线上，则采用单旋转进行平衡化，如果这三个结点位于一条折线上，则采用双旋转进行平衡化。 左旋：S 为当前需要左旋的结点，E 为当前结点的父节点。 左旋的操作可以用一句话简单表示：将当前结点 S 的左孩子旋转为当前结点父结点 E 的右孩子，同时将父结点 E 旋转为当前结点 S 的左孩子。 右旋：S 为当前需要左旋的结点，E 为当前结点的父节点。右单旋是左单旋的镜像旋转。 左旋的操作同样可以用一句话简单表示：将当前结点 S 的左孩子 E 的右孩子旋转为当前结点 S 的左孩子，同时将当前结点 S 旋转为左孩子 E 的右孩子 红黑树平衡二叉树（AVL）为了追求高度平衡，需要通过平衡处理使得左右子树的高度差必须小于等于 1。高度平衡带来的好处是能够提供更高的搜索效率，其最坏的查找时间复杂度都是 O(logN)。但是由于需要维持这份高度平衡，所付出的代价就是当对树种结点进行插入和删除时，需要经过多次旋转实现复衡。这导致 AVL 的插入和删除效率并不高。 为了解决这样的问题，能不能找一种结构能够兼顾搜索和插入删除的效率呢？这时候红黑树便申请出战了。 红黑树具有五个特性： 每个结点要么是红的要么是黑的。 根结点是黑的。 每个叶结点（叶结点即指树尾端 NIL 指针或 NULL 结点）都是黑的。 如果一个结点是红的，那么它的两个儿子都是黑的。 对于任意结点而言，其到叶结点树尾端 NIL 指针的每条路径都包含相同数目的黑结点。 红黑树通过将结点进行红黑着色，使得原本高度平衡的树结构被稍微打乱，平衡程度降低。红黑树不追求完全平衡，只要求达到部分平衡。这是一种折中的方案，大大提高了结点删除和插入的效率。C++ 中的 STL 就常用到红黑树作为底层的数据结构。 除了上面所提及的树结构，还有许多广泛应用在数据库、磁盘存储等场景下的树结构。比如 B 树、B + 树等。这里就先不介绍了诶，下次在讲述相关存储原理的时候将会着重介绍。（其实是因为懒） B树（B-tree）B树和平衡二叉树稍有不同的是B树属于多叉树又名平衡多路查找树（查找路径不只两个），数据库索引技术里大量使用者B树和B+树的数据结构。B树相对于平衡二叉树，每个节点包含的关键字增多了，特别是在B树应用到数据库中的时候，数据库充分利用了磁盘块的原理（磁盘数据存储是采用块的形式存储的，每个块的大小为4K，每次IO进行数据读取时，同一个磁盘块的数据可以一次性读取出来）把节点大小限制和充分使用在磁盘快大小范围；把树的节点关键字增多后树的层级比原来的二叉树少了，减少数据查找的次数和复杂度; 规则： 排序方式：所有节点关键字是按递增次序排列，并遵循左小右大原则； 子节点数：非叶节点的子节点数&gt;1，且&lt;=M ，且M&gt;=2，空树除外（注：M阶代表一个树节点最多有多少个查找路径，M=M路,当M=2则是2叉树,M=3则是3叉）； 关键字数：枝节点的关键字数量大于等于ceil(m/2)-1个且小于等于M-1个（注：ceil()是个朝正无穷方向取整的函数 如ceil(1.1)结果为2)； 所有叶子节点均在同一层、叶子节点除了包含了关键字和关键字记录的指针外也有指向其子节点的指针只不过其指针地址都为null对应下图最后一层节点的空格子; 查询： 如上图我要从上图中找到E字母，查找流程如下 获取根节点的关键字进行比较，当前根节点关键字为M，E&lt;M（26个字母顺序），所以往找到指向左边的子节点（二分法规则，左小右大，左边放小于当前节点值的子节点、右边放大于当前节点值的子节点）； 拿到关键字D和G，D&lt;E&lt;G 所以直接找到D和G中间的节点； 拿到E和F，因为E=E 所以直接返回关键字和指针信息（如果树结构里面没有包含所要查找的节点则返回null）； 插入： 节点拆分规则：当前是要组成一个5路查找树，那么此时m=5,关键字数必须&lt;=5-1（这里关键字数&gt;4就要进行节点拆分）； 排序规则：满足节点本身比左边节点大，比右边节点小的排序规则; 删除： 节点合并规则：当前是要组成一个5路查找树，那么此时m=5,关键字数必须大于等于ceil（5/2）（这里关键字数&lt;2就要进行节点合并）； 满足节点本身比左边节点大，比右边节点小的排序规则; 关键字数小于二时先从子节点取，子节点没有符合条件时就向向父节点取，取中间值往父节点放； B+树B+树是B树的一个升级版，相对于B树来说B+树更充分的利用了节点的空间，让查询速度更加稳定，其速度完全接近于二分法查找。查找的效率要比B树更高、更稳定。 规则： B+跟B树不同B+树的非叶子节点不保存关键字记录的指针，只进行数据索引，这样使得B+树每个非叶子节点所能保存的关键字大大增加； B+树叶子节点保存了父节点的所有关键字记录的指针，所有数据地址必须要到叶子节点才能获取到。所以每次数据查询的次数都一样； B+树叶子节点的关键字从小到大有序排列，左边结尾数据都会保存右边节点开始数据的指针。 非叶子节点的子节点数=关键字数（来源百度百科）（根据各种资料 这里有两种算法的实现方式，另一种为非叶节点的关键字数=子节点数-1（来源维基百科)，虽然他们数据排列结构不一样，但其原理还是一样的Mysql 的B+树是用第一种方式实现）; 特点： B+树的层级更少：相较于B树B+每个非叶子节点存储的关键字数更多，树的层级更少所以查询数据更快； B+树查询速度更稳定：B+所有关键字数据地址都存在叶子节点上，所以每次查找的次数都相同所以查询速度要比B树更稳定; B+树天然具备排序功能：B+树所有的叶子节点数据构成了一个有序链表，在查询大小区间的数据时候更方便，数据紧密性很高，缓存的命中率也会比B树高。 B+树全节点遍历更快：B+树遍历整棵树只需要遍历所有的叶子节点即可，，而不需要像B树一样需要对每一层进行遍历，这有利于数据库做全表扫描。 B树相对于B+树的优点是，如果经常访问的数据离根节点很近，而B树的非叶子节点本身存有关键字其数据的地址，所以这种数据检索的时候会要比B+树快。 7 堆了解完二叉树，再来理解堆就不是什么难事了。堆通常是一个可以被看做一棵树的数组对象。堆的具体实现一般不通过指针域，而是通过构建一个一维数组与二叉树的父子结点进行对应，因此堆总是一颗完全二叉树。 对于任意一个父节点的序号 n 来说（这里 n 从 0 算），它的子节点的序号一定是 2n+1，2n+2，因此可以直接用数组来表示一个堆。 不仅如此，堆还有一个性质：堆中某个节点的值总是不大于或不小于其父节点的值。将根节点最大的堆叫做最大堆或大根堆，根节点最小的堆叫做最小堆或小根堆。 堆常用来实现优先队列，在面试中经常考的问题都是与排序有关，比如堆排序、topK 问题等。由于堆的根节点是序列中最大或者最小值，因而可以在建堆以及重建堆的过程中，筛选出数据序列中的极值，从而达到排序或者挑选 topK 值的目的。 8 散列表散列表也叫哈希表，是一种通过键值对直接访问数据的机构。在初中，我们就学过一种能够将一个 x 值通过一个函数获得对应的一个 y 值的操作，叫做映射。散列表的实现原理正是映射的原理，通过设定的一个关键字和一个映射函数，就可以直接获得访问数据的地址，实现 O(1) 的数据访问效率。在映射的过程中，事先设定的函数就是一个映射表，也可以称作散列函数或者哈希函数。 散列表的实现最关键的就是散列函数的定义和选择。一般常用的有以下几种散列函数： 直接寻址法：取关键字或关键字的某个线性函数值为散列地址。 数字分析法：通过对数据的分析，发现数据中冲突较少的部分，并构造散列地址。例如同学们的学号，通常同一届学生的学号，其中前面的部分差别不太大，所以用后面的部分来构造散列地址。 平方取中**法**：当无法确定关键字里哪几位的分布相对比较均匀时，可以先求出关键字的平方值，然后按需要取平方值的中间几位作为散列地址。这是因为：计算平方之后的中间几位和关键字中的每一位都相关，所以不同的关键字会以较高的概率产生不同的散列地址。 取随机数法：使用一个随机函数，取关键字的随机值作为散列地址，这种方式通常用于关键字长度不同的场合。 除留取余法：取关键字被某个不大于散列表的表长 n 的数 m 除后所得的余数 p 为散列地址。这种方式也可以在用过其他方法后再使用。该函数对 m 的选择很重要，一般取素数或者直接用 n。 确定好散列函数之后，通过某个key值的确会得到一个唯一的value地址。但是却会出现一些特殊情况。即通过不同的key值可能会访问到同一个地址，这个现象称之为冲突。 冲突在发生之后，当在对不同的key值进行操作时会使得造成相同地址的数据发生覆盖或者丢失，是非常危险的。所以在设计散列表往往还需要采用冲突解决的办法。 常用的冲突处理方式有很多，常用的包括以下几种： 开放地址法（也叫开放寻址法）：实际上就是当需要存储值时，对 Key 哈希之后，发现这个地址已经有值了，这时该怎么办？不能放在这个地址，不然之前的映射会被覆盖。这时对计算出来的地址进行一个探测再哈希，比如往后移动一个地址，如果没人占用，就用这个地址。如果超过最大长度，则可以对总长度取余。这里移动的地址是产生冲突时的增列序量。 再哈希法：在产生冲突之后，使用关键字的其他部分继续计算地址，如果还是有冲突，则继续使用其他部分再计算地址。这种方式的缺点是时间增加了。 链地址法：链地址法其实就是对 Key 通过哈希之后落在同一个地址上的值，做一个链表。其实在很多高级语言的实现当中，也是使用这种方式处理冲突的。 公共溢出区：这种方式是建立一个公共溢出区，当地址存在冲突时，把新的地址放在公共溢出区里。 目前比较常用的冲突解决方法是链地址法，一般可以通过数组和链表的结合达到冲突数据缓存的目的。 左侧数组的每个成员包括一个指针，指向一个链表的头。每发生一个冲突的数据，就将该数据作为链表的节点链接到链表尾部。这样一来，就可以保证冲突的数据能够区分并顺利访问。 考虑到链表过长造成的问题，还可以使用红黑树替换链表进行冲突数据的处理操作，来提高散列表的查询稳定性。 9 图图相较于上文的几个结构可能接触的不多，但是在实际的应用场景中却经常出现。比方说交通中的线路图，常见的思维导图都可以看作是图的具体表现形式。 图结构一般包括顶点和边，顶点通常用圆圈来表示，边就是这些圆圈之间的连线。边还可以根据顶点之间的关系设置不同的权重，默认权重相同皆为 1。此外根据边的方向性，还可将图分为有向图和无向图。 图结构用抽象的图线来表示十分简单，顶点和边之间的关系非常清晰明了。但是在具体的代码实现中，为了将各个顶点和边的关系存储下来，却不是一件易事。 邻接矩阵目前常用的图存储方式为邻接矩阵，通过所有顶点的二维矩阵来存储两个顶点之间是否相连，或者存储两顶点间的边权重。 无向图的邻接矩阵是一个对称矩阵，是因为边不具有方向性，若能从此顶点能够到达彼顶点，那么彼顶点自然也能够达到此顶点。此外，由于顶点本身与本身相连没有意义，所以在邻接矩阵中对角线上皆为 0。 有向图由于边具有方向性，因此彼此顶点之间并不能相互达到，所以其邻接矩阵的对称性不再。 用邻接矩阵可以直接从二维关系中获得任意两个顶点的关系，可直接判断是否相连。但是在对矩阵进行存储时，却需要完整的一个二维数组。若图中顶点数过多，会导致二维数组的大小剧增，从而占用大量的内存空间。 而根据实际情况可以分析得，图中的顶点并不是任意两个顶点间都会相连，不是都需要对其边上权重进行存储。那么存储的邻接矩阵实际上会存在大量的 0。虽然可以通过稀疏表示等方式对稀疏性高的矩阵进行关键信息的存储，但是却增加了图存储的复杂性。 因此，为了解决上述问题，一种可以只存储相连顶点关系的邻接表应运而生。 邻接表在邻接表中，图的每一个顶点都是一个链表的头节点，其后连接着该顶点能够直接达到的相邻顶点。相较于无向图，有向图的情况更为复杂，因此这里采用有向图进行实例分析。 在邻接表中，每一个顶点都对应着一条链表，链表中存储的是顶点能够达到的相邻顶点。存储的顺序可以按照顶点的编号顺序进行。比如上图中对于顶点 B 来说，其通过有向边可以到达顶点 A 和顶点 E，那么其对应的邻接表中的顺序即 B-&gt;A-&gt;E，其它顶点亦如此。 通过邻接表可以获得从某个顶点出发能够到达的顶点，从而省去了对不相连顶点的存储空间。然而，这还不够。对于有向图而言，图中有效信息除了从顶点 “指出去” 的信息，还包括从别的顶点 “指进来” 的信息。这里的 “指出去” 和“指进来”可以用出度和入度来表示。 入度：有向图的某个顶点作为终点的次数和。 出度：有向图的某个顶点作为起点的次数和。 由此看出，在对有向图进行表示时，邻接表只能求出图的出度，而无法求出入度。这个问题很好解决，那就是增加一个表用来存储能够到达某个顶点的相邻顶点。这个表称作逆邻接表。 逆邻接表逆邻接表与邻接表结构类似，只不过图的顶点链接着能够到达该顶点的相邻顶点。也就是说，邻接表时顺着图中的箭头寻找相邻顶点，而逆邻接表时逆着图中的箭头寻找相邻顶点。 邻接表和逆邻接表的共同使用下，就能够把一个完整的有向图结构进行表示。可以发现，邻接表和逆邻接表实际上有一部分数据时重合的，因此可以将两个表合二为一，从而得到了所谓的十字链表。 十字链表十字链表似乎很简单，只需要通过相同的顶点分别链向以该顶点为终点和起点的相邻顶点即可。 但这并不是最优的表示方式。虽然这样的方式共用了中间的顶点存储空间，但是邻接表和逆邻接表的链表节点中重复出现的顶点并没有得到重复利用，反而是进行了再次存储。因此，上图的表示方式还可以进行进一步优化。 十字链表优化后，可通过扩展的顶点结构和边结构来进行正逆邻接表的存储：（下面的弧头可看作是边的箭头那端，弧尾可看作是边的圆点那端） data：用于存储该顶点中的数据； firstin 指针：用于连接以当前顶点为弧头的其他顶点构成的链表，即从别的顶点指进来的顶点； firstout 指针：用于连接以当前顶点为弧尾的其他顶点构成的链表，即从该顶点指出去的顶点； 边结构通过存储两个顶点来确定一条边，同时通过分别代表这两个顶点的指针来与相邻顶点进行链接： tailvex：用于存储作为弧尾的顶点的编号； headvex：用于存储作为弧头的顶点的编号； headlink 指针：用于链接下一个存储作为弧头的顶点的节点； taillink 指针：用于链接下一个存储作为弧尾的顶点的节点； 以上图为例子，对于顶点 A 而言，其作为起点能够到达顶点 E。因此在邻接表中顶点 A 要通过边AE（即边 04）指向顶点 E，顶点 A 的firstout指针需要指向边 04 的tailvex。同时，从 B 出发能够到达 A，所以在逆邻接表中顶点 A 要通过边AB（即边 10）指向 B，顶点 A 的firstin指针需要指向边 10 的弧头，即headlink指针。依次类推。 十字链表采用了一种看起来比较繁乱的方式对边的方向性进行了表示，能够在尽可能降低存储空间的情况下增加指针保留顶点之间的方向性。具体的操作可能一时间不好弄懂，建议多看几次上图，弄清指针指向的意义，明白正向和逆向邻接表的表示。 10 总结数据结构博大精深，没有高等数学的讳莫如深，也没有量子力学的玄乎其神，但是其在计算机科学的各个领域都具有强大的力量。本文试图采用图解的方式对九种数据结构进行理论上的介绍，但是其实这都是不够的。 即便是简单的数组、栈、队列等结构，在实际使用以及底层实现上都会有许多优化设计以及使用技巧，这意味着还需要真正把它们灵活的用起来，才能够算是真正意义上的熟悉和精通。但是本文可以作为常见数据结构的一个总结，当你对某些结构有些淡忘的时候，不妨重新回来看看。","categories":[{"name":"数据结构","slug":"数据结构","permalink":"https://topone233.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"https://topone233.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}]},{"title":"二叉树的四种遍历方式","slug":"二叉树的四种遍历方式","date":"2020-07-10T09:07:59.381Z","updated":"2020-09-07T14:20:14.567Z","comments":true,"path":"2020/07/10/二叉树的四种遍历方式/","link":"","permalink":"https://topone233.github.io/2020/07/10/%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E5%9B%9B%E7%A7%8D%E9%81%8D%E5%8E%86%E6%96%B9%E5%BC%8F/","excerpt":"","text":"原文地址 www.cnblogs.com 二叉树的四种遍历方式： 二叉树的遍历（traversing binary tree）是指从根结点出发，按照某种次序依次访问二叉树中所有的结点，使得每个结点被访问依次且仅被访问一次。四种遍历方式分别为：先序遍历、中序遍历、后序遍历、层序遍历。 树的相关术语：节点的度：一个节点含有的子树的个数称为该节点的度； 叶节点：度为0的节点； 树的度：一棵树中，最大的节点的度； 森林：由m（m&gt;=0）棵互不相交的树的集合 树的符号表现法：（1（2（4（5，6）），3） 解读：祖先1的子节点2（子节点4（叶节点5，6）），3。同层子树间用逗号隔开。 如何创建二叉树遍历之前，我们首先介绍一下，如何创建一个二叉树，在这里我们用的是先建左树在建右树的方法， 首先要声明结点 TreeNode 类，代码如下： public class TreeNode { public int data; public TreeNode leftChild; public TreeNode rightChild; public TreeNode(int data){ this.data = data; } } 再来创建一颗二叉树： /** * 构建二叉树 * @param list 输入序列 * @return */ public static TreeNode createBinaryTree(LinkedList&lt;Integer&gt; list){ TreeNode node = null; if(list == null || list.isEmpty()){ return null; } Integer data = list.removeFirst(); if(data!=null){ node = new TreeNode(data); node.leftChild = createBinaryTree(list); node.rightChild = createBinaryTree(list); } return node; } 接下来我们按照上面列的顺序一一讲解， 先序遍历首先来看先序遍历，所谓的先序遍历就是先访问根节点，在访问左节点，最后访问右节点， 如上图所示，前序遍历结果为：ABDFECGHI 实现代码如下： /** * 二叉树前序遍历 根-&gt; 左-&gt; 右 * @param node 二叉树节点 */ public static void preOrderTraveral(TreeNode node){ if(node == null){ return; } System.out.print(node.data+&quot; &quot;); preOrderTraveral(node.leftChild); preOrderTraveral(node.rightChild); } 中序遍历再者就是中序遍历，所谓的中序遍历就是先访问左节点，再访问根节点，最后访问右节点， 如上图所示，中序遍历结果为：DBEFAGHCI（G没有左子树，所以直接访问G，而不是访问H） 实现代码如下： /** * 二叉树中序遍历 左-&gt; 根-&gt; 右 * @param node 二叉树节点 */ public static void inOrderTraveral(TreeNode node){ if(node == null){ return; } inOrderTraveral(node.leftChild); System.out.print(node.data+&quot; &quot;); inOrderTraveral(node.rightChild); } 后序遍历最后就是后序遍历，所谓的后序遍历就是先访问左节点，再访问右节点，最后访问根节点。 如上图所示，前序遍历结果为：DEFBHGICA 实现代码如下： /** * 二叉树后序遍历 左-&gt; 右-&gt; 根 * @param node 二叉树节点 */ public static void postOrderTraveral(TreeNode node){ if(node == null){ return; } postOrderTraveral(node.leftChild); postOrderTraveral(node.rightChild); System.out.print(node.data+&quot; &quot;); } 非递归的前中后序遍历讲完上面三种非递归的方法，下面再给大家讲讲非递归是如何实现前中后序遍历的 非递归前序遍历还是一样，先看非递归前序遍历 首先申请一个新的栈，记为 stack； 声明一个结点 treeNode，让其指向 node 结点； 如果 treeNode 的不为空，将 treeNode 的值打印，并将 treeNode 入栈，然后让 treeNode 指向 treeNode 的右结点， 重复步骤 3，直到 treenode 为空； 然后出栈，让 treeNode 指向 treeNode 的右孩子 重复步骤 3，直到 stack 为空. 实现代码如下： public static void preOrderTraveralWithStack(TreeNode node){ Stack&lt;TreeNode&gt; stack = new Stack&lt;TreeNode&gt;(); TreeNode treeNode = node; while(treeNode!=null || !stack.isEmpty()){ //迭代访问节点的左孩子，并入栈 while(treeNode != null){ System.out.print(treeNode.data+&quot; &quot;); stack.push(treeNode); treeNode = treeNode.leftChild; } //如果节点没有左孩子，则弹出栈顶节点，访问节点右孩子 if(!stack.isEmpty()){ treeNode = stack.pop(); treeNode = treeNode.rightChild; } } } 非递归中序遍历中序遍历非递归，在此不过多叙述具体步骤了， 具体过程： 申请一个新栈，记为 stack，申请一个变量 cur，初始时令 treeNode 为头节点； 先把 treeNode 节点压入栈中，对以 treeNode 节点为头的整棵子树来说，依次把整棵树的左子树压入栈中，即不断令 treeNode=treeNode.leftChild，然后重复步骤 2； 不断重复步骤 2，直到发现 cur 为空，此时从 stack 中弹出一个节点记为 treeNode，打印 node 的值，并让 treeNode= treeNode.right，然后继续重复步骤 2； 当 stack 为空并且 cur 为空时结束。 public static void inOrderTraveralWithStack(TreeNode node){ Stack&lt;TreeNode&gt; stack = new Stack&lt;TreeNode&gt;(); TreeNode treeNode = node; while(treeNode!=null || !stack.isEmpty()){ while(treeNode != null){ stack.push(treeNode); treeNode = treeNode.leftChild; } if(!stack.isEmpty()){ treeNode = stack.pop(); System.out.print(treeNode.data+&quot; &quot;); treeNode = treeNode.rightChild; } } } 非递归后序遍历后序遍历这里较前两者实现复杂一点，我们需要一个标记为来记忆我们此时节点上一个节点，具体看代码注释 public static void postOrderTraveralWithStack(TreeNode node){ Stack&lt;TreeNode&gt; stack = new Stack&lt;TreeNode&gt;(); TreeNode treeNode = node; TreeNode lastVisit = null; //标记每次遍历最后一次访问的节点 while(treeNode!=null || !stack.isEmpty()){//节点不为空，结点入栈，并且指向下一个左孩子 while(treeNode!=null){ stack.push(treeNode); treeNode = treeNode.leftChild; } //栈不为空 if(!stack.isEmpty()){ //出栈 treeNode = stack.pop(); /** * 这块就是判断treeNode是否有右孩子， * 如果没有输出treeNode.data，让lastVisit指向treeNode，并让treeNode为空 * 如果有右孩子，将当前节点继续入栈，treeNode指向它的右孩子,继续重复循环 */ if(treeNode.rightChild == null || treeNode.rightChild == lastVisit) { System.out.print(treeNode.data + &quot; &quot;); lastVisit = treeNode; treeNode = null; }else{ stack.push(treeNode); treeNode = treeNode.rightChild; } } } } 层序遍历最后再介绍一下层序遍历 具体步骤如下： 首先申请一个新的队列，记为 queue； 将头结点 head 压入 queue 中； 每次从 queue 中出队，记为 node，然后打印 node 值，如果 node 左孩子不为空，则将左孩子入队；如果 node 的右孩子不为空，则将右孩子入队； 重复步骤 3，直到 queue 为空。 实现代码如下： public static void levelOrder(TreeNode root){ LinkedList&lt;TreeNode&gt; queue = new LinkedList&lt;&gt;(); queue.add(root); while(!queue.isEmpty()){ root = queue.pop(); System.out.print(root.data+&quot; &quot;); if(root.leftChild!=null) queue.add(root.leftChild); if(root.rightChild!=null) queue.add(root.rightChild); } }","categories":[{"name":"数据结构","slug":"数据结构","permalink":"https://topone233.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"https://topone233.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"二叉树","slug":"二叉树","permalink":"https://topone233.github.io/tags/%E4%BA%8C%E5%8F%89%E6%A0%91/"}]},{"title":"时间复杂度","slug":"时间复杂度","date":"2020-07-06T16:00:00.000Z","updated":"2020-09-07T14:19:14.759Z","comments":true,"path":"2020/07/07/时间复杂度/","link":"","permalink":"https://topone233.github.io/2020/07/07/%E6%97%B6%E9%97%B4%E5%A4%8D%E6%9D%82%E5%BA%A6/","excerpt":"","text":"时间复杂度 若存在函数 f(n)，使得当n趋近于无穷大时，T(n) / f(n) 的极限值为不等于零的常数，则称 f(n) 是 T(n) 的同数量级函数。记作 T(n) = O( f(n) )，称 O( f(n) ) 为算法的渐进时间复杂度(asymptotic time complexity)，简称时间复杂度。 OK，我们先引出官方的定义先混个眼熟。接下来看几个通俗易懂的案例： 场景1：问：给李华一个长n寸的面包，每3天吃掉1寸，几天吃完？ 答：3 X n = 3n 天。 如果用函数表达这个相对时间：T(n) = 3n 场景2：问：给李华一个长16寸的面包，每5天吃掉面包剩余长度的一半。第一次吃掉8寸，第二次吃4寸，…… 几天可以吃得只剩1寸？ 答：5 X log16 = 20天。 T(n) = 5log n 场景3：问：给李华一个长10寸的面包和一个鸡腿，每2天吃掉1个鸡腿，几天吃完鸡腿？ 答：2天 （与面包一点关系没有）。 T(n) = 2 场景4：问：给李华一个长10寸的面包，吃掉第一个一寸需要1天时间，吃掉第二个一寸需要2天时间，吃掉第三个一寸需要3天时间…..每多吃一寸，所花的时间也多一天，几天吃完？ 答：1到10的和 = 55天 1+2+3+……+ n-1 + n = (1+n)*n/2 = 0.5n^2 + 0.5n 。 T(n) = 0.5n^2 + 0.5n 相信通过以上4个案例已经了解了： T(n) 基本操作执行次数的函数。 那么如何推导出时间复杂度呢？有如下几个原则： 如果运行时间是常数量级，用常数1表示； 只保留时间函数中的最高阶项； 如果最高阶项存在，则省去最高阶项前面的系数。 渐进分析（asymptotic analysis）：忽略掉那些依赖于机器的常量，不去检查实际的运行时间，而是关注运行时间的增长。 在看刚才的四个场景： 场景1： T(n) = 3n 最高阶项为3n，省去系数3，时间复杂度为：O(n) 场景2： T(n) = 5log n 最高阶项为5log n，省去系数5，时间复杂度为：O(log n) 场景3： T(n) = 2 只有常数量级，时间复杂度为：O(1) 场景4： T(n) = 0.5n^2 + 0.5n 最高阶项为0.5n^2，省去系数0.5，时间复杂度为：O(n^2) O（1）&lt; O（log n）&lt; O（n）&lt; O（n^2） 空间复杂度空间复杂度：即程序中变量的个数 位运算位运算在算法中很有用，速度可以比四则运算快很多。 左移 &lt;&lt;10 &lt;&lt; 1 结果： 20 左移就是将二进制全部往左移动。10的二进制：1010，左移一位：10100，十进制就是20。 基本可以把左移看作：a * (2 ^ b) 右移 &gt;&gt;10 &gt;&gt; 1 结果： 5 右移就是将二进制全部往右移动，并去除多余的右边。右移一位：101，十进制就是5 基本可以把右移看作：a / (2 ^ b) 右移很好用，比如可以用在二分算法中取中间值","categories":[{"name":"数据结构","slug":"数据结构","permalink":"https://topone233.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"https://topone233.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}]},{"title":"Hello World！（hexo配置记录）","slug":"Hello World！（hexo配置记录）","date":"2020-07-01T02:25:00.000Z","updated":"2020-09-07T14:18:48.816Z","comments":true,"path":"2020/07/01/Hello World！（hexo配置记录）/","link":"","permalink":"https://topone233.github.io/2020/07/01/Hello%20World%EF%BC%81%EF%BC%88hexo%E9%85%8D%E7%BD%AE%E8%AE%B0%E5%BD%95%EF%BC%89/","excerpt":"","text":"Hello World！（hexo配置记录）以前在网上冲浪的时候只是不经意间发现许多让人眼前一亮的blog，由此萌生了create my blog的想法。 目前的blog搭建： CSDN/博客园平台 但我个人不是很喜欢这种，首先是太丑了（没错，就是你，CSDN）。 其次依托于平台，虽然只需要创作就行，但是感觉不是属于自己的，没有归属感 独立blog 租云服务器、买域名，还要管理维护，个人感觉略微有些费事，精力有限，还是简单点好 hexo 依托于Github，也是我目前选择的，配置相对简单快捷，主题丰富 hexo配置步骤： 安装Git 安装Node.js 安装hexo 生成ssh并添加到GitHub 部署项目 上传到GitHub 修改主题 1.安装Git下载地址 安装步骤：双击下载的exe文件，一路next就行 2.安装Node.jsHexo是基于nodeJS环境的静态博客，npm是必备的 下载地址 安装步骤：下载好msi文件后，双击打开安装，也是一路next，不过在Custom Setup这一步记得选 Add to PATH ,这样你就不用自己去配置电脑上环境变量了 3.安装hexo 创建一个源文件夹，然后cd到该文件夹下 安装hexo： npm i -g hexo hexo -v 查看版本，检查是否安装成功 hexo init 初始化，初始化完成后可在文件夹下看到文件 这里要说下，npm install出现一直停留在”fetchMetadata: sill resolveWithNewModule find-cache-dir@”解决方法，更换成淘宝的源（反正我是解决了） //修改为淘宝源 npm config set registry https://registry.npm.taobao.org //配置后可通过下面方式来验证是否成功 npm config get registry //或 npm info express4.生成ssh并添加到GitHubSSH密钥可以防止其他人恶意部署文件到你的仓库 首先要有GitHub账号，没有的自行注册 创建一个仓库repository，名称为youname.github.io 在gitbash中，配置GitHub账号信息 //配置你的GitHub账号信息 git config --global user.name &quot;YourName&quot; git config --global user.email &quot;YourEmail&quot;创建ssh //创建ssh ssh-keygen -t rsa -C &quot;youremail@xx.com&quot;生成ssh，在gitbash中切换到文件目录cat读取 //读取ssh文件内容 cat id_rsa.pub 全部复制（包括开头的ssh-rsa，和尾部的email）到GitHub 配置ssh，title随便起 5.部署项目修改hexo的_config.yml文件配置信息（直接复制，只需要修改url即可） deploy: type: git repo: https://github.com/YourgithubName/YourgithubName.github.io.git branch: master回到gitbash，进入hexo目录 hexo clean hexo generate hexo server这时，在http://localhost:4000就可以看到默认页面 6.上传到GitHubnpm install hexo-deployer-git --save将写好的文章部署到GitHub服务器，执行命令 hexo clean hexo generate hexo deploy 第一次deploy要输入GitHubusername和password完成后https://yourgithubname.github.io，查看即可 7.修改主题hexo官网有推荐很多很多主题，自行选择","categories":[],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://topone233.github.io/tags/hexo/"}]}],"categories":[{"name":"网络协议","slug":"网络协议","permalink":"https://topone233.github.io/categories/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/"},{"name":"Java","slug":"java","permalink":"https://topone233.github.io/categories/java/"},{"name":"SQL","slug":"sql","permalink":"https://topone233.github.io/categories/sql/"},{"name":"工具","slug":"工具","permalink":"https://topone233.github.io/categories/%E5%B7%A5%E5%85%B7/"},{"name":"NoSQL","slug":"nosql","permalink":"https://topone233.github.io/categories/nosql/"},{"name":"Spring","slug":"spring","permalink":"https://topone233.github.io/categories/spring/"},{"name":"操作系统","slug":"操作系统","permalink":"https://topone233.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"数据结构","slug":"数据结构","permalink":"https://topone233.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}],"tags":[{"name":"网络协议","slug":"网络协议","permalink":"https://topone233.github.io/tags/%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE/"},{"name":"SSL","slug":"ssl","permalink":"https://topone233.github.io/tags/ssl/"},{"name":"安全","slug":"安全","permalink":"https://topone233.github.io/tags/%E5%AE%89%E5%85%A8/"},{"name":"TCP","slug":"tcp","permalink":"https://topone233.github.io/tags/tcp/"},{"name":"滑动窗口","slug":"滑动窗口","permalink":"https://topone233.github.io/tags/%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3/"},{"name":"Java","slug":"java","permalink":"https://topone233.github.io/tags/java/"},{"name":"集合","slug":"集合","permalink":"https://topone233.github.io/tags/%E9%9B%86%E5%90%88/"},{"name":"JVM","slug":"jvm","permalink":"https://topone233.github.io/tags/jvm/"},{"name":"GC","slug":"gc","permalink":"https://topone233.github.io/tags/gc/"},{"name":"SQL","slug":"sql","permalink":"https://topone233.github.io/tags/sql/"},{"name":"工具","slug":"工具","permalink":"https://topone233.github.io/tags/%E5%B7%A5%E5%85%B7/"},{"name":"配置","slug":"配置","permalink":"https://topone233.github.io/tags/%E9%85%8D%E7%BD%AE/"},{"name":"NoSQL","slug":"nosql","permalink":"https://topone233.github.io/tags/nosql/"},{"name":"Spring","slug":"spring","permalink":"https://topone233.github.io/tags/spring/"},{"name":"CORS","slug":"cors","permalink":"https://topone233.github.io/tags/cors/"},{"name":"RESTful","slug":"restful","permalink":"https://topone233.github.io/tags/restful/"},{"name":"IO","slug":"io","permalink":"https://topone233.github.io/tags/io/"},{"name":"操作系统","slug":"操作系统","permalink":"https://topone233.github.io/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"进程与线程","slug":"进程与线程","permalink":"https://topone233.github.io/tags/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B/"},{"name":"数据结构","slug":"数据结构","permalink":"https://topone233.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"排序算法","slug":"排序算法","permalink":"https://topone233.github.io/tags/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/"},{"name":"动态代理","slug":"动态代理","permalink":"https://topone233.github.io/tags/%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86/"},{"name":"HashMap","slug":"hashmap","permalink":"https://topone233.github.io/tags/hashmap/"},{"name":"二叉树","slug":"二叉树","permalink":"https://topone233.github.io/tags/%E4%BA%8C%E5%8F%89%E6%A0%91/"},{"name":"hexo","slug":"hexo","permalink":"https://topone233.github.io/tags/hexo/"}]}