{"meta":{"title":"QSX1C","subtitle":" ","description":"","author":"QSX1C","url":"https://topone233.github.io","root":"/"},"pages":[{"title":"about","date":"2020-07-12T08:05:04.000Z","updated":"2020-07-12T08:05:18.584Z","comments":true,"path":"about/index.html","permalink":"https://topone233.github.io/about/","excerpt":"","text":""},{"title":"contact","date":"2020-07-12T08:05:31.000Z","updated":"2020-07-12T08:05:48.424Z","comments":true,"path":"contact/index.html","permalink":"https://topone233.github.io/contact/","excerpt":"","text":""},{"title":"categories","date":"2020-07-12T08:02:56.000Z","updated":"2020-07-12T08:04:10.280Z","comments":true,"path":"categories/index.html","permalink":"https://topone233.github.io/categories/","excerpt":"","text":""},{"title":"tags","date":"2020-07-12T08:04:26.000Z","updated":"2020-07-12T08:04:53.027Z","comments":true,"path":"tags/index.html","permalink":"https://topone233.github.io/tags/","excerpt":"","text":""}],"posts":[{"title":"Spring Bean","slug":"Spring Bean","date":"2020-08-22T08:14:36.429Z","updated":"2020-08-25T13:30:03.023Z","comments":true,"path":"2020/08/22/Spring Bean/","link":"","permalink":"https://topone233.github.io/2020/08/22/Spring%20Bean/","excerpt":"","text":"Spring IoC容器可以创建、装配、配置应用组件对象，这里的组件对象称为Bean。 1.Bean 的配置Spring可以看作一个工厂，用于生产和管理Spring容器中的Bean。 如果要使用这个工厂生产和管理Bean，需要将Bean配置在Spring的配置文件中。支持 XML 和 Properties 两种格式的配置文件，常用 XML格式。 元素的常用属性及其子元素： 属性或子元素 描述 id Bean在BeanFactory中的唯一标识，在代码中通过BeanFactory获取Bean实例时需要依次作为索引名称 class Bean的具体实现类，例如dao.TestDIDaoImpl scope 指定Bean实例的作用域 用于设置一个属性。name 指定Bean实例中相应的属性名称、value 指定Bean的属性值、ref 指定属性对BeanFactory中其他Bean的引用关系 使用构造方法注入，指定构造方法的参数。index指定参数的序号，ref指定对BeanFactory中其他Bean的引用关系，type指定参数类型，value指定参数的常量值 、 的子元素，封装对应类型的依赖注入 的子元素，封装List 、数组类型的依赖注入 的子元素，用于设置一个键值对 2.Bean 的实例化在面向对象编程时，如果要使用某个对象，需要事先实例化该对象。Spring中，也需要先实例化Bean。 有3种方式：构造方法实例化、静态工厂实例化、实例工厂实例化。最常用构造方法实例化。 2.1构造方法实例化Spring容器调用Bean对应类中的无参数构造方法来实例化Bean。 创建BeanClass类 package instance; public class BeanClass { public String message; public BeanClass() { message = &quot;构造方法实例化Bean&quot;; } public BeanClass(String s) { message = s; } }创建配置文件applicationContext.xml &lt;!-- 构造方法实例化Bean --&gt; &lt;bean id=&quot;demo&quot; class=&quot;instance.BeanClass&quot;/&gt;创建测试类 package test; public class TestInstance { public static void mani(String[] args) { ApplicationContext appCon = new ClassPathXmlApplicationContext(&quot;applicationContext.xml&quot;); BeanClass b = (BeanClass)appCon.getBean(&quot;demo&quot;); System.out.println(b1 + b1.message); } } 结果：instance.BeanClass@490ab905构造方法实例化Bean3.Bean的作用域 scope参数 描述 singleton 默认的作用域，定义的Bean在Spring容器中只有一个Bean实例（返回同一个） prototype Spring容器每次获取Bean，都将创建一个新的Bean实例（每次都返回新的） request 每次HTTP请求都会返回一个Bean实例 session 在一个session中，将返回同一个Bean实例 application 为每个ServletContext对象创建一个实例，即同一个应用共享一个 websocket 为每个WebSocket对象创建一个实例 singleton 与 prototype是最常用的，后面4种仅在Web Spring应用上下文中使用。 4.Bean的生命周期一个对象的生命周期包括：创建（实例化与初始化）、使用、销毁。Bean也遵循这一过程。但是Spring通过了许多对外接口，允许开发者对 实例化（开辟空间）、初始化（属性初始化）、销毁 3个过程的前后做一些操作。 Spring容器可以管理singleton作用域下Bean的生命周期，能够精确知道Bean何时被创建，何时初始化完成，何时被销毁。而对于prototype作用域下的Bean，Spring只负责创建。创建之后Bean实例就交给客户端的代码管理，Spring将不再跟踪其生命周期，也不会管理这些Bean。 Bean的生命周期： 根据Bean的配置情况实例化一个Bean。 根据Spring上下文对实例化的Bean进行依赖注入，即对Bean的属性进行初始化。 如果Bean实现了 BeanNameAware接口，将调用它实现的 setBeanName(String beanId)方法，此处参数传递的是Bean的id，让实现这个接口的Bean知道自己在Spring容器中的的名字。 如果Bean实现了 BeanFactoryAware接口，将调用它实现的 setBeanFactory方法，此处参数传递的是当前Spring工厂实例的引用。此接口是在Bean实例化后、Setter方法之前调用。可以使得Bean获取容器的内部信息，从而进行某些定制化的操作。 如果Bean实现了 ApplicationContextAware接口，将调用它实现的setApplicationContext(ApplicationContext)方法，此处参数传递的是Spring上下文实例的引用。该方法会将容器本身作为参数传给该方法，将Spring传入的参数赋给该类对象的applicationContext实例变量，接下来可以通过该变量来访问容器本身。 如果Bean关联了 BeanPostProcessor接口，将调用初始化方法 postProcessBeforeInitialization(Object obj, String beanName)对Bean进行前置处理。BeanFactoryPostProcessor是Bean属性处理容器，管理所有未实例化的数据（修改属性）。 如果Bean实现了 InitializingBean接口，将调用 afterPropertiesSet方法。 如果Bean在Spring配置文件中配置了 init-method属性，将自动调用其配置的初始化方法。 注意：Spring为Bean提供了两种初始化方式：实现InitializingBean接口、init-method指定。 ​ 两种方式可以同时使用，但如果调用afterPropertiesSet时出错，则不会调用init-method指定的方法。 ​ 通过反射调用init-method指定的方法效率相对较低，但是消除了对Spring的依赖。 如果Bean关联了 BeanPostProcessor接口，将调用 postProcessAfterInitialization(Object obj, String beanName)方法进行后置处理，由于是在Bean初始化结束时调用After方法，也可用于内存或缓存技术。 注意：此时已经可以使用该Bean，由于该Bean的作用域是singleton，所以调用的是同一个Bean实例。 当Bean不再需要时将进入销毁阶段，如果Bean实现了 DisposableBean接口，则调用其实现的destroy方法将Bean销毁 如果在配置文件中通过 destroy-method属性指定了Bean的销毁方法，将调用其配置的销毁方法进行销毁 实例演示： package life; public class BeanLife { public void initMyself() { System.out.println(this.getClass().getName() + &quot;执行自定义的初始化方法&quot;); } public void destroyMyself() { System.out.println(this.getClass().getName() + &quot;执行自定义的销毁方法&quot;)； } }&lt;!-- 使用init-method属性指定初始化方法，使用destroy-method属性指定销毁方法--&gt; &lt;bean id=&quot;beanLife&quot; class=&quot;life.BeanLife&quot; init-method=&quot;initMyself&quot; destroy-method=&quot;destroyMyself&quot;/&gt;package test; public class TestLife { public static void main(String[] args) { ClassPathXmlApplicationContext ctx = new ClassPathXmlApplicationContext(&quot;applicationContext.xml&quot;); BeanLife blife = (BeanLife)ctx.genBean(&quot;beanLife&quot;); System.out.println(&quot;获得对象后&quot; + blife); // 关闭容器，销毁Bean对象 ctx.close(); } }5.Bean的装配Bean的装配可以理解为将Bean依赖注入到Spring容器中。Spring容器支持：基于XML配置、基于注解、自动装配等多种装配方式，最常见的是基于注解。 5.1基于注解的装配尽管使用XML配置文件可以很简单的装配Bean，但如果有大量的Bean，会导致XML配置文件过于庞大，不方便升级与维护，因此更推荐使用注解（annotation）。 @Repository 将数据访问层（DAO）的类标识为Bean。 @Service 将业务逻辑组件类（Service层）标注为Bean。 @Controller 将控制器组件类标注为Bean。 @Component 可以作用在任何层次上，标注一个Bean。为了更加层次化，不推荐使用。 @Autowired 对类成员变量、方法、构造方法进行标注，完成自动装配工作。可以消除setter和getter方法。默认按照Bean的类型进行装配，如果想按照名称装配，需要和@Qualifier 一起使用 @Resource(name=” “) 与@Autowired 功能一样，区别在于该注解默认是按照名称来装配注入的，只有找不到与名称匹配的Bean时才会按照Bean的类型来装配注入。@Resource有两个属性：name、type。name指定Bean实例名称，即按照名称来装配；type指定类型，即按照类型来装配。 @Qualifier 与@Autowired配合使用，当需要按照名称装配时。Bean的实例名称由@Qualifier 的参数指定。","categories":[{"name":"Spring","slug":"spring","permalink":"https://topone233.github.io/categories/spring/"}],"tags":[{"name":"Java","slug":"java","permalink":"https://topone233.github.io/tags/java/"},{"name":"Spring","slug":"spring","permalink":"https://topone233.github.io/tags/spring/"}]},{"title":"Spring IoC","slug":"Spring IoC","date":"2020-08-22T08:09:05.509Z","updated":"2020-08-25T13:30:26.497Z","comments":true,"path":"2020/08/22/Spring IoC/","link":"","permalink":"https://topone233.github.io/2020/08/22/Spring%20IoC/","excerpt":"","text":"1. IoC 的基本概念 IoC（Inversion of Control，控制反转）是一个比较抽象的概念，是Spring框架的核心，用来消减程序的耦合问题。DI（Dependency Injection，依赖注入）是IoC的另外一种说法，只是从不同的角度描述相同的概念。 想吃面包，你可以自己做。也可以选择在面包店下单，告诉店家你的需求，然后等着吃就行。 上面的例子包含了控制反转的思想：把制作面包的主动权交给面包店。 当某个Java对象（调用者，例如我），需要调用另一个Java对象（被调用者，即被依赖对象，例如面包）时，以前我们通常会“new 被调用者”来创建对象（例如我们自己做面包）。这种方式会增加调用者与被调用者之间的耦合性，不利于后期代码的升级和维护。 Spring出现后，对象的实例由Spring容器（例如面包店）来创建。Spring容器会负责控制程序之间的关系（例如面包店负责控制我们与面包的关系）。这样控制权就由调用者转移到Spring容器，控制权发生了反转。 依赖注入：Spring容器负责将依赖对象赋值给调用者的成员变量，相当于为调用者注入它所依赖的实例。这就是依赖注入。 综上所述，控制反转是一种通过描述（XML或者注解）并通过第三方去产生或获取特定对象的方式。实现控制反转的是IoC容器，其实现方式是依赖注入。 2.IoC 容器前面我们知道，实现控制反转的是IoC容器。IoC容器的设计主要是基于BeanFactory 和 ApplicationContext 两个接口。 2.1 BeanFactory 接口BeanFactory 由org.springframework.beans.factory.BeanFactory接口定义，提供了完整的IoC服务支持，是一个管理Bean的工厂，主要负责初始化各种Bean。 BeanFactory接口有很多实现类，常用的是XmlBeanFactory，根据XML配置文件中的定义来配置Bean。 使用BeanFactory实例加载Spring配置文件实际并不多见，仅作了解。 2.2 ApplicationContext 接口ApplicationContext 是BeanFactory的子接口，也称应用上下文。除了包含BeanFactory的所有功能以外，还添加了对国际化、资源访问、事件传播等内容的支持。 创建ApplicationContext接口实例通常有以下三种方法： 2.2.1 通过ClassPathXmlApplicationContextpublic static void main(String[] args) { // 初始化Spring容器ApplicationContext，加载指定的XML配置文件 ApplicationContext appCon = new ClassPathXmlApplicationContext(&quot;applicationContext.xml&quot;); // 通过容器获取test实例 TestDao tt = (TestDao)appCon.getBean(&quot;test&quot;); tt.sayHello(); }2.2.2通过FileSystemXmlApplicationContext创建// 仅需要修改这一行代码 ApplicationContext appCon = new FileSystemXmlApplicationContext(&quot;D:\\test\\applicationContext.xml&quot;);FileSystemXmlApplicationContext 将从指定文件的绝对路径中寻找XML配置文件，但是绝对路径会导致程序的灵活性变差，不推荐使用。通常Spring的Java应用采用ClassPathXmlApplicationContext类来实例化ApplicationContext容器，而Web应用中，将交给Web服务器完成。 2.2.3通过Web服务器实例化ApplicationContext容器Web服务器实例化ApplicationContext容器时，一般使用基于org.springframework.web.context.ContextLoaderListener的实现方式。 &lt;context-param&gt; &lt;!-- 加载src目录下的applicationContext.xml文件 --&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt; classpath:applicationContext.xml &lt;/param-value&gt; &lt;/context-param&gt; &lt;!-- 指定以ContextLoaderListener方式启动Spring容器 --&gt; &lt;listener&gt; &lt;listener-class&gt; org.springframework.web.context.ContextLoaderListener &lt;/listener-class&gt; &lt;/listener&gt;3.依赖注入 Spring中实现IoC容器的方法是依赖注入。依赖注入的作用是在使用Spring创建对象时，动态地将其所依赖的对象（例如属性值）注入Bean组件中。 3.1使用属性的setter方法注入依赖注入通常有两种实现方式：构造方法注入、属性的setter方法注入。（这两种方式都是基于Java的反射机制）。 使用setter方法注入是Spring中最主流的注入方式，利用Java Bean规范所定义的setter方法来完成注入，灵活且可读性高。 下面将两者放在一起进行，方便对比。 3.1.1创建dao包在dao包创建TestDIDao接口及其实现类TestDIDaoImpl package dao; public interface TestDIDao { public void sayHello(); }package dao; public class TestDIDaoImpl implements TestDIDao { @Override public void sayHello() { System.out.println(&quot;TestDIDao say: Hello&quot;); } }3.1.2创建service包service包中创建TestDIService接口及其实现类TestDIServiceImpl package service; public interface TestDIService { public void sayHello(); }package service; import dao.TestDIDao; public class TestDIServiceImpl implements TestDIService { private TestDIDao testDIDao; // 添加testDIDao属性的setter方法，用于实现依赖注入 public void setTestDIDao(TestDIDao testDIDao) { this.testDIDao = testDIDao; } /* 构造方法，用于实现依赖注入接口对象testDIDao public TestDIServiceImpl(TestDIDao testDIDao) { super(); this.testDIDao = testDIDao; } */ @Override public void sayHello() { // 调用testDIDao中的sayHelllo方法 testDIDao.sayHello(); System.out.println(&quot;TestDIService setter方法注入 say: Hello&quot;); } }3.1.3编写配置文件在src根目录下创建Spring配置文件 applicationContext.xml。将TestDIServiceImpl类托管给Spring，让Spring创建其对象，同时调用其setter方法完成依赖注入。 &lt;!-- 将TestDIDaoImpl类配置给Spring，让Spring创建其实例 --&gt; &lt;bean id=&quot;myTestDIDao&quot; class=&quot;dao.TestDIDaoImpl&quot;/&gt; &lt;!-- 使用setter方法注入 --&gt; &lt;bean id=&quot;testDIService&quot; class=&quot;service.TestDIServiceImpl&quot;&gt; &lt;!-- 调用TestDIServiceImpl类的setter方法，将myTestDIDao注入到TestDIServiceImpl类的属性testDIDao上--&gt; &lt;property name=&quot;testDIDao&quot; ref=&quot;myTestDIDao&quot;/&gt; &lt;/bean&gt; /* &lt;!-- 使用构造方法注入 --&gt; &lt;bean id=&quot;testDIService&quot; class=&quot;service.TestDIServiceImpl&quot;&gt; &lt;!-- 将myTestDIDao注入到TestDIServiceImpl类的属性testDIDao上--&gt; &lt;!-- constructor-arg元素用于定义类构造方法的参数，index定义参数的位置--&gt; &lt;!-- ref指定某个实例的引用，如果参数是常量值，ref由value代替--&gt; &lt;constructor-arg index=&quot;o&quot; ref=&quot;myTestDIDao&quot;/&gt; &lt;/bean&gt; */3.1.4测试创建test包，并创建TestDI测试类 package test; public class TestDI { public static void main(String[] args) { ApplicationContext appCon = new ClassPathXmlApplicationContext(&quot;applicationContext.xml&quot;) TestDIservice ts = (TestDIService)appCon.getBean(&quot;testDIService&quot;); ts.sayHello(); } }","categories":[{"name":"Spring","slug":"spring","permalink":"https://topone233.github.io/categories/spring/"}],"tags":[{"name":"Java","slug":"java","permalink":"https://topone233.github.io/tags/java/"},{"name":"Spring","slug":"spring","permalink":"https://topone233.github.io/tags/spring/"}]},{"title":"CORS RESTful Web Service","slug":"CORS RESTful Web Service","date":"2020-08-20T13:28:36.452Z","updated":"2020-08-25T13:13:07.313Z","comments":true,"path":"2020/08/20/CORS RESTful Web Service/","link":"","permalink":"https://topone233.github.io/2020/08/20/CORS%20RESTful%20Web%20Service/","excerpt":"","text":"Enabling Cross Origin Requests for a RESTful Web Service 直奔主题，将使用Spring Boot快速构建项目部分省略，如果需要请访问：https://spring.io/guides/gs/rest-service-cors/ 前言RESTfulRepresentational State Transfer 表述行状态转移，是一种设计风格和开发方式。 Web应用最重要的REST原则是，客户端与服务端之间的交互请求是无状态的。客户端到服务端的请求必须包含理解请求所必需的信息；请求可以由任何可用服务器回答。 资源与URL REST全称是表述性状态转移，那究竟指的是什么的表述? 其实指的就是资源。任何事物，只要有被引用到的必要，它就是一个资源。 要让一个资源可以被识别，需要有个唯一标识，在Web中这个唯一标识就是URI(Uniform Resource Identifier)。URI既可以看成是资源的地址，也可以看成是资源的名称。如果某些信息没有使用URI来表示，那它就不能算是一个资源， 只能算是资源的一些信息而已。 统一资源接口 RESTful架构应该遵循统一接口原则，统一接口包含了一组受限的预定义的操作，不论什么样的资源，都是通过使用相同的接口进行资源的访问。接口应该使用标准的HTTP方法如GET，PUT和POST，并遵循这些方法的语义。 如果按照HTTP方法的语义来暴露资源，那么接口将会拥有安全性和幂等性的特性，例如GET和HEAD请求都是安全的， 无论请求多少次，都不会改变服务器状态。而GET、HEAD、PUT和DELETE请求都是幂等的，无论对资源操作多少次， 结果总是一样的，后面的请求并不会产生比第一次更多的影响。 CORSCross Origin Resource Sharing 跨源资源共享。 是一种机制，它使用额外的 HTTP头来告诉浏览器 让运行在一个 origin (domain) 上的Web应用被准许访问来自不同源服务器上的指定的资源。当一个资源从与该资源本身所在的服务器不同的域、协议或端口请求一个资源时，资源会发起一个跨域 HTTP 请求。 1.Resource Representation Classpackage com.example.restservicecors; public class Greeting { private final long id; private final String content; public Greeting() { this.id = -1; this.content = &quot;&quot;; } public Greeting(long id, String content) { this.id = id; this.content = content; } public long getId() { return id; } public String getContent() { return content; } }Spring使用Jackson JSON库自动将Greeting类型的实例编组为JSON 2.Resource Controllerpackage com.example.restservicecors; import java.util.concurrent.atomic.AtomicLong; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.RequestParam; import org.springframework.web.bind.annotation.CrossOrigin; import org.springframework.web.bind.annotation.RestController; @RestController public class GreetingController { private static final String template = &quot;Hello, %s!&quot;; private final AtomicLong counter = new AtomicLong(); @GetMapping(&quot;/greeting&quot;) public Greeting greeting(@RequestParam(required=false, defaultValue=&quot;World&quot;) String name) { System.out.println(&quot;==== in greeting ====&quot;); /** * 创建并返回一个新的Greeting对象 * 具有基于计数器（counter）的下一个值的 id 和 context * 并使用Greeting模板格式化给定的name */ return new Greeting(counter.incrementAndGet(), String.format(template, name)); } }@RestController将类标记为控制器，其中每个方法返回域对象而不是视图。包含 @Controller 和 @ResponseBody @GetMapping使HTTP GET /greeting 的请求，映射到greeting() 方法。对于其他HTTP请求也有对应的注释（例如 @PostMapping）。它们都派生自@RequeMapping。@RequeMapping(method=GET) @RequestParam将查询字符串参数名的值绑定到greeting()方法的名称参数中。如果请求中没有name参数，则使用默认参数“World” @ResponseBody告诉SpringMVC 不需要通过视图层呈现greeting对象，返回的greeting对象是响应体，应该直接写入 传统MVC控制器和RESTful web服务控制器之间的一个关键区别创建HTTP响应体的方式。RESTful 将对象数据将以JSON的形式直接写入HTTP响应，不依赖视图。 Greeting对象必须转换为JSON。由于Spring的HTTP消息转换器支持，不需要手动转换。在类路径中的Jackson2会自动选择Spring的MappingJackson2HttpMessageConverter来将Greeting实例转换为JSON。 3.Enabling CORS为了使RESTful Web的响应中包含CORS访问控制头，必须添加@CrossOrigin 在处理方法中（也可以添加到控制器类，该类的所有处理方法都启用CORS） @CrossOrigin(origins = &quot;http://localhost:9000&quot;， maxAge = 3000) @GetMapping(&quot;/greeting&quot;) public Greeting greeting(@RequestParam(required=false, defaultValue=&quot;World&quot;) String name) { System.out.println(&quot;==== in greeting ====&quot;); return new Greeting(counter.incrementAndGet(), String.format(template, name)); }@CrossOrigin仅对这个特定的方法允许跨源资源共享。包含以下属性 origins methods allowedHeaders exposedHeaders allowCredentials maxAge （默认30分钟） 4.Creating the Application Classpackage com.example.restservicecors; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.context.annotation.Bean; import org.springframework.web.servlet.config.annotation.CorsRegistry; import org.springframework.web.servlet.config.annotation.WebMvcConfigurer; @SpringBootApplication public class RestServiceCorsApplication { public static void main(String[] args) { SpringApplication.run(RestServiceCorsApplication.class, args); } /** * 添加一种方法来配置如何处理跨域资源共享 */ @Bean public WebMvcConfigurer corsConfigurer() { return new WebMvcConfigurer() { @Override public void addCorsMappings(CorsRegistry registry) { registry.addMapping(&quot;/greeting-javaconfig&quot;).allowedOrigins(&quot;http://localhost:9000&quot;); } }; } }@SpringBootApplication添加了以下所有内容： @Configuration：将类标记为程序上下文的Bean定义的源 @EnableAutoConfiguration：告诉Spring Boot根据类路径设置、其他bean和各种属性设置开始添加bean @ComponentScan：告诉Spring在com/example包中寻找其他组件、配置、服务，让它找到控制器 5.Build an executable JAR// 运行 ./mvnw spring-boot: run //构建jar文件 ./mvnw clean //运行jar文件 java -jar target/demo.jar6.Test the Service访问：http://localhost:8080/greeting 结果：{&quot;id&quot;:1,&quot;content&quot;:&quot;Hello, World!&quot;} 访问：http://localhost:8080/greeting?name=User 结果：{&quot;id&quot;:2,&quot;content&quot;:&quot;Hello, User!&quot;}创建一个js客户端来使用服务 hello.js $(document).ready(function() { $.ajax({ url: &quot;http://localhost:8080/greeting&quot; }).then(function(data, status, jqxhr) { $(&#39;.greeting-id&#39;).append(data.id); $(&#39;.greeting-content&#39;).append(data.content); console.log(jqxhr); }); });index.html &lt;!DOCTYPE html&gt; &lt;html&gt; &lt;head&gt; &lt;title&gt;Hello CORS&lt;/title&gt; &lt;script src=&quot;https://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js&quot;&gt;&lt;/script&gt; &lt;script src=&quot;hello.js&quot;&gt;&lt;/script&gt; &lt;/head&gt; &lt;body&gt; &lt;div&gt; &lt;p class=&quot;greeting-id&quot;&gt;The ID is &lt;/p&gt; &lt;p class=&quot;greeting-content&quot;&gt;The content is &lt;/p&gt; &lt;/div&gt; &lt;/body&gt; &lt;/html&gt;./mvnw spring-boot:run -Dserver.port=9000 访问：http://localhost:9000/ 结果： The ID is 1 The content is Hello,World!","categories":[{"name":"Java","slug":"java","permalink":"https://topone233.github.io/categories/java/"}],"tags":[{"name":"Java","slug":"java","permalink":"https://topone233.github.io/tags/java/"},{"name":"Spring","slug":"spring","permalink":"https://topone233.github.io/tags/spring/"},{"name":"CORS","slug":"cors","permalink":"https://topone233.github.io/tags/cors/"},{"name":"RESTful","slug":"restful","permalink":"https://topone233.github.io/tags/restful/"}]},{"title":"十大经典排序算法(Java)","slug":"十大经典排序算法(Java)","date":"2020-07-21T06:14:54.671Z","updated":"2020-08-25T13:33:59.417Z","comments":true,"path":"2020/07/21/十大经典排序算法(Java)/","link":"","permalink":"https://topone233.github.io/2020/07/21/%E5%8D%81%E5%A4%A7%E7%BB%8F%E5%85%B8%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95(Java)/","excerpt":"","text":"1.排序算法说明1.1 排序的定义对一序列对象根据某个关键字进行排序。本文对十大排序算法进行解读。 1.2 术语说明 稳定：如果 a 原本在 b 前面，而 a=b，排序之后 a 仍然在 b 的前面； 不稳定：如果 a 原本在 b 的前面，而 a=b，排序之后 a 可能会出现在 b 的后面； 内排序：所有排序操作都在内存中完成； 外排序：由于数据太大，因此把数据放在磁盘中，而排序通过磁盘和内存的数据传输才能进行； 时间复杂度： 一个算法执行所耗费的时间。 空间复杂度：运行完一个程序所需内存的大小。 1.3 算法总结 图片名词解释： n: 数据规模 k: “桶” 的个数 In-place: 占用常数内存，不占用额外内存 Out-place: 占用额外内存 1.4 算法分类 1.5 比较和非比较的区别常见的快速排序、归并排序、堆排序、冒泡排序等属于比较排序。在排序的最终结果里，元素之间的次序依赖于它们之间的比较。每个数都必须和其他数进行比较，才能确定自己的位置。在冒泡排序之类的排序中，问题规模为 n，又因为需要比较 n 次，所以平均时间复杂度为 O(n²)。在归并排序、快速排序之类的排序中，问题规模通过分治法消减为 logN 次，所以时间复杂度平均 O(nlogn)。比较排序的优势是，适用于各种规模的数据，也不在乎数据的分布，都能进行排序。可以说，比较排序适用于一切需要排序的情况。 计数排序、基数排序、桶排序则属于非比较排序。非比较排序是通过确定每个元素之前，应该有多少个元素来排序。针对数组 arr，计算 arr[i] 之前有多少个元素，则唯一确定了 arr[i] 在排序后数组中的位置。非比较排序只要确定每个元素之前的已有的元素个数即可，所有一次遍历即可解决。算法时间复杂度 O(n)。非比较排序时间复杂度底，但由于非比较排序需要占用空间来确定唯一位置。所以对数据规模和数据分布有一定的要求。 2.冒泡排序（Bubble Sort）冒泡排序是一种简单的排序算法。它重复地走访过要排序的数列，一次比较两个元素，如果它们的顺序错误就把它们交换过来。走访数列的工作是重复地进行直到没有再需要交换，也就是说该数列已经排序完成。这个算法的名字由来是因为越小的元素会经由交换慢慢 “浮” 到数列的顶端。 2.1 算法描述 比较相邻的元素。如果第一个比第二个大，就交换它们两个； 对每一对相邻元素作同样的工作，从开始第一对到结尾的最后一对，这样在最后的元素应该会是最大的数； 针对所有的元素重复以上的步骤，除了最后一个； 重复步骤 1~3，直到排序完成。 2.2 动图演示 2.3 代码实现 /** * 冒泡排序 * 依次比较相邻两个元素，并调整位置 * 一趟排序后最大的数“冒泡”成功，到最右边 * 重复“冒泡” * @param array * @return */ public static int[] bubbleSort(int[] array) { if (array == null || array.length == 0) { return array; } // 外层：length-1次循环 for (int i = 0; i &lt; array.length - 1; i++) { for (int j = 0; j &lt; array.length - 1 - i; j++) { // 将较小的与大的交换位置 if (array[j + 1] &lt; array[j]) { // 采用临时变量法交换 int temp = array[j + 1]; array[j + 1] = array[j]; array[j] = temp; } } } return array; }2.4 算法分析冒泡排序是稳定的排序算法，最容易实现的排序, 最坏的情况是每次都需要交换, 共需遍历并交换将近n²/2次, 时间复杂度为O(n²). 最佳的情况是内循环遍历一次后发现排序是对的, 因此退出循环, 时间复杂度为O(n). 平均来讲, 时间复杂度为O(n²). 由于冒泡排序中只有缓存的temp变量需要内存空间, 因此空间复杂度为常量O(1)。 3.选择排序（Selection Sort）无论什么数据进去都是 O(n^2) 的时间复杂度，所以用到它的时候，数据规模越小越好。唯一的好处可能就是不占用额外的内存空间了吧。理论上讲，选择排序可能也是平时排序一般人想到的最多的排序方法了吧。 选择排序 (Selection-sort) 是一种简单直观的排序算法。它的工作原理：首先在未排序序列中找到最小（大）元素，存放到排序序列的起始位置，然后，再从剩余未排序元素中继续寻找最小（大）元素，然后放到已排序序列的末尾。以此类推，直到所有元素均排序完毕。 3.1 算法描述n 个记录的直接选择排序可经过 n-1 趟直接选择排序得到有序结果。具体算法描述如下： 初始状态：无序区为 R[1..n]，有序区为空； 第 i 趟排序 (i=1,2,3…n-1) 开始时，当前有序区和无序区分别为 R[1..i-1]和 R(i..n）。该趟排序从当前无序区中 - 选出关键字最小的记录 R[k]，将它与无序区的第 1 个记录 R 交换，使 R[1..i]和 R[i+1..n)分别变为记录个数增加 1 个的新有序区和记录个数减少 1 个的新无序区； n-1 趟结束，数组有序化了。 3.2 动图演示 3.3 代码实现 /** * 选择排序 * 遍历数组，在未排序的队列，找到最小或最大的数，放在左边形成有序队列 * @param array * @return */ public static int[] selectionSort(int[] array) { if (array.length == 0) { return array; } for (int i = 0; i &lt; array.length - 1; i++) { int minIndex = i; for (int j = i + 1; j &lt; array.length; j++) { // 找到最小的数 if (array[j] &lt; array[minIndex]) // 将最小数的索引保存 minIndex = j; } // 将i位置元素与找到的最小数，交换位置 if (minIndex != i) { int temp = array[minIndex]; array[minIndex] = array[i]; array[i] = temp; } } return array; }3.4 算法分析最佳情况：O(n^2) 最差情况：O(n^2) 平均情况： O(n^2) 4.插入排序（Insertion Sort）插入排序（Insertion-Sort）的算法描述是一种简单直观的排序算法。它的工作原理是通过构建有序序列，对于未排序数据，在已排序序列中从后向前扫描，找到相应位置并插入。插入排序在实现上，通常采用 in-place 排序（即只需用到 O(1) 的额外空间的排序），因而在从后向前扫描过程中，需要反复把已排序元素逐步向后挪位，为最新元素提供插入空间。 4.1 算法描述一般来说，插入排序都采用 in-place 在数组上实现。具体算法描述如下： 从第一个元素开始，该元素可以认为已经被排序； 取出下一个元素，在已经排序的元素序列中从后向前扫描； 如果该元素（已排序）大于新元素，将该元素移到下一位置； 重复步骤 3，直到找到已排序的元素小于或者等于新元素的位置； 将新元素插入到该位置后； 重复步骤 2~5。 4.2 动图演示 4.3 代码实现提供两种写法，一种是移位法，一种是交换法。移位法是完全按照以上算法描述实，再插入过程中将有序序列中比待插入数字大的数据向后移动，由于移动时会覆盖待插入数据，所以需要额外的临时变量保存待插入数据，代码实现如下： /** * 插入排序-移位法 * 每次在右侧未排序队列，选中一个元素，在左侧有序队列中，找适合自己的位置，并插入 * @param array * @return */ public static int[] insertionSort(int[] arr) { if (arr == null || arr.length == 0) { return arr; } for (int i = 0; i &lt; arr.length; i++) { int j = i - 1; // temp即被选中，进行操作的元素 int temp = a[i]; // 如果比待插入数据大，就后移 while (j &gt;= 0 &amp;&amp; temp &lt; arr[j]) { // j位置元素大，后移，腾出位置 arr[j + 1] = arr[j]; // 一直向前，直到找到合适的位置 j--; } // 找到比待插入数据小的位置，将待插入数据插入 arr[j + 1] = temp; } return arr; }而交换法不需求额外的保存待插入数据，通过不停的向前交换带插入数据，类似冒泡法，直到找到比它小的值，也就是待插入数据找到了自己的位置: public static void insertionSort(int[] arr) { if (arr == null || arr.length == 0) { return; } for (int i = 1; i &lt; arr.length; i++) { int j = i - 1; while (j &gt;= 0 &amp;&amp; arr[j] &gt; arr[i]) { // 只要大就交换操作 arr[j + 1] = arr[j] + arr[j+1]; arr[j] = arr[j + 1] - arr[j]; arr[j + 1] = arr[j + 1] - arr[j]; System.out.println(&quot;Sorting: &quot; + Arrays.toString(arr)); } } }4.4 算法分析最佳情况： O(n) 最坏情况： O(n^2) 平均情况： O(n^2) 空间复杂度：O(1) 5.希尔排序（Shell Sort）希尔排序是希尔（Donald Shell）于 1959 年提出的一种排序算法。希尔排序也是一种插入排序，它是简单插入排序经过改进之后的一个更高效的版本，也称为缩小增量排序，同时该算法是冲破 O(n2）的第一批算法之一。它与插入排序的不同之处在于，它会优先比较距离较远的元素; 直接插入排序是稳定的；而希尔排序是不稳定的。希尔排序又叫缩小增量排序。 希尔排序是把记录按一定增量分组，对每组使用直接插入排序算法排序；随着增量逐渐减少，每组包含的关键词越来越多，当增量减至 1 时，整个文件恰被分成一组，算法便终止。 5.1 算法描述我们来看下希尔排序的基本步骤，在此我们选择增量 gap=length/2，缩小增量继续以 gap = gap/2 的方式，这种增量选择我们可以用一个序列来表示，{n/2,(n/2)/2…1}，称为增量序列。希尔排序的增量序列的选择与证明是个数学难题，我们选择的这个增量序列是比较常用的，也是希尔建议的增量，称为希尔增量，但其实这个增量序列不是最优的。此处我们做示例使用希尔增量。 先将整个待排序的记录序列分割成为若干子序列分别进行直接插入排序，具体算法描述： 选择一个增量序列 t1，t2，…，tk，其中 ti&gt;tj，tk=1； 按增量序列个数 k，对序列进行 k 趟排序； 每趟排序，根据对应的增量 ti，将待排序列分割成若干长度为 m 的子序列，分别对各子表进行直接插入排序。仅增量因子为 1 时，整个序列作为一个表来处理，表长度即为整个序列的长度。 5.2 过程演示 5.3 代码实现 /** * 希尔排序 * * @param array * @return */ public static int[] ShellSort(int[] array) { int len = array.length; // 初始增量gap int temp, gap = len / 2; while (gap &gt; 0) { for (int i = gap; i &lt; len; i++) { // temp放分组的第二个数，即中位数gap右边元素 temp = array[i]; // preIndex：分组第一个数 = i与中位数gap的差 = i自增的次数 = 左侧下标 int preIndex = i - gap; //如果左侧元素大，交换位置 while (preIndex &gt;= 0 &amp;&amp; array[preIndex] &gt; temp) { array[preIndex + gap] = array[preIndex]; preIndex -= gap; } array[preIndex + gap] = temp; } gap /= 2; } return array; } 第二种写法： public static int[] ShellSort(int[] arr) { int gap = arr.length / 2; // 不断缩小gap，直到1为止 for (;gap &gt; 0; gap = gap/2) { // j用来控制分组内多个元素时，比较的次数 for (int j = 0; (j + gap) &lt; arr.length; j++) { // k左侧元素，k+gap=右侧元素。依次调整每个分组 for (int k = 0; (k + gap) &lt; arr.length; k++) { if (arr[k] &gt; arr[k+gap]) { // 交换操作 arr[k] = arr[k] + arr[k+gap]; arr[k+gap] = arr[k] - arr[k+gap]; arr[k] = arr[k] - arr[k+gap]; System.out.println(&quot; Sorting: &quot; + Arrays.toString(arr)); }5.4 算法分析*最佳情况： O(nlog n) 最坏情况： O(nlog n) 平均情况：O(nlog n) * 6.归并排序（Merge Sort）和选择排序一样，归并排序的性能不受输入数据的影响，但表现比选择排序好的多，因为始终都是 O(n log n）的时间复杂度。代价是需要额外的内存空间。 归并排序是建立在归并操作上的一种有效的排序算法。该算法是采用分治法（Divide and Conquer）的一个非常典型的应用。归并排序是一种稳定的排序方法。将已有序的子序列合并，得到完全有序的序列；即先使每个子序列有序，再使子序列段间有序。若将两个有序表合并成一个有序表，称为 2 - 路归并。 6.1 算法描述 把长度为 n 的输入序列分成两个长度为 n/2 的子序列； 对这两个子序列分别采用归并排序； 将两个排序好的子序列合并成一个最终的排序序列。 6.2 动图演示 6.3 代码实现 /** * 归并排序 * 先分治，在合并 * @param array * @return */ public static int[] MergeSort(int[] array) { if (array.length &lt;= 1) { return array; } // &gt;&gt; 1 等价于 /2 int mid = array.length &gt;&gt; 1; int[] left = Arrays.copyOfRange(array, 0, mid); int[] right = Arrays.copyOfRange(array, mid, array.length); return merge(MergeSort(left), MergeSort(right)); } /** * 归并排序——将两段排序好的数组结合成一个排序数组 * * @param left * @param right * @return */ public static int[] merge(int[] left, int[] right) { int[] result = new int[left.length + right.length]; int i = 0, j = 0, k = 0; while (i &lt; left.length &amp;&amp; j &lt; right.length) { if (left[i] &lt;= right[j]) { result[k++] = left[i++]; }else { result[k++] = right[j++]; } } // left中的剩余元素移入结果数组 while (i &lt; left.length) { result[k++] = left[i++]； } // right中的剩余元素移入结果数组 while (j &lt; right.length) { result[k++] = right[j++]; } return result; }6.4 算法分析最佳情况：O(nlog n) 最差情况：O(nlog n) 平均情况： O(nlog n) 空间复杂度：O(n) 7.快速排序（Quick Sort）快速排序的基本思想：通过一趟排序将待排记录分隔成独立的两部分，其中一部分记录的关键字均比另一部分的关键字小，则可分别对这两部分记录继续进行快速排序，以达到整个序列有序。 7.1 算法描述快速排序使用分治法来把一个串（list）分为两个子串（sub-lists）。具体算法描述如下： 从数列中挑出一个元素，称为 “基准”（pivot）； 重新排序数列，所有元素比基准值小的摆放在基准前面，所有元素比基准值大的摆在基准的后面（相同的数可以到任一边）。在这个分区退出之后，该基准就处于数列的中间位置。这个称为分区（partition）操作； 递归地（recursive）把小于基准值元素的子数列和大于基准值元素的子数列排序。 7.2 动图演示 7.3 代码实现 /** * 快速排序方法（左右指针法） * 从左至右依次选择元素作为基准，比较之后的元素 * 将小于基准的元素一起放到基准左边（无须排序）， * @param array * @param start * @param end * @return */ public static int[] QuickSort(int[] array, int start, int end) { if (array.length &lt; 1 || start &lt; 0 || end &gt;= array.length || start &gt; end) { return null; } int smallIndex = partition(array, start, end); if (smallIndex &gt; start) QuickSort(array, start, smallIndex - 1); if (smallIndex &lt; end) QuickSort(array, smallIndex + 1, end); return array; } /** * 快速排序算法——partition * @param array * @param start * @param end * @return */ public static int partition(int[] array, int start, int end) { int pivot = (int) (start + Math.random() * (end - start + 1)); int smallIndex = start - 1; swap(array, pivot, end); for (int i = start; i &lt;= end; i++) if (array[i] &lt;= array[end]) { smallIndex++; if (i &gt; smallIndex) swap(array, i, smallIndex); } return smallIndex; } /** * 交换数组内两个元素 * @param array * @param i * @param j */ public static void swap(int[] array, int i, int j) { int temp = array[i]; array[i] = array[j]; array[j] = temp; }7.4 算法分析最佳情况： O(nlog n) 最差情况： O(n^2) 平均情况： O(nlog n) 空间复杂度：O(1) 8.堆排序（Heap Sort）堆排序（Heapsort）是指利用堆这种数据结构所设计的一种排序算法。堆积是一个近似完全二叉树的结构，并同时满足堆积的性质：即子结点的键值或索引总是小于（或者大于）它的父节点。 8.1 算法描述 将初始待排序关键字序列 (R1,R2….Rn) 构建成大顶堆，此堆为初始的无序区；（一般升序采用大顶堆，降序采用小顶堆）； 将堆顶元素 R[1]与最后一个元素 R[n]交换，此时得到新的无序区 (R1,R2,……Rn-1) 和新的有序区(Rn，), 且满足 R[1,2…n-1]&lt;=R[n]； 恢复堆。由于交换后新的堆顶 R[1]可能违反堆的性质，因此需要对当前无序区 (R1,R2,……Rn-1) 调整为新堆，然后再次将 R[1]与无序区最后一个元素交换，得到新的无序区 (R1,R2….Rn-2) 和新的有序区(Rn-1,Rn)。不断重复此过程直到有序区的元素个数为 n-1，则整个排序过程完成。 8.2 动图演示 8.3 代码实现注意：这里用到了完全二叉树的部分性质：详情见《数据结构二叉树知识点总结》 /** * 堆排序 * 构建大顶堆，交换堆顶元素与末尾元素，恢复大顶堆 * 每次将最大值“沉”到数组末端，升序 * @param arr */ public static void sort(int[] arr) { // 1.构建大顶堆 // 从最后一个非叶子节点开始 for (int i = arr.length / 2 - 1; i &gt;= 0; i--) { // 第一个非叶子节点i，从下至上、从左至右调整结构 adjustHeap(arr, i, arr.length); } // 2.交换堆顶与末尾 + 调整堆结构 // j就是末尾元素 for (int j = arr.length-1; j &gt; 0; j--) { // swap方法，交换操作 swap(arr, i, j); // adjustHeap方法，重新调整堆结构 adjustHeap(arr, i, j); } } /** * 调整大顶堆（仅是调整过程，建立在大顶堆已构建的基础上） * @param arr * @param i * @param length */ public static void adjustHeap(int[] arr, int i, int length) { // 以i节点为父节点，先将值放到temp保存 int temp = arr[i]; // 从i节点的左子节点开始，找出最大值，放到父节点位置 for (int k = i*2+1; k &lt; length; k = k*2+1) { // 如果左子节点小于右子节点，k指向右子节点 if (k+1 &lt; length &amp;&amp; arr[k] &lt; arr[k + 1]) { k++; } // 如果子节点大于父节点，将子节点值赋给父节点，最终使i为最大值 // 注意，这里k覆盖了i位置元素 if (arr[k] &gt; temp) { arr[i] = arr[k]; i = k; }else { break; } } // 此时才真正确定i的位置，将保存的值还给i arr[i] = temp; } /** * 交换元素 * @param arr * @param a * @param b */ public static void swap(int[] arr, int a, int b) { int temp = arr[a]; arr[a] = arr[b]; arr[b] = temp; }8.4 算法分析由于堆排序中初始化堆的过程比较次数较多, 因此它不太适用于小序列。同时由于多次任意下标相互交换位置, 相同元素之间原本相对的顺序被破坏了, 因此, 它是不稳定的排序。 最佳情况： O(nlogn) 最差情况： O(nlogn) 平均情况： O(nlogn) 空间复杂度：O(1) 9.计数排序（Counting Sort）计数排序的核心在于将输入的数据值转化为键存储在额外开辟的数组空间中。 作为一种线性时间复杂度的排序，计数排序要求输入的数据必须是有确定范围的整数。 计数排序 (Counting sort) 是一种稳定的排序算法。计数排序使用一个额外的数组 C，其中第 i 个元素是待排序数组 A 中值等于 i 的元素的个数。然后根据数组 C 来将 A 中的元素排到正确的位置。它只能对整数进行排序。 9.1 算法描述 找出待排序的数组中最大和最小的元素； 统计数组中每个值为 i 的元素出现的次数，存入数组 C 的第 i 项； 对所有的计数累加（从 C 中的第一个元素开始，每一项和前一项相加）； 反向填充目标数组：将每个元素 i 放在新数组的第 C(i) 项，每放一个元素就将 C(i) 减去 1。 9.2 动图演示 9.3 代码实现/** * 计数排序 * * @param array * @return */ public static int[] CountingSort(int[] array) { if (array.length == 0) return array; int bias, min = array[0], max = array[0]; for (int i = 1; i &lt; array.length; i++) { if (array[i] &gt; max) max = array[i]; if (array[i] &lt; min) min = array[i]; } bias = 0 - min; int[] bucket = new int[max - min + 1]; Arrays.fill(bucket, 0); for (int i = 0; i &lt; array.length; i++) { bucket[array[i] + bias]++; } int index = 0, i = 0; while (index &lt; array.length) { if (bucket[i] != 0) { array[index] = i - bias; bucket[i]--; index++; } else i++; } return array; }9.4 算法分析当输入的元素是 n 个 0 到 k 之间的整数时，它的运行时间是 O(n + k)。计数排序不是比较排序，排序的速度快于任何比较排序算法。由于用来计数的数组 C 的长度取决于待排序数组中数据的范围（等于待排序数组的最大值与最小值的差加上 1），这使得计数排序对于数据范围很大的数组，需要大量时间和内存。 最佳情况： O(n+k) 最差情况： O(n+k) 平均情况： O(n+k) 10.桶排序（Bucket Sort）桶排序是计数排序的升级版。它利用了函数的映射关系，高效与否的关键就在于这个映射函数的确定。 桶排序 (Bucket sort) 的工作的原理：假设输入数据服从均匀分布，将数据分到有限数量的桶里，每个桶再分别排序（有可能再使用别的排序算法或是以递归方式继续使用桶排序进行排 10.1 算法描述 人为设置一个 BucketSize，作为每个桶所能放置多少个不同数值（例如当 BucketSize==5 时，该桶可以存放｛1,2,3,4,5｝这几种数字，但是容量不限，即可以存放 100 个 3）； 遍历输入数据，并且把数据一个一个放到对应的桶里去； 对每个不是空的桶进行排序，可以使用其它排序方法，也可以递归使用桶排序； 从不是空的桶里把排好序的数据拼接起来。 注意，如果递归使用桶排序为各个桶排序，则当桶数量为 1 时要手动减小 BucketSize 增加下一循环桶的数量，否则会陷入死循环，导致内存溢出。 10.2 图片演示 10.3 代码实现 /** * 桶排序 * * @param array * @param bucketSize * @return */ public static ArrayList&lt;Integer&gt; BucketSort(ArrayList&lt;Integer&gt; array, int bucketSize) { if (array == null || array.size() &lt; 2) return array; int max = array.get(0), min = array.get(0); // 找到最大值最小值 for (int i = 0; i &lt; array.size(); i++) { if (array.get(i) &gt; max) max = array.get(i); if (array.get(i) &lt; min) min = array.get(i); } int bucketCount = (max - min) / bucketSize + 1; ArrayList&lt;ArrayList&lt;Integer&gt;&gt; bucketArr = new ArrayList&lt;&gt;(bucketCount); ArrayList&lt;Integer&gt; resultArr = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; bucketCount; i++) { bucketArr.add(new ArrayList&lt;Integer&gt;()); } for (int i = 0; i &lt; array.size(); i++) { bucketArr.get((array.get(i) - min) / bucketSize).add(array.get(i)); } for (int i = 0; i &lt; bucketCount; i++) { if (bucketSize == 1) { // 如果带排序数组中有重复数字时 感谢 @见风任然是风 朋友指出错误 for (int j = 0; j &lt; bucketArr.get(i).size(); j++) resultArr.add(bucketArr.get(i).get(j)); } else { if (bucketCount == 1) bucketSize--; ArrayList&lt;Integer&gt; temp = BucketSort(bucketArr.get(i), bucketSize); for (int j = 0; j &lt; temp.size(); j++) resultArr.add(temp.get(j)); } } return resultArr; }10.4 算法分析桶排序最好情况下使用线性时间 O(n)，桶排序的时间复杂度，取决与对各个桶之间数据进行排序的时间复杂度，因为其它部分的时间复杂度都为 O(n)。很显然，桶划分的越小，各个桶之间的数据越少，排序所用的时间也会越少。但相应的空间消耗就会增大。 *最佳情况： O(n+k) 最差情况： O(n+k) 平均情况： O(n^2) * 11.基数排序（Radix Sort）将所有待比较数值（正整数）统一为同样的数位长度，数位较短的数前面补零。然后，从最低位开始，依次进行一次排序。这样从最低位排序一直到最高位排序完成以后，数列就变成一个有序序列。 基数排序按照优先从高位或低位来排序有两种实现方案： MSD（Most significant digital） 从最左侧高位开始进行排序。先按k1排序分组, 同一组中记录, 关键码k1相等, 再对各组按k2排序分成子组, 之后, 对后面的关键码继续这样的排序分组, 直到按最次位关键码kd对各子组排序后. 再将各组连接起来, 便得到一个有序序列。MSD方式适用于位数多的序列。 LSD（Least significant digital） 从最右侧低位开始进行排序。先从kd开始排序，再对kd-1进行排序，依次重复，直到对k1排序后便得到一个有序序列。LSD方式适用于位数少的序列。 基数排序基于分别排序，分别收集，不改变相同元素之间的相对顺序，所以是稳定的。 下面以LSD为例。 11.1 算法描述 取得数组中的最大数，并取得位数； arr 为原始数组，从最低位开始取每个位组成 radix 数组； 对 radix 进行计数排序（利用计数排序适用于小范围数的特点）； 11.2 动图演示 11.3 代码实现 /** * 基数排序 * @param array * @return */ public static int[] RadixSort(int[] array) { if (array == null || array.length &lt; 2) { return array; } // 1.先算出最大数的位数； int max = array[0]; for (int i = 1; i &lt; array.length; i++) { if (a[i] &gt; max) { max = a[i]; } } int maxDigit = 0; while (max != 0) { max /= 10; maxDigit++; } int[][] buckets = new int[10][a.length]; int base = 10; //从低位到高位，对每一位遍历，将所有元素分配到桶中 for (int i = 0; i &lt; maxDigit; i++) { //存储各个桶中存储元素的数量 int[] bucketLen = new int[10]; //收集：将不同桶里数据挨个捞出来,为下一轮高位排序做准备,由于靠近桶底的元素排名靠前,因此从桶底先捞 for (int j = 0; j &lt; a.length; j++) { int whichBucket = (a[j] % base) / (base / 10); buckets[whichBucket][bucketLen[whichBucket]] = a[j]; bucketLen[whichBucket]++; } int k = 0; //收集：将不同桶里数据挨个捞出来,为下一轮高位排序做准备,由于靠近桶底的元素排名靠前,因此从桶底先捞 for (int l = 0; l &lt; buckets.length; l++) { for (int m =0; m &lt; bucketLen[l]; m++) { a[k++] = buckets[l][m]; } } System.out.println(&quot;Sorting: &quot; + Arrays.toString(a)); base *= 10; } return array; }11.4 算法分析最佳情况：O(d(n+r)) 最差情况：O(d(n+r)) 平均情况：O(d*(n+r)) 空间复杂度: O(n+r) 其中，d 为位数，r 为基数，n 为原数组个数。在基数排序中，因为没有比较操作，所以在复杂上，最好的情况与最坏的情况在时间上是一致的，均为 O(d*(n + r))。 基数排序更适合用于对时间, 字符串等这些整体权值未知的数据进行排序，适用于。 (1)数据范围较小，建议在小于1000 (2)每个数值都要大于等于0 基数排序 vs 计数排序 vs 桶排序 这三种排序算法都利用了桶的概念，但对桶的使用方法上有明显差异： 基数排序：根据键值的每位数字来分配桶 计数排序：每个桶只存储单一键值 桶排序：每个桶存储一定范围的数值 参考资料：https://juejin.im/post/5b95da8a5188255c775d8124 https://www.cnblogs.com/guoyaohua/p/8600214.html https://www.cnblogs.com/Young111/p/11300929.html","categories":[{"name":"数据结构","slug":"数据结构","permalink":"https://topone233.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}],"tags":[{"name":"Java","slug":"java","permalink":"https://topone233.github.io/tags/java/"},{"name":"数据结构","slug":"数据结构","permalink":"https://topone233.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"排序算法","slug":"排序算法","permalink":"https://topone233.github.io/tags/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/"}]},{"title":"反射、注解和动态代理","slug":"反射、注解和动态代理","date":"2020-07-20T08:48:44.137Z","updated":"2020-08-25T13:32:42.344Z","comments":true,"path":"2020/07/20/反射、注解和动态代理/","link":"","permalink":"https://topone233.github.io/2020/07/20/%E5%8F%8D%E5%B0%84%E3%80%81%E6%B3%A8%E8%A7%A3%E5%92%8C%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86/","excerpt":"","text":"原文地址 一、Java 反射机制及基本用法反射是指计算机程序在运行时访问、检测和修改它本身状态或行为的一种能力，是一种元编程语言特性，有很多语言都提供了对反射机制的支持，它使程序能够编写程序。Java 的反射机制使得 Java 能够动态的获取类的信息和调用对象的方法。 在 Java 中，Class（类类型）是反射编程的起点，代表运行时类型信息（RTTI，Run-Time Type Identification）。java.lang.reflect 包含了 Java 支持反射的主要组件，如 Constructor、Method 和 Field 等，分别表示类的构造器、方法和域，它们的关系如下图所示。 Constructor 和 Method 与 Field 的区别在于前者继承自抽象类 Executable，是可以在运行时动态调用的，而 Field 仅仅具备可访问的特性，且默认为不可访问。下面了解下它们的基本用法： 获取 Class 对象有三种方式，Class.forName 适合于已知类的全路径名，典型应用如加载 JDBC 驱动。对同一个类，不同方式获得的 Class 对象是相同的。 // 1. 采用Class.forName获取类的Class对象 Class clazz0 = Class.forName(&quot;com.yhthu.java.ClassTest&quot;); System.out.println(&quot;clazz0:&quot; + clazz0); // 2. 采用.class方法获取类的Class对象 Class clazz1 = ClassTest.class; System.out.println(&quot;clazz1:&quot; + clazz1); // 3. 采用getClass方法获取类的Class对象 ClassTest classTest = new ClassTest(); Class clazz2 = classTest.getClass(); System.out.println(&quot;clazz2:&quot; + clazz2); // 4. 判断Class对象是否相同 System.out.println(&quot;Class对象是否相同:&quot; + ((clazz0.equals(clazz1)) &amp;&amp; (clazz1.equals(clazz2)))); 注意：三种方式获取的 Class 对象相同的前提是使用了相同的类加载器，比如上述代码中默认采用应用程序类加载器（sun.misc.Launcher$AppClassLoader）。不同类加载器加载的同一个类，也会获取不同的 Class 对象： // 自定义类加载器 ClassLoader myLoader = new ClassLoader() { @Override public Class&lt;?&gt; loadClass(String name) throws ClassNotFoundException { try { String fileName = name.substring(name.lastIndexOf(&quot;.&quot;) + 1) + &quot;.class&quot;; InputStream is = getClass().getResourceAsStream(fileName); if (is == null) { return super.loadClass(name); } byte[] b = new byte[is.available()]; is.read(b); return defineClass(name, b, 0, b.length); } catch (IOException e) { throw new ClassNotFoundException(name); } } }; // 采用自定义类加载器加载 Class clazz3 = Class.forName(&quot;com.yhthu.java.ClassTest&quot;, true, myLoader); // clazz0与clazz3并不相同 System.out.println(&quot;Class对象是否相同:&quot; + clazz0.equals(clazz3)); 通过 Class 的 getDeclaredXxxx 和 getXxx 方法获取构造器、方法和域对象，两者的区别在于前者返回的是当前 Class 对象申明的构造器、方法和域，包含修饰符为 private 的；后者只返回修饰符为 public 的构造器、方法和域，但包含从基类中继承的。 // 返回申明为public的方法，包含从基类中继承的 for (Method method: String.class.getMethods()) { System.out.println(method.getName()); } // 返回当前类申明的所有方法，包含private的 for (Method method: String.class.getDeclaredMethods()) { System.out.println(method.getName()); } 通过 Class 的 newInstance 方法和 Constructor 的 newInstance 方法方法均可新建类型为 Class 的对象，通过 Method 的 invoke 方法可以在运行时动态调用该方法，通过 Field 的 set 方法可以在运行时动态改变域的值，但需要首先设置其为可访问（setAccessible）。 二、注解注解（Annotation）是 Java5 引入的一种代码辅助工具，它的核心作用是对类、方法、变量、参数和包进行标注，通过反射来访问这些标注信息，以此在运行时改变所注解对象的行为。Java 中的注解由内置注解和元注解组成。内置注解主要包括： @Override - 检查该方法是否是重载方法。如果发现其父类，或者是引用的接口中并没有该方法时，会报编译错误。 @Deprecated - 标记过时方法。如果使用该方法，会报编译警告。 @SuppressWarnings - 指示编译器去忽略注解中声明的警告。 @SafeVarargs - Java 7 开始支持，忽略任何使用参数为泛型变量的方法或构造函数调用产生的警告。 @FunctionalInterface - Java 8 开始支持，标识一个匿名函数或函数式接口。 这里，我们重点关注元注解，元注解位于 java.lang.annotation 包中，主要用于自定义注解。元注解包括： @Retention - 标识这个注解怎么保存，是只在代码中，还是编入 class 文件中，或者是在运行时可以通过反射访问，枚举类型分为别 SOURCE、CLASS 和 RUNTIME； @Documented - 标记这些注解是否包含在用户文档中。 @Target - 标记这个注解应该是哪种 Java 成员，枚举类型包括 TYPE、FIELD、METHOD、CONSTRUCTOR 等； @Inherited - 标记这个注解可以继承超类注解，即子类 Class 对象可使用 getAnnotations() 方法获取父类被 @Inherited 修饰的注解，这个注解只能用来申明类。 @Repeatable - Java 8 开始支持，标识某注解可以在同一个声明上使用多次。 自定义元注解需重点关注两点：1）注解的数据类型；2）反射获取注解的方法。首先，注解中的方法并不支持所有的数据类型，仅支持八种基本数据类型、String、Class、enum、Annotation 和它们的数组。比如以下代码会产生编译时错误： @Documented @Inherited @Target(ElementType.TYPE) @Retention(RetentionPolicy.RUNTIME) public @interface AnnotationTest { // 1. 注解数据类型不能是Object；2. 默认值不能为null Object value() default null; // 支持的定义方式 String value() default &quot;&quot;; }其次，上节中提到的反射相关类（Class、Constructor、Method 和 Field）和 Package 均实现了 AnnotatedElement 接口，该接口定义了访问反射信息的方法，主要如下： // 获取指定注解类型 getAnnotation(Class&lt;T&gt;):T; // 获取所有注解，包括从父类继承的 getAnnotations():Annotation[]; // 获取指定注解类型，不包括从父类继承的 getDeclaredAnnotation(Class&lt;T&gt;):T // 获取所有注解，不包括从父类继承的 getDeclaredAnnotations():Annotation[]; // 判断是否存在指定注解 isAnnotationPresent(Class&lt;? extends Annotation&gt;:boolean当使用上例中的 AnnotationTest 标注某个类后，便可在运行时通过该类的反射方法访问注解信息了。 @AnnotationTest(&quot;yhthu&quot;) public class AnnotationReflection { public static void main(String[] args) { AnnotationReflection ar = new AnnotationReflection(); Class clazz = ar.getClass(); // 判断是否存在指定注解 if (clazz.isAnnotationPresent(AnnotationTest.class)) { // 获取指定注解类型 Annotation annotation = clazz.getAnnotation(AnnotationTest.class); // 获取该注解的值 System.out.println(((AnnotationTest) annotation).value()); } } } 当自定义注解只有一个方法 value() 时，使用注解可只写值，例如：@AnnotationTest(“yhthu”) 三、动态代理参考上一篇：动态代理 代理是一种结构型设计模式，当无法或不想直接访问某个对象，或者访问某个对象比较复杂的时候，可以通过一个代理对象来间接访问，代理对象向客户端提供和真实对象同样的接口功能。经典设计模式中，代理模式有四种角色： Subject 抽象主题类——申明代理对象和真实对象共同的接口方法； RealSubject 真实主题类——实现了 Subject 接口，真实执行业务逻辑的地方； ProxySubject 代理类——实现了 Subject 接口，持有对 RealSubject 的引用，在实现的接口方法中调用 RealSubject 中相应的方法执行； Cliect 客户端类——使用代理对象的类。 在实现上，代理模式分为静态代理和动态代理，静态代理的代理类二进制文件是在编译时生成的，而动态代理的代理类二进制文件是在运行时生成并加载到虚拟机环境的。JDK 提供了对动态代理接口的支持，开源的动态代理库（Cglib、Javassist 和 Byte Buddy）提供了对接口和类的代理支持，本节将简单比较 JDK 和 Cglib 实现动态代理的异同，后续章节会对 Java 字节码编程做详细分析。 3.1 JDK 动态代理接口JDK 实现动态代理是通过 Proxy 类的 newProxyInstance 方法实现的，该方法的三个入参分别表示： public static Object newProxyInstance(ClassLoader loader, Class&lt;?&gt;[] interfaces, InvocationHandler h) ClassLoader loader，定义代理生成的类的加载器，可以自定义类加载器，也可以复用当前 Class 的类加载器； Class&lt;?&gt;[] interfaces，定义代理对象需要实现的接口； InvocationHandler h，定义代理对象调用方法的处理，其 invoke 方法中的 Object proxy 表示生成的代理对象，Method 表示代理方法， Object[] 表示方法的参数。 通常的使用方法如下： private Object getProxy() { return Proxy.newProxyInstance(JDKProxyTest.class.getClassLoader(), new Class&lt;?&gt;[]{Subject.class}, new MyInvocationHandler(new RealSubject())); } private static class MyInvocationHandler implements InvocationHandler { private Object realSubject; public MyInvocationHandler(Object realSubject) { this.realSubject = realSubject; } @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { System.out.println(&quot;Some thing before method invoke&quot;); Object result = method.invoke(realSubject, args); System.out.println(&quot;Some thing after method invoke&quot;); return result; } }类加载器采用当前类的加载器，默认为应用程序类加载器（sun.misc.Launcher$AppClassLoader）；接口数组以 Subject.class 为例，调用方法处理类 MyInvocationHandler 实现 InvocationHandler 接口，并在构造器中传入 Subject 的真正的业务功能服务类 RealSubject，在执行 invoke 方法时，可以在实际方法调用前后织入自定义的处理逻辑，这也就是 AOP（面向切面编程）的原理。关于 JDK 动态代理，有两个问题需要清楚： Proxy.newProxyInstance 的代理类是如何生成的？Proxy.newProxyInstance 生成代理类的核心分成两步： // 1. 获取代理类的Class对象 Class&lt;?&gt; cl = getProxyClass0(loader, intfs); // 2. 利用Class获取Constructor，通过反射生成对象 cons.newInstance(new Object[]{h});与反射获取 Class 对象时搜索 classpath 路径的. class 文件不同的是，这里的 Class 对象完全是 “无中生有” 的。getProxyClass0 根据类加载器和接口集合返回了 Class 对象，这里采用了缓存的处理。 // 缓存(key, sub-key) -&gt; value，其中key为类加载器，sub-key为代理的接口，value为Class对象 private static final WeakCache&lt;ClassLoader, Class&lt;?&gt;[], Class&lt;?&gt;&gt; proxyClassCache = new WeakCache&lt;&gt;(new KeyFactory(), new ProxyClassFactory()); // 如果实现了代理接口的类已存在就返回缓存对象，否则就通过ProxyClassFactory生成 private static Class&lt;?&gt; getProxyClass0(ClassLoader loader, Class&lt;?&gt;... interfaces) { if (interfaces.length &gt; 65535) { throw new IllegalArgumentException(&quot;interface limit exceeded&quot;); } return proxyClassCache.get(loader, interfaces); }如果实现了代理接口的类已存在就返回缓存对象，否则就通过 ProxyClassFactory 生成。ProxyClassFactory 又是通过下面的代码生成 Class 对象的。 // 生成代理类字节码文件 byte[] proxyClassFile = ProxyGenerator.generateProxyClass(proxyName, interfaces, accessFlags); try { // defineClass0为native方法，生成Class对象 return defineClass0(loader, proxyName, proxyClassFile, 0, proxyClassFile.length); } catch (ClassFormatError e) { throw new IllegalArgumentException(e.toString()); }generateProxyClass 方法是用来生成字节码文件的，根据生成的字节码文件，再在 native 层生成 Class 对象。 InvocationHandler 的 invoke 方法是怎样调用的？回答这个问题得先看下上面生成的 Class 对象究竟是什么样的，将 ProxyGenerator 生成的字节码保存成文件，然后反编译打开（IDEA 直接打开），可见生成的 Proxy.class 主要包含 equals、toString、hashCode 和代理接口的 request 方法实现。 public final class $Proxy extends Proxy implements Subject { // m1 = Object的equals方法 private static Method m1; // m2 = Object的toString方法 private static Method m2; // Subject的request方法 private static Method m3; // Object的hashCode方法 private static Method m0; // 省略m1/m2/m0，此处只列出request方法实现 public final void request() throws { try { super.h.invoke(this, m3, (Object[])null); } catch (RuntimeException | Error var2) { throw var2; } catch (Throwable var3) { throw new UndeclaredThrowableException(var3); } } }由于生成的代理类继承自 Proxy，super.h 即是 Prxoy 的 InvocationHandler，即代理类的 request 方法直接调用了 InvocationHandler 的实现，这就回答了 InvocationHandler 的 invoke 方法是如何被调用的了。 3.2 Cglib 动态代理接口和类Cglib 的动态代理是通过 Enhancer 类实现的，其 create 方法生成动态代理的对象，有五个重载方法： create():Object create(Class, Callback):Object create(Class, Class[], Callback):Object create(Class, Class[], CallbackFilter, Callback):Object create(Class[], Object):Object常用的是第二个和第三个方法，分别用于动态代理类和动态代理接口，其使用方法如下： private Object getProxy() { // 1. 动态代理类 return Enhancer.create(RealSubject.class, new MyMethodInterceptor()); // 2. 动态代理接口 return Enhancer.create(Object.class, new Class&lt;?&gt;[]{Subject.class}, new MyMethodInterceptor()); } private static class MyMethodInterceptor implements MethodInterceptor { @Override public Object intercept(Object obj, Method method, Object[] args, MethodProxy proxy) throws Throwable { System.out.println(&quot;Some thing before method invoke&quot;); Object result = proxy.invokeSuper(obj, args); System.out.println(&quot;Some thing after method invoke&quot;); return result; } }从上小节可知，JDK 只能代理接口，代理生成的类实现了接口的方法；而 Cglib 是通过继承被代理的类、重写其方法来实现的，如：create 方法入参的第一个参数就是被代理类的类型。当然，Cglib 也能代理接口，比如 getProxy() 方法中的第二种方式。","categories":[{"name":"Java","slug":"java","permalink":"https://topone233.github.io/categories/java/"}],"tags":[{"name":"Java","slug":"java","permalink":"https://topone233.github.io/tags/java/"}]},{"title":"动态代理","slug":"动态代理","date":"2020-07-20T07:51:44.059Z","updated":"2020-08-25T13:31:04.915Z","comments":true,"path":"2020/07/20/动态代理/","link":"","permalink":"https://topone233.github.io/2020/07/20/%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86/","excerpt":"","text":"原文地址 代理模式为其他对象提供一个代理以控制对某个对象的访问。代理类主要负责为委托了（真实对象）预处理：消息、过滤消息、传递消息给委托类，代理类不现实具体服务，而是利用委托类来完成服务，并将执行结果封装处理。类似于生活中的中介。 有一个打印机的类 public class Printer { public void print(){ System.out.println(&quot;打印！&quot;); } }我想在打印之前先记录一下日志怎么做？ 最简单的方法：在打印的功能前面直接加上记录日志的功能。 public class Printer { public void print(){ System.out.println(&quot;记录日志！&quot;); System.out.println(&quot;打印！&quot;); } }看上去好像没有问题，但是我们修改了打印机的源代码，破坏了面向对象的开闭原则，有可能影响到其它功能。怎么解决呢？很容易可以想到，既然不能修改原来的代码，那我新建一个类吧。 public class LogPrinter extends Printer { public void print(){ System.out.println(&quot;记录日志！&quot;); System.out.println(&quot;打印！&quot;); } }这个类继承了打印机的类，重写了打印机的 print 方法，提供了记录日志的功能，以后需要打印机的时候使用这个类就好。问题似乎得到了解决，我们可以在这个解决方案的基础上进一步的优化： 静态代理先抽象出一个接口: public interface IPrinter { void print(); }打印机类（被代理类）实现这个接口: public class Printer implements IPrinter { @Override public void print(){ System.out.println(&quot;打印！&quot;); } }创建打印机代理类也实现该接口 被代理类被传递给了代理类PrinterProxy，代理类在执行具体方法时通过所持用的被代理类完成调用。 在构造函数中将打印机对象传进去，实现接口的打印方法时调用打印机对象的打印方法并在前面加上记录日志的功能: public class PrinterProxy implements IPrinter { private IPrinter printer; public PrinterProxy(){ this.printer = new printer(); } @Override public void print() { System.out.println(&quot;记录日志&quot;); printer.print(); } }试一把： public class Test { public static void main(String[] args) { PrinterProxy proxy = new PrinterProxy(); proxy.print(); } }结果出来了： 记录日志 打印以后我们就可以直接实例化 PrinterProxy 对象调用它的打印方法了，这就是静态代理模式，通过抽象出接口让程序的扩展性和灵活性更高了。 静态代理的缺点静态代理是完美无缺的吗？ 考虑一下，如果我的打印机类中还有别的方法，也需要加上记录日志的功能，但是静态代理只能为一个类服务，就不得不将记录日志的功能写 n 遍。进一步如果我还有电视机，电冰箱的类里面的所有方法也需要加上记录日志的功能，那要重复的地方就更多了。 怎么办？ 动态代理闪亮登场： 动态代理要想不重复写记录日志的功能，针对每一个接口实现一个代理类的做法肯定不可行了，可不可以让这些代理类的对象自动生成呢？ 利用反射机制在运行时创建代理类。 Jdk 提供了 invocationHandler 接口和 Proxy 类，借助这两个工具可以达到我们想要的效果。 invocationHandler 接口上场： //Object proxy:被代理的对象 //Method method:要调用的方法 //Object[] args:方法调用时所需要参数 public interface InvocationHandler { public Object invoke(Object proxy, Method method, Object[] args) throws Throwable; }接口里只有一个方法 invoke，这个方法非常重要，先混个脸熟，稍后解释。 Proxy 类上场，它里面有一个很重要的方法 newProxyInstance： //CLassLoader loader:被代理对象的类加载器 //Class&lt;?&gt; interfaces:被代理类全部的接口 //InvocationHandler h:实现InvocationHandler接口的对象 public static Object newProxyInstance(ClassLoader loader, Class&lt;?&gt;[] interfaces, InvocationHandler h) throws IllegalArgumentException 调用 Proxy 的 newProxyInstance 方法可以生成代理对象 一切准备就绪动态代理模式千呼万唤始出来： 接口 IPrinter 和 该接口的实现类 Printer 的代码同前。 实现一个类，该类用来创建代理对象，_它实现了_InvocationHandler 接口： public class ProxyHandler implements InvocationHandler { private Object targetObject;//被代理的对象 //将被代理的对象传入获得它的类加载器和实现接口作为Proxy.newProxyInstance方法的参数。 public Object newProxyInstance(Object targetObject){ this.targetObject = targetObject; //targetObject.getClass().getClassLoader()：被代理对象的类加载器 //targetObject.getClass().getInterfaces()：被代理对象的实现接口 //this 当前对象，该对象实现了InvocationHandler接口所以有invoke方法，通过invoke方法可以调用被代理对象的方法 return Proxy.newProxyInstance(targetObject.getClass().getClassLoader(),targetObject.getClass().getInterfaces(),this); } //该方法在代理对象调用方法时调用 @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { System.out.println(&quot;记录日志&quot;); return method.invoke(targetObject,args); } }被代理的对象 targetObject 可以通过方法参数传进来： public Object newProxyInstance(Object targetObject){ this.targetObject=targetObject;我们重点来分析一下这段代码： return Proxy.newProxyInstance(targetObject.getClass().getClassLoader(),targetObject.getClass().getInterfaces(),this);动态代理对象就是通过调用这段代码被创建并返回的。 方法有三个参数： 第一个参数： targetObject.getClass().getClassLoader()：targetObject 对象的类加载器。 第二个参数: targetObject.getClass().getInterfaces()：targetObject 对象的所有接口 第三个参数: this：也就是当前对象即实现了 InvocationHandler 接口的类的对象，在调用方法时会调用它的 invoke 方法。 再来看一下这段代码： public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { //在这里可以通过判断方法名来决定执行什么功能 System.out.println(&quot;记录日志&quot;); //调用被代理对象的方法 return method.invoke(targetObject, args); }这个方法就是生成的代理类中的方法被调用时会去自动调用的方法，可以看到在这个方法中调用了被代理对象的方法: method.invoke(targetObject, args); 我们可以在这里加上需要的业务逻辑，比如调用方法前记录日志功能. 见证奇迹的时刻到了： public class Test { public static void main(String[] args){ ProxyHandler proxyHandler=new ProxyHandler(); IPrinter printer = (IPrinter) proxyHandler.newProxyInstance(new Printer()); printer.print(); } }打印结果： 记录日志 打印当执行 printer.print(); 时会自动调用 invoke 方法，很多初学者不理解为什么能调用这个方法，回忆一下创建代理对象的时候是通过 return Proxy.newProxyInstance(targetObject.getClass().getClassLoader(),targetObject.getClass().getInterfaces(),this);来创建的，方法的第三个参数 this 是实现了 InvocationHandler 接口的对象， InvocationHandler 接口有 invoke 方法。现在有点思路了吧~ 将被代理的对象作为参数传入就可以执行里面的任意方法，所有的方法调用都通过 invoke 来完成。不用对每个方法进行处理，动态代理是不是很简洁。 动态代理的优势 Proxy 类的代码量被固定下来，不会因为业务的逐渐庞大而庞大； 可以实现 AOP 编程，实际上静态代理也可以实现，总的来说，AOP 可以算作是代理模式的一个典型应用； 解耦，通过参数就可以判断真实类，不需要事先实例化，更加灵活多变。 复习对象的创建很多初学 Java 的朋友眼中创建对象的过程 实际上可以换个角度，也说得通 所谓的 Class 对象，是 Class 类的实例，而 Class 类是描述所有类的，比如 Person 类，Student 类 可以看出，要创建一个实例，最关键的就是得到对应的 Class 对象。只不过对于初学者来说，new 这个关键字配合构造方法，实在太好用了，底层隐藏了太多细节，一句 Person p = new Person(); 直接把对象返回给你了。我自己刚开始学 Java 时，也没意识到 Class 对象的存在。 分析到这里，貌似有了思路： 能否不写代理类，而直接得到代理 Class 对象，然后根据它创建代理实例（反射) ? Class 对象包含了一个类的所有信息，比如构造器、方法、字段等。如果我们不写代理类，这些信息从哪获取呢？苦思冥想，突然灵光一现：代理类和目标类理应实现同一组接口。之所以实现相同接口，是为了尽可能保证代理对象的内部结构和目标对象一致，这样我们对代理对象的操作最终都可以转移到目标对象身上，代理对象只需专注于增强代码的编写。还是上面这幅图： 所以，可以这样说：接口拥有代理对象和目标对象共同的类信息。所以，我们可以从接口那得到理应由代理类提供的信息。但是别忘了，接口是无法创建对象的，怎么办？ JDK 提供了 java.lang.reflect.InvocationHandler 接口和 java.lang.reflect.Proxy 类，这两个类相互配合，入口是 Proxy，所以我们先聊它。 ProxyProxy 有个静态方法：getProxyClass(ClassLoader, interfaces)，只要你给它传入类加载器和一组接口，它就给你返回代理 Class 对象。 用通俗的话说，getProxyClass() 这个方法，会从你传入的接口 Class 中，“拷贝” 类结构信息到一个新的 Class 对象中，但新的 Class 对象带有构造器，是可以创建对象的。打个比方，一个大内太监（接口 Class），空有一身武艺（类信息），但是无法传给后人。现在江湖上有个妙手神医（Proxy 类），发明了克隆大法（getProxyClass），不仅能克隆太监的一身武艺，还保留了小 DD（构造器）…（这到底是道德の沦丧，还是人性的扭曲，欢迎走进动态代理） 所以，一旦我们明确接口，完全可以通过接口的 Class 对象，创建一个代理 Class，通过代理 Class 即可创建代理对象。 所以，按我理解，Proxy.getProxyClass() 这个方法的本质就是：以 Class 造 Class。 有了 Class 对象，就很好办了，具体看代码： 完美。 根据代理 Class 的构造器创建对象时，需要传入 InvocationHandler。每次调用代理对象的方法，最终都会调用 InvocationHandler 的 invoke() 方法： 怎么做到的呢？ 上面不是说了吗，根据代理 Class 的构造器创建对象时，需要传入 InvocationHandler。通过构造器传入一个引用，那么必然有个成员变量去接收。没错，代理对象的内部确实有个成员变量 invocationHandler，而且代理对象的每个方法内部都会调用 handler.invoke()！InvocationHandler 对象成了代理对象和目标对象的桥梁，不像静态代理这么直接。 大家仔细看上图右侧的动态代理，我在 invocationHandler 的 invoke() 方法中并没有写目标对象。因为一开始 invocationHandler 的 invoke() 里确实没有目标对象，需要我们手动 new。 但这种写法不够优雅，属于硬编码。我这次代理 A 对象，下次想代理 B 对象还要进来改 invoke() 方法，太差劲了。改进一下，让调用者把目标对象作为参数传进来： public class ProxyTest { public static void main(String[] args) throws Throwable { CalculatorImpl target = new CalculatorImpl(); //传入目标对象 //目的：1.根据它实现的接口生成代理对象 2.代理对象调用目标对象方法 Calculator calculatorProxy = (Calculator) getProxy(target); calculatorProxy.add(1, 2); calculatorProxy.subtract(2, 1); } private static Object getProxy(final Object target) throws Exception { //参数1：随便找个类加载器给它， 参数2：目标对象实现的接口，让代理对象实现相同接口 Class proxyClazz = Proxy.getProxyClass(target.getClass().getClassLoader(), target.getClass().getInterfaces()); Constructor constructor = proxyClazz.getConstructor(InvocationHandler.class); Object proxy = constructor.newInstance(new InvocationHandler() { @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { System.out.println(method.getName() + &quot;方法开始执行...&quot;); Object result = method.invoke(target, args); System.out.println(result); System.out.println(method.getName() + &quot;方法执行结束...&quot;); return result; } }); return proxy; } } 这样就非常灵活，非常优雅了。无论现在系统有多少类，只要你把实例传进来，getProxy() 都能给你返回对应的代理对象。就这样，我们完美地跳过了代理类，直接创建了代理对象！ 不过实际编程中，一般不用 getProxyClass()，而是使用 Proxy 类的另一个静态方法：Proxy.newProxyInstance()，直接返回代理实例，连中间得到代理 Class 对象的过程都帮你隐藏： public class ProxyTest { public static void main(String[] args) throws Throwable { CalculatorImpl target = new CalculatorImpl(); Calculator calculatorProxy = (Calculator) getProxy(target); calculatorProxy.add(1, 2); calculatorProxy.subtract(2, 1); } private static Object getProxy(final Object target) throws Exception { Object proxy = Proxy.newProxyInstance( target.getClass().getClassLoader(),/*类加载器*/ target.getClass().getInterfaces(),/*让代理对象和目标对象实现相同接口*/ new InvocationHandler(){/*代理对象的方法最终都会被JVM导向它的invoke方法*/ public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { System.out.println(method.getName() + &quot;方法开始执行...&quot;); Object result = method.invoke(target, args); System.out.println(result); System.out.println(method.getName() + &quot;方法执行结束...&quot;); return result; } } ); return proxy; } } 现在，我想应该能看懂动态代理了。 最后讨论一下代理对象是什么类型。 首先，请区分两个概念：代理 Class 对象和代理对象。 单从名字看，代理 Class 和 Calculator 的接口确实相去甚远，但是我们却能将代理对象赋值给接口类型： 千万别觉得名字奇怪，就怀疑它不能用接口接收，只要实现该接口就是该类型。 代理对象的本质就是：和目标对象实现相同接口的实例。代理 Class 可以叫任何名字，whatever，只要它实现某个接口，就能成为该接口类型。 我写了一个 MyProxy 类，那么它的 Class 名字必然叫 MyProxy。但这和能否赋值给接口没有任何关系。由于它实现了 Serializable 和 Collection，所以 myProxy（代理实例）同时是这两个接口的类型。 小结我想了个很骚的比喻，希望能解释清楚： 接口 Class 对象是大内太监，里面的方法和字段比做他的一身武艺，但是他没有小 DD（构造器），所以不能 new 实例。一身武艺后继无人。 那怎么办呢？ 正常途径（implements）： 写一个类，实现该接口。这个就相当于大街上拉了一个人，认他做干爹。一身武艺传给他，只是比他干爹多了小 DD，可以 new 实例。 非正常途径（动态代理）： 通过妙手圣医 Proxy 的克隆大法（Proxy.getProxyClass()），克隆一个 Class，但是有小 DD。所以这个克隆人 Class 可以创建实例，也就是代理对象。 代理 Class 其实就是附有构造器的接口 Class，一样的类结构信息，却能创建实例。 JDK 动态代理生成的实例 CGLib 动态代理生成的实例 如果说继承的父类是亲爹（只有一个），那么实现的接口是干爹（可以有多个）。 实现接口是一个类认干爹的过程。接口无法创建对象，但实现该接口的类可以。 比如 class Student extends Person implements A, B这个类 new 一个实例出来，你问它：你爸爸是谁啊？它会告诉你：我只有一个爸爸 Person。 但是 student instanceof A interface，或者 student instanceof B interface，它会告诉你两个都是它干爹（true），都可以用来接收它。 然而，凡是有利必有弊。 也就是说，动态代理生成的代理对象，最终都可以用接口接收，和目标对象一起形成了多态，可以随意切换展示不同的功能。但是切换的同时，只能使用该接口定义的方法。 类加载器初学者可能对诸如 “字节码文件”、Class 对象比较陌生。所以这里花一点点篇幅介绍一下类加载器的部分原理。如果我们要定义类加载器，需要继承 ClassLoader 类，并覆盖 findClass() 方法： @Override public Class&lt;?&gt; findClass(String name) throws ClassNotFoundException { try { /*自己另外写一个getClassData() 通过IO流从指定位置读取xxx.class文件得到字节数组*/ byte[] datas = getClassData(name); if(datas == null) { throw new ClassNotFoundException(&quot;类没有找到：&quot; + name); } //调用类加载器本身的defineClass()方法，由字节码得到Class对象 return this.defineClass(name, datas, 0, datas.length); } catch (IOException e) { e.printStackTrace(); throw new ClassNotFoundException(&quot;类找不到：&quot; + name); } } 所以，这就是类加载之所以能把 xxx.class 文件加载进内存，并创建对应 Class 对象的深层原因。","categories":[{"name":"Java","slug":"java","permalink":"https://topone233.github.io/categories/java/"}],"tags":[{"name":"Java","slug":"java","permalink":"https://topone233.github.io/tags/java/"},{"name":"动态代理","slug":"动态代理","permalink":"https://topone233.github.io/tags/%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86/"}]},{"title":"HashMap 剖析 (基于 jdk1.8)","slug":"HashMap 剖析 (基于 jdk1.8)","date":"2020-07-10T09:07:59.406Z","updated":"2020-08-25T13:24:44.198Z","comments":true,"path":"2020/07/10/HashMap 剖析 (基于 jdk1.8)/","link":"","permalink":"https://topone233.github.io/2020/07/10/HashMap%20%E5%89%96%E6%9E%90%20(%E5%9F%BA%E4%BA%8E%20jdk1.8)/","excerpt":"","text":"原文地址 www.cnblogs.com 本文的源码是基于 JDK1.8 版本，在学习 HashMap 之前，先了解数组和链表的知识。 数组数组具有遍历快，增删慢的特点。数组在堆中是一块连续的存储空间，遍历时数组的首地址是知道的（首地址 = 首地址 + 元素字节数 * 下标），所以遍历快（数组遍历的时间复杂度为 O(1) ）；增删慢是因为，当在中间插入或删除元素时，会造成该元素后面所有元素地址的改变，所以增删慢（增删的时间复杂度为 O(n) ）。 链表链表具有增删快，遍历慢的特点。链表中各元素的内存空间是不连续的，一个节点至少包含节点数据与后继节点的引用，所以在插入删除时，只需修改该位置的前驱节点与后继节点即可，链表在插入删除时的时间复杂度为 O(1)。但是在遍历时，get(n) 元素时，需要从第一个开始，依次拿到后面元素的地址，进行遍历，直到遍历到第 n 个元素（时间复杂度为 O(n) ），所以效率极低。 HashMapHash 表是一个数组 + 链表的结构，这种结构能够保证在遍历与增删的过程中，如果不产生 hash 碰撞，仅需一次定位就可完成，时间复杂度能保证在 O(1)。 在 jdk1.7 中，只是单纯的数组 + 链表的结构，但是如果散列表中的 hash 碰撞过多时，会造成效率的降低，所以在 JKD1.8 中对这种情况进行了控制，当一个 hash 值上的链表长度大于 8 时，该节点上的数据就不再以链表进行存储，而是转成了一个红黑树。 红黑树: static final class TreeNode&lt;K,V&gt; extends LinkedHashMap.Entry&lt;K,V&gt; { TreeNode&lt;K,V&gt; parent; // red-black tree links TreeNode&lt;K,V&gt; left; TreeNode&lt;K,V&gt; right; TreeNode&lt;K,V&gt; prev; // needed to unlink next upon deletion boolean red; } hash 碰撞hash 是指，两个元素通过 hash 函数计算出的值是一样的，是同一个存储地址。当后面的元素要插入到这个地址时，发现已经被占用了，这时候就产生了 hash 冲突 hash 冲突的解决方法开放定址法 (查询产生冲突的地址的下一个地址是否被占用，直到寻找到空的地址)，再散列法，链地址法等。hashmap 采用的就是链地址法，jdk1.7 中，当冲突时，在冲突的地址上生成一个链表，将冲突的元素的 key，通过 equals 进行比较，相同即覆盖，不同则添加到链表上，此时如果链表过长，效率就会大大降低，查找和添加操作的时间复杂度都为 O(n)；但是在 jdk1.8 中如果链表长度大于 8，链表就会转化为红黑树，下图就是 1.8 版本的（图片来源 https://segmentfault.com/a/1190000012926722），时间复杂度也降为了 O(logn)，性能得到了很大的优化。 HashMap 的底层实现首先，hashMap 的主干是一个 Node 数组（jdk1.7 及之前为 Entry 数组）每一个 Node 包含一个 key 与 value 的键值对，与一个 next 指向下一个 node，hashMap 由多个 Node 对象组成。 Node 是 HhaspMap 中的一个静态内部类 ： static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; { final int hash; final K key; V value; Node&lt;K,V&gt; next; Node(int hash, K key, V value, Node&lt;K,V&gt; next) { this.hash = hash; this.key = key; this.value = value; this.next = next; } public final K getKey() { return key; } public final V getValue() { return value; } public final String toString() { return key + &quot;=&quot; + value; } //hashCode等其他代码 } 再看下 hashMap 中几个重要的字段： //默认初始容量为16，0000 0001 左移4位 0001 0000为16，主干数组的初始容量为16，而且这个数组 //必须是2的倍数(后面说为什么是2的倍数) static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // aka 16 //最大容量为int的最大值除2 static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30; //默认加载因子为0.75 static final float DEFAULT_LOAD_FACTOR = 0.75f; //阈值，如果主干数组上的链表的长度大于8，链表转化为红黑树 static final int TREEIFY_THRESHOLD = 8; //hash表扩容后，如果发现某一个红黑树的长度小于6，则会重新退化为链表 static final int UNTREEIFY_THRESHOLD = 6; //当hashmap容量大于64时，链表才能转成红黑树 static final int MIN_TREEIFY_CAPACITY = 64; //临界值=主干数组容量*负载因子 int threshold； HashMap 的构造方法//initialCapacity为初始容量，loadFactor为负载因子 public HashMap(int initialCapacity, float loadFactor) { //初始容量小于0，抛出非法数据异常 if (initialCapacity &lt; 0) throw new IllegalArgumentException(&quot;Illegal initial capacity: &quot; + initialCapacity); //初始容量最大为MAXIMUM_CAPACITY if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; //负载因子必须大于0，并且是合法数字 if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(&quot;Illegal load factor: &quot; + loadFactor); this.loadFactor = loadFactor; //将初始容量转成2次幂 this.threshold = tableSizeFor(initialCapacity); } //tableSizeFor的作用就是，如果传入A，当A大于0，小于定义的最大容量时， //如果A是2次幂则返回A，否则将A转化为一个比A大且差距最小的2次幂。 //例如传入7返回8，传入8返回8，传入9返回16 static final int tableSizeFor(int cap) { int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1; } //调用上面的构造方法，自定义初始容量，负载因子为默认的0.75 public HashMap(int initialCapacity) { this(initialCapacity, DEFAULT_LOAD_FACTOR); } //默认构造方法，负载因子为0.75，初始容量为DEFAULT_INITIAL_CAPACITY=16，初始容量在第一次put时才会初始化 public HashMap() { this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted } //传入一个MAP集合的构造方法 public HashMap(Map&lt;? extends K, ? extends V&gt; m) { this.loadFactor = DEFAULT_LOAD_FACTOR; putMapEntries(m, false); } HashMap 的 put() 方法put 方法的源码分析是本篇的一个重点，因为通过该方法我们可以窥探到 HashMap 在内部是如何进行数据存储的，所谓的数组 + 链表 + 红黑树的存储结构是如何形成的，又是在何种情况下将链表转换成红黑树来优化性能的。带着一系列的疑问，我们看这个 put 方法： public V put(K key, V value) { return putVal(hash(key), key, value, false, true); } 也就是 put 方法调用了 putVal 方法，其中传入一个参数位 hash(key)，我们首先来看看 hash() 这个方法。 static final int hash(Object key) { int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16); } 此处如果传入的 int 类型的值：①向一个 Object 类型赋值一个 int 的值时，会将 int 值自动封箱为 Integer。②integer 类型的 hashcode 都是他自身的值，即 h=key；h &gt;&gt;&gt; 16 为无符号右移 16 位，低位挤走，高位补 0；^ 为按位异或，即转成二进制后，相异为 1，相同为 0，由此可发现，当传入的值小于 2 的 16 次方 - 1 时，调用这个方法返回的值，都是自身的值。然后再执行 putVal 方法： //onlyIfAbsent是true的话，不要改变现有的值 //evict为true的话，表处于创建模式 final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) { Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; //如果主干上的table为空，长度为0，调用resize方法，调整table的长度（resize方法在下图中） if ((tab = table) == null || (n = tab.length) == 0) /* 这里调用resize，其实就是第一次put时，对数组进行初始化。 如果是默认构造方法会执行resize中的这几句话： newCap = DEFAULT_INITIAL_CAPACITY; 新的容量等于默认值16 newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); threshold = newThr; 临界值等于16*0.75 Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; 将新的node数组赋值给table，然后return newTab 如果是自定义的构造方法则会执行resize中的： int oldThr = threshold; newCap = oldThr; 新的容量等于threshold，这里的threshold都是2的倍数，原因在 于传入的数都经过tableSizeFor方法，返回了一个新值，上面解释过 float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); threshold = newThr; 新的临界值等于 (int)(新的容量*负载因子) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; return newTab; */ n = (tab = resize()).length; //将调用resize后构造的数组的长度赋值给n if ((p = tab[i = (n - 1) &amp; hash]) == null) //将数组长度与计算得到的hash值比较 tab[i] = newNode(hash, key, value, null);//位置为空，将i位置上赋值一个node对象 else { //位置不为空 Node&lt;K,V&gt; e; K k; if (p.hash == hash &amp;&amp; // 如果这个位置的old节点与new节点的key完全相同 ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; // 则e=p else if (p instanceof TreeNode) // 如果p已经是树节点的一个实例，既这里已经是树了 e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else { //p与新节点既不完全相同，p也不是treenode的实例 for (int binCount = 0; ; ++binCount) { //一个死循环 if ((e = p.next) == null) { //e=p.next,如果p的next指向为null p.next = newNode(hash, key, value, null); //指向一个新的节点 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // 如果链表长度大于等于8 treeifyBin(tab, hash); //将链表转为红黑树 break; } if (e.hash == hash &amp;&amp; //如果遍历过程中链表中的元素与新添加的元素完全相同，则跳出循环 ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; //将p中的next赋值给p,即将链表中的下一个node赋值给p， //继续循环遍历链表中的元素 } } if (e != null) { //这个判断中代码作用为：如果添加的元素产生了hash冲突，那么调用 //put方法时，会将他在链表中他的上一个元素的值返回 V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) //判断条件成立的话，将oldvalue替换 //为newvalue，返回oldvalue；不成立则不替换，然后返回oldvalue e.value = value; afterNodeAccess(e); //这个方法在后面说 return oldValue; } } ++modCount; //记录修改次数 if (++size &gt; threshold) //如果元素数量大于临界值，则进行扩容 resize(); //下面说 afterNodeInsertion(evict); return null; } 在 Java 8 中，如果一个桶中的元素个数超过 TREEIFY_THRESHOLD(默认是 8)，就使用红黑树来替换链表，从而提高速度。上诉代码这个替换的方法叫 treeifyBin() 即树形化。 看一下 treeifyBin() 的源码: //将桶内所有的 链表节点 替换成 红黑树节点 final void treeifyBin(Node&lt;K,V&gt;[] tab, int hash) { int n, index; Node&lt;K,V&gt; e; //如果当前哈希表为空，或者哈希表中元素的个数小于 进行树形化的阈值(默认为 64)，就去新建/扩容 if (tab == null || (n = tab.length) &lt; MIN_TREEIFY_CAPACITY) resize(); else if ((e = tab[index = (n - 1) &amp; hash]) != null) { //如果哈希表中的元素个数超过了 树形化阈值，进行树形化 // e 是哈希表中指定位置桶里的链表节点，从第一个开始 TreeNode&lt;K,V&gt; hd = null, tl = null; //红黑树的头、尾节点 do { //新建一个树形节点，内容和当前链表节点 e 一致 TreeNode&lt;K,V&gt; p = replacementTreeNode(e, null); if (tl == null) //确定树头节点 hd = p; else { p.prev = tl; tl.next = p; } tl = p; } while ((e = e.next) != null); //让桶的第一个元素指向新建的红黑树头结点，以后这个桶里的元素就是红黑树而不是链表了 if ((tab[index] = hd) != null) hd.treeify(tab); } } TreeNode&lt;K,V&gt; replacementTreeNode(Node&lt;K,V&gt; p, Node&lt;K,V&gt; next) { return new TreeNode&lt;&gt;(p.hash, p.key, p.value, next); } 注释已经很详细了，咱们说一下这个初始化的问题 //如果 table 还未被初始化，那么初始化它 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; resize() 扩容机制，单元素如何散列到新的数组中，链表中的元素如何散列到新的数组中，红黑树中的元素如何散列到新的数组中？ //上图中说了默认构造方法与自定义构造方法第一次执行resize的过程，这里再说一下扩容的过程 final Node&lt;K,V&gt;[] resize() { Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; if (oldCap &gt; 0) { //扩容肯定执行这个分支 if (oldCap &gt;= MAXIMUM_CAPACITY) { //当容量超过最大值时，临界值设置为int最大值 threshold = Integer.MAX_VALUE; return oldTab; } else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) //扩容容量为2倍，临界值为2倍 newThr = oldThr &lt;&lt; 1; } else if (oldThr &gt; 0) // 不执行 newCap = oldThr; else { // 不执行 newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); } if (newThr == 0) { // 不执行 float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); } threshold = newThr; //将新的临界值赋值赋值给threshold @SuppressWarnings({&quot;rawtypes&quot;,&quot;unchecked&quot;}) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; //新的数组赋值给table //扩容后，重新计算元素新的位置 if (oldTab != null) { //原数组 for (int j = 0; j &lt; oldCap; ++j) { //通过原容量遍历原数组 Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) { //判断node是否为空，将j位置上的节点 //保存到e,然后将oldTab置为空，这里为什么要把他置为空呢，置为空有什么好处吗？？ //难道是吧oldTab变为一个空数组，便于垃圾回收？？ 这里不是很清楚 oldTab[j] = null; if (e.next == null) //判断node上是否有链表 newTab[e.hash &amp; (newCap - 1)] = e; //无链表，确定元素存放位置， //扩容前的元素地址为 (oldCap - 1) &amp; e.hash ,所以这里的新的地址只有两种可能，一是地址不变， //二是变为 老位置+oldCap else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else { // preserve order Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; /* 这里如果判断成立，那么该元素的地址在新的数组中就不会改变。因为oldCap的最高位的1，在e.hash对应的位上为0，所以扩容后得到的地址是一样的，位置不会改变 ，在后面的代码的执行中会放到loHead中去，最后赋值给newTab[j]； 如果判断不成立，那么该元素的地址变为 原下标位置+oldCap，也就是lodCap最高位的1，在e.hash对应的位置上也为1，所以扩容后的地址改变了，在后面的代码中会放到hiHead中，最后赋值给newTab[j + oldCap] 举个栗子来说一下上面的两种情况： 设：oldCap=16 二进制为：0001 0000 oldCap-1=15 二进制为：0000 1111 e1.hash=10 二进制为：0000 1010 e2.hash=26 二进制为：0101 1010 e1在扩容前的位置为：e1.hash &amp; oldCap-1 结果为：0000 1010 e2在扩容前的位置为：e2.hash &amp; oldCap-1 结果为：0000 1010 结果相同，所以e1和e2在扩容前在同一个链表上，这是扩容之前的状态。 现在扩容后，需要重新计算元素的位置，在扩容前的链表中计算地址的方式为e.hash &amp; oldCap-1 那么在扩容后应该也这么计算呀，扩容后的容量为oldCap*2=32 0010 0000 newCap=32，新的计算 方式应该为 e1.hash &amp; newCap-1 即：0000 1010 &amp; 0001 1111 结果为0000 1010与扩容前的位置完全一样。 e2.hash &amp; newCap-1 即：0101 1010 &amp; 0001 1111 结果为0001 1010,为扩容前位置+oldCap。 而这里却没有e.hash &amp; newCap-1 而是 e.hash &amp; oldCap，其实这两个是等效的，都是判断倒数第五位 是0，还是1。如果是0，则位置不变，是1则位置改变为扩容前位置+oldCap。 再来分析下loTail loHead这两个的执行过程（假设(e.hash &amp; oldCap) == 0成立）： 第一次执行： e指向oldTab[j]所指向的node对象，即e指向该位置上链表的第一个元素 loTail为空,所以loHead指向与e相同的node对象，然后loTail也指向了同一个node对象。 最后，在判断条件e指向next，就是指向oldTab链表中的第二个元素 第二次执行： lotail不为null，所以lotail.next指向e，这里其实是lotail指向的node对象的next指向e， 也可以说是，loHead的next指向了e，就是指向了oldTab链表中第二个元素。此时loHead指向 的node变成了一个长度为2的链表。然后lotail=e也就是指向了链表中第二个元素的地址。 第三次执行： 与第二次执行类似，loHead上的链表长度变为3，又增加了一个node，loTail指向新增的node ...... hiTail与hiHead的执行过程与以上相同，这里就不再做解释了。 由此可以看出，loHead是用来保存新链表上的头元素的，loTail是用来保存尾元素的，直到遍 历完链表。 这是(e.hash &amp; oldCap) == 0成立的时候。 (e.hash &amp; oldCap) == 0不成立的情况也相同，其实就是把oldCap遍历成两个新的链表， 通过loHead和hiHead来保存链表的头结点，然后将两个头结点放到newTab[j]与 newTab[j+oldCap]上面去 */ do { next = e.next; if ((e.hash &amp; oldCap) == 0) { if (loTail == null) loHead = e; else loTail.next = e; loTail = e; } else { if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; } } while ((e = next) != null); if (loTail != null) { loTail.next = null; //尾节点的next设置为空 newTab[j] = loHead; } if (hiTail != null) { hiTail.next = null; //尾节点的next设置为空 newTab[j + oldCap] = hiHead; } } } } } return newTab; } 有关 JDK1.7 扩容出现的死循环的问题: /** * Transfers all entries from current table to newTable. */ void transfer(Entry[] newTable) { Entry[] src = table; int newCapacity = newTable.length; for (int j = 0; j &lt; src.length; j++) { Entry&lt;K,V&gt; e = src[j]; if (e != null) { src[j] = null; do { // B线程执行到这里之后就暂停了 Entry&lt;K,V&gt; next = e.next; int i = indexFor(e.hash, newCapacity); e.next = newTable[i]; newTable[i] = e; e = next; } while (e != null); } } } 并发下的 Rehash 1）假设我们有两个线程。我用红色和浅蓝色标注了一下。我们再回头看一下我们的 transfer 代码中的这个细节： do { Entry&lt;K,V&gt; next = e.next; // &lt;--假设线程一执行到这里就被调度挂起了 int i = indexFor(e.hash, newCapacity); e.next = newTable[i]; newTable[i] = e; e = next; } while (e != null); 而我们的线程二执行完成了。于是我们有下面的这个样子。 注意，因为 Thread1 的 e 指向了 key(3)，而 next 指向了 key(7)，其在线程二 rehash 后，指向了线程二重组后的链表。我们可以看到链表的顺序被反转后。 2）线程一被调度回来执行。 先是执行 newTalbe[i] = e; 然后是 e = next，导致了 e 指向了 key(7)， 而下一次循环的 next = e.next 导致了 next 指向了 key(3) 3）一切安好。 线程一接着工作。把 key(7) 摘下来，放到 newTable[i] 的第一个，然后把 e 和 next 往下移。 4）环形链接出现。 e.next = newTable[i] 导致 key(3).next 指向了 key(7) 注意：此时的 key(7).next 已经指向了 key(3)， 环形链表就这样出现了。 于是，当我们的线程一调用到，HashTable.get(11) 时，悲剧就出现了——Infinite Loop。 因为 HashMap 本来就不支持并发。要并发就用 ConcurrentHashmap HashMap 的 get() 方法public V get(Object key) { Node&lt;K,V&gt; e; //直接调用了getNode() return (e = getNode(hash(key), key)) == null ? null : e.value; } final Node&lt;K,V&gt; getNode(int hash, Object key) { Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; //先判断数组是否为空，长度是否大于0，那个node节点是否存在 if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) { //如果找到，直接返回 if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; if ((e = first.next) != null) { //如果是红黑树，去红黑树找 if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); //链表找 do { if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; } while ((e = e.next) != null); } } return null; } 这里关于first = tab[(n - 1) &amp; hash] 这里通过(n - 1)&amp; hash即可算出桶的在桶数组中的位置，可能有的朋友不太明白这里为什么这么做，这里简单解释一下。HashMap 中桶数组的大小 length 总是 2 的幂，此时，(n - 1) &amp; hash 等价于对 length 取余。但取余的计算效率没有位运算高，所以(n - 1) &amp; hash也是一个小的优化。举个例子说明一下吧，假设 hash = 185，n = 16。计算过程示意图如下 在上面源码中，除了查找相关逻辑，还有一个计算 hash 的方法。这个方法源码如下： /** * 计算键的 hash 值 */ static final int hash(Object key) { int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16); } 看这个方法的逻辑好像是通过位运算重新计算 hash，那么这里为什么要这样做呢？为什么不直接用键的 hashCode 方法产生的 hash 呢？大家先可以思考一下，我把答案写在下面。 这样做有两个好处，我来简单解释一下。我们再看一下上面求余的计算图，图中的 hash 是由键的 hashCode 产生。计算余数时，由于 n 比较小，hash 只有低 4 位参与了计算，高位的计算可以认为是无效的。这样导致了计算结果只与低位信息有关，高位数据没发挥作用。为了处理这个缺陷，我们可以上图中的 hash 高 4 位数据与低 4 位数据进行异或运算，即 hash ^ (hash &gt;&gt;&gt; 4)。通过这种方式，让高位数据与低位数据进行异或，以此加大低位信息的随机性，变相的让高位数据参与到计算中。此时的计算过程如下： 在 Java 中，hashCode 方法产生的 hash 是 int 类型，32 位宽。前 16 位为高位，后 16 位为低位，所以要右移 16 位。 上面所说的是重新计算 hash 的一个好处，除此之外，重新计算 hash 的另一个好处是可以增加 hash 的复杂度。当我们覆写 hashCode 方法时，可能会写出分布性不佳的 hashCode 方法，进而导致 hash 的冲突率比较高。通过移位和异或运算，可以让 hash 变得更复杂，进而影响 hash 的分布性。这也就是为什么 HashMap 不直接使用键对象原始 hash 的原因了。 由于个人能力问题, 先学习这些, 数据结构这个大山, 我一定要刨平它。 基于 jdk1.7 版本的 HashMap https://www.jianshu.com/p/dde9b12343c1 参考博客: https://www.cnblogs.com/wenbochang/archive/2018/02/22/8458756.html https://segmentfault.com/a/1190000012926722 https://blog.csdn.net/pange1991/article/details/82377980","categories":[{"name":"数据结构","slug":"数据结构","permalink":"https://topone233.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}],"tags":[{"name":"Java","slug":"java","permalink":"https://topone233.github.io/tags/java/"},{"name":"数据结构","slug":"数据结构","permalink":"https://topone233.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"面试","slug":"面试","permalink":"https://topone233.github.io/tags/%E9%9D%A2%E8%AF%95/"}]},{"title":"HashMap 面试必问的数据结构相关知识总结","slug":"HashMap 面试必问的数据结构相关知识总结","date":"2020-07-10T09:07:59.400Z","updated":"2020-08-25T13:24:33.268Z","comments":true,"path":"2020/07/10/HashMap 面试必问的数据结构相关知识总结/","link":"","permalink":"https://topone233.github.io/2020/07/10/HashMap%20%E9%9D%A2%E8%AF%95%E5%BF%85%E9%97%AE%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86%E6%80%BB%E7%BB%93/","excerpt":"","text":"原文地址 www.cnblogs.com 1.HashMap 的数据结构？​ 哈希表结构（链表散列：数组 + 链表）实现，结合数组和链表的优点。当链表长度超过 8 时，链表转换为红黑树。transient Node&lt;K,V&gt;[] table; 2.HashMap 的工作原理？ HashMap 底层是 hash 数组和单向链表实现，数组中的每个元素都是链表，由 Node 内部类（实现 Map.Entry&lt;K,V&gt; 接口）实现，HashMap 通过 put &amp; get 方法存储和获取。 存储对象时，将 K/V 键值传给 put() 方法： ​ ①、调用 hash(K) 方法计算 K 的 hash 值，然后结合数组长度，计算得数组下标； ​ ②、调整数组大小（当容器中的元素个数大于 capacity * loadfactor 时，容器会进行扩容 resize 为 2n）； ​ ③、如果 K 的 hash 值在 HashMap 中不存在，则执行插入，若存在，则发生碰撞； 如果 K 的 hash 值在 HashMap 中存在，且它们两者 equals 返回 true，则更新键值对； 如果 K 的 hash 值在 HashMap 中存在，且它们两者 equals 返回 false，则插入链表的尾部（尾插法）或者红黑树中。 （JDK 1.7 之前使用头插法、JDK 1.8 使用尾插法）（注意：当碰撞导致链表大于 TREEIFY_THRESHOLD = 8 时，就把链表转换成红黑树） 获取对象时，将 K 传给 get() 方法： ①、调用 hash(K) 方法（计算 K 的 hash 值）从而获取该键值所在链表的数组下标； ②、顺序遍历链表，equals() 方法查找相同 Node 链表中 K 值对应的 V 值。 hashCode 是定位的，找到存储位置；equals 是定性的，比较两者是否相等。 3. 当两个对象的 hashCode 相同会发生什么？ 因为 hashCode 相同，不一定就是相等的（equals 方法比较），如果两个对象所在数组的下标相同，”碰撞” 就此发生。又因为 HashMap 使用链表存储对象，这个 Node 会存储到链表中。 4. 你知道 hash 的实现吗？为什么要这样实现？ JDK 1.8 中，是通过 hashCode() 的高 16 位异或低 16 位实现的：(h = k.hashCode()) ^ (h &gt;&gt;&gt; 16)，主要是从速度，功效和质量来考虑的，减少系统的开销，也不会造成因为高位没有参与下标的计算，从而引起的碰撞。 5. 为什么要用异或运算符？​ 保证了对象的 hashCode 的 32 位值只要有一位发生改变，整个 hash() 返回值就会改变。尽可能的减少碰撞。 6. HashMap 的 table 的容量如何确定？loadFactor 是什么？ 该容量如何变化？这种变化会带来什么问题？​ ①、table 数组大小是由capacity这个参数确定的，默认是 16，也可以构造时传入，最大限制是 1&lt;&lt;30； ​ ②、loadFactor 是装载因子，主要目的是用来确认 table 数组是否需要动态扩展，默认值是 0.75，比如 table 数组大小为 16，装载 因子为 0.75 时，threshold 就是 12，当 table 的实际大小超过 12 时，table 就需要动态扩容； ​ ③、扩容时，调用 resize() 方法，将 table 长度变为原来的两倍（注意是 table 长度，而不是 threshold） ​ ④、如果数据很大的情况下，扩展时将会带来性能的损失，在性能要求很高的地方，这种损失很可能很致命。 7.HashMap 中 put 方法的过程？ 答：“调用哈希函数获取 Key 对应的 hash 值，再计算其数组下标； 如果没有出现哈希冲突，则直接放入数组；如果出现哈希冲突，则以链表的方式放在链表后面； 如果链表长度超过阀值 (TREEIFY THRESHOLD==8)，就把链表转成红黑树，链表长度低于 6，就把红黑树转回链表; 如果结点的 key 已经存在，则替换其 value 即可； 如果集合中的键值对大于 12，调用 resize 方法进行数组扩容。” 8. 数组扩容的过程？ 创建一个新的数组，其容量为旧数组的两倍，并重新计算旧数组中结点的存储位置。结点在新数组中的位置只有两种，原下标位置或原下标 + 旧数组的大小。 9. 拉链法导致的链表过深问题为什么不用二叉查找树代替，而选择红黑树？为什么不一直使用红黑树？​ 之所以选择红黑树是为了解决二叉查找树的缺陷，二叉查找树在特殊情况下会变成一条线性结构（这就跟原来使用链表结构一样了，造成很深的问题），遍历查找会非常慢。而红黑树在插入新数据后可能需要通过左旋，右旋、变色这些操作来保持平衡，引入红黑树就是为了查找数据快，解决链表查询深度的问题，我们知道红黑树属于平衡二叉树，但是为了保持 “平衡” 是需要付出代价的，但是该代价所损耗的资源要比遍历线性链表要少，所以当长度大于 8 的时候，会使用红黑树，如果链表长度很短的话，根本不需要引入红黑树，引入反而会慢。 10. 说说你对红黑树的见解？ 1、每个节点非红即黑 2、根节点总是黑色的 3、如果节点是红色的，则它的子节点必须是黑色的（反之不一定） 4、每个叶子节点都是黑色的空节点（NIL 节点） 5、从根节点到叶节点或空子节点的每条路径，必须包含相同数目的黑色节点（即相同的黑色高度） 11.jdk8 中对 HashMap 做了哪些改变？ 在 java 1.8 中，如果链表的长度超过了 8，那么链表将转换为红黑树。（桶的数量必须大于 64，小于 64 的时候只会扩容） 发生 hash 碰撞时，java 1.7 会在链表的头部插入，而 java 1.8 会在链表的尾部插入 在 java 1.8 中，Entry 被 Node 替代 (换了一个马甲)。 12.HashMap，LinkedHashMap，TreeMap 有什么区别？ HashMap 参考其他问题： LinkedHashMap 保存了记录的插入顺序，在用 Iterator 遍历时，先取到的记录肯定是先插入的；遍历比 HashMap 慢； TreeMap 实现 SortMap 接口，能够把它保存的记录根据键排序（默认按键值升序排序，也可以指定排序的比较器） 13.HashMap &amp; TreeMap &amp; LinkedHashMap 使用场景？ 一般情况下，使用最多的是 HashMap。 HashMap：在 Map 中插入、删除和定位元素时； TreeMap：在需要按自然顺序或自定义顺序遍历键的情况下； LinkedHashMap：在需要输出的顺序和输入的顺序相同的情况下。 14.HashMap 和 HashTable 有什么区别？ ①、HashMap 是线程不安全的，HashTable 是线程安全的； ②、由于线程安全，所以 HashTable 的效率比不上 HashMap； ③、HashMap 最多只允许一条记录的键为 null，允许多条记录的值为 null，而 HashTable 不允许； ④、HashMap 默认初始化数组的大小为 16，HashTable 为 11，前者扩容时，扩大两倍，后者扩大两倍 + 1； ⑤、HashMap 需要重新计算 hash 值，而 HashTable 直接使用对象的 hashCode 15.Java 中的另一个线程安全的与 HashMap 极其类似的类是什么？同样是线程安全，它与 HashTable 在线程同步上有什么不同？ ConcurrentHashMap 类（是 Java 并发包 java.util.concurrent 中提供的一个线程安全且高效的 HashMap 实现）。 HashTable 是使用 synchronize 关键字加锁的原理（就是对对象加锁）； 而针对 ConcurrentHashMap，在 JDK 1.7 中采用 分段锁的方式；JDK 1.8 中直接采用了 CAS（无锁算法）+ synchronized。 16.HashMap &amp; ConcurrentHashMap 的区别？ 除了加锁，原理上无太大区别。另外，HashMap 的键值对允许有 null，但是 ConCurrentHashMap 都不允许。 17. 为什么 ConcurrentHashMap 比 HashTable 效率要高？ HashTable 使用一把锁（锁住整个链表结构）处理并发问题，多个线程竞争一把锁，容易阻塞； ConcurrentHashMap JDK 1.7 中使用分段锁（ReentrantLock + Segment + HashEntry），相当于把一个 HashMap 分成多个段，每段分配一把锁，这样支持多线程访问。锁粒度：基于 Segment，包含多个 HashEntry。 JDK 1.8 中使用 CAS + synchronized + Node + 红黑树。锁粒度：Node（首结点）（实现 Map.Entry&lt;K,V&gt;）。锁粒度降低了。 18. 针对 ConcurrentHashMap 锁机制具体分析（JDK 1.7 VS JDK 1.8）？ JDK 1.7 中，采用分段锁的机制，实现并发的更新操作，底层采用数组 + 链表的存储结构，包括两个核心静态内部类 Segment 和 HashEntry。 ①、Segment 继承 ReentrantLock（重入锁） 用来充当锁的角色，每个 Segment 对象守护每个散列映射表的若干个桶； ②、HashEntry 用来封装映射表的键 - 值对； ③、每个桶是由若干个 HashEntry 对象链接起来的链表 JDK 1.8 中，采用 Node + CAS + Synchronized 来保证并发安全。取消类 Segment，直接用 table 数组存储键值对；当 HashEntry 对象组成的链表长度超过 TREEIFY_THRESHOLD 时，链表转换为红黑树，提升性能。底层变更为数组 + 链表 + 红黑树。 19.ConcurrentHashMap 在 JDK 1.8 中，为什么要使用内置锁 synchronized 来代替重入锁 ReentrantLock？​ ①、粒度降低了；​ ②、JVM 开发团队没有放弃 synchronized，而且基于 JVM 的 synchronized 优化空间更大，更加自然。​ ③、在大量的数据操作下，对于 JVM 的内存压力，基于 API 的 ReentrantLock 会开销更多的内存。 20.ConcurrentHashMap 简单介绍？①、重要的常量： private transient volatile int sizeCtl; 当为负数时，-1 表示正在初始化，-N 表示 N - 1 个线程正在进行扩容； 当为 0 时，表示 table 还没有初始化； 当为其他正数时，表示初始化或者下一次进行扩容的大小。 ②、数据结构： Node 是存储结构的基本单元，继承 HashMap 中的 Entry，用于存储数据； TreeNode 继承 Node，但是数据结构换成了二叉树结构，是红黑树的存储结构，用于红黑树中存储数据； TreeBin 是封装 TreeNode 的容器，提供转换红黑树的一些条件和锁的控制。 ③、存储对象时（put() 方法）： 1. 如果没有初始化，就调用 initTable() 方法来进行初始化； 2. 如果没有 hash 冲突就直接 CAS 无锁插入； 3. 如果需要扩容，就先进行扩容； 4. 如果存在 hash 冲突，就加锁来保证线程安全，两种情况：一种是链表形式就直接遍历到尾端插入，一种是红黑树就按照红黑树结构插入； 5. 如果该链表的数量大于阀值 8，就要先转换成红黑树的结构，break 再一次进入循环 6. 如果添加成功就调用 addCount() 方法统计 size，并且检查是否需要扩容。 ④、扩容方法 transfer()：默认容量为 16，扩容时，容量变为原来的两倍。 helpTransfer()：调用多个工作线程一起帮助进行扩容，这样的效率就会更高。 ⑤、获取对象时（get() 方法）： 1. 计算 hash 值，定位到该 table 索引位置，如果是首结点符合就返回； 2. 如果遇到扩容时，会调用标记正在扩容结点 ForwardingNode.find() 方法，查找该结点，匹配就返回； 3. 以上都不符合的话，就往下遍历结点，匹配就返回，否则最后就返回 null。 21.ConcurrentHashMap 的并发度是什么？ 程序运行时能够同时更新 ConccurentHashMap 且不产生锁竞争的最大线程数。默认为 16，且可以在构造函数中设置。当用户设置并发度时，ConcurrentHashMap 会使用大于等于该值的最小 2 幂指数作为实际并发度（假如用户设置并发度为 17，实际并发度则为 32） 有时间会对 HashTable，ConcurrentHashmap 解析。 22.为什么要重写hashcode和equals方法？​ 用HashMap存入自定义的类时，如果不重写这个自定义类的hashcode和equals方法，得到的结果会和预期的不一样。 ​ 重写hashcode和equals方法，来覆盖Object里的同名方法。Object的固有方法是根据两个对象的内存地址来判断，两个不同的对象，内存地址一定不会相同，所以无论值是否相等，结果都一定不会相等 参考博客：https://www.cnblogs.com/heqiyoujing/p/11143298.html https://www.jianshu.com/p/75adf47958a7","categories":[{"name":"数据结构","slug":"数据结构","permalink":"https://topone233.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}],"tags":[{"name":"Java","slug":"java","permalink":"https://topone233.github.io/tags/java/"},{"name":"数据结构","slug":"数据结构","permalink":"https://topone233.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"面试","slug":"面试","permalink":"https://topone233.github.io/tags/%E9%9D%A2%E8%AF%95/"}]},{"title":"浅谈HashMap","slug":"浅谈HashMap","date":"2020-07-10T09:07:59.392Z","updated":"2020-08-25T13:33:16.480Z","comments":true,"path":"2020/07/10/浅谈HashMap/","link":"","permalink":"https://topone233.github.io/2020/07/10/%E6%B5%85%E8%B0%88HashMap/","excerpt":"","text":"HashMap 什么是哈希表 HashMap的实现原理 为何HashMap的数组长度一定是2的次幂 重写equals方法需同时重写hashCode方法 JDK1.8中HashMap的性能优化 参考自：https://blog.csdn.net/woshimaxiao1/article/details/83661464 1.什么是哈希表讨论哈希表之前，先大概了解下其他数据结构 数组采用一段连续的存储单元来存储数据。 通过指定下标查找，时间复杂度为O(1)； 通过给定值查找，需要遍历数组，逐一对比给定关键字和数组元素，时间复杂度O(n)。 对于有序数组，则可采用二分查找、插值查找、斐波那契查找等方式，可将复杂度提高到O(logn)；一般的插入删除操作，涉及到数组元素的移动，评价复杂度也为O(n)。 线性链表对于链表的新增、删除等操作，在找到指定操作位置后，仅需处理结点间的引用即可，时间复杂度为O(1),而查找操作需要遍历链表逐一进行对比，复杂度为O(n)。 二叉树对一棵相对平衡的有序二叉树，CRUD，平均复杂度均为O(logn)。 哈希表哈希表(hash table)进行CRUD，性能十分之高，不考虑哈希冲突的情况下，仅需一次定位即可完成，时间复杂度为O(1)。 数据结构的物理存储结构只有两种：顺序存储结构和链式存储结构。栈、队列、树、图等都是从逻辑结构去抽象，映射到内存中，也是这两种物理组织形式。 哈希表主干是数组。如果要新增或查找某个元素，把元素的关键字，通过某个函数映射到数组中的某个位置，通过数组下标一次定位就可以完成。这个函数可以简单描述为：存储位置=f(关键字)。函数f一般成为哈希函数，直接影响到哈希表的优劣。 哈希冲突如果两个不同的元素，通过哈希函数得出的实际存储地址相同；或者元素哈希运算得到一个存储地址，进行插入的时候发现已经被其他元素占用了，这就是所谓的哈希冲突，也叫哈希碰撞。 好的哈希函数会尽可能使计算简单和散列地址分布均匀。但是，数组是一块连续的固定长度的内存空间，再好的哈希函数也不能保证得到的存储地址绝对不发生冲突。 哈希冲突的解决方案有多种：开放定址法(发生冲突，继续寻找下一块未被占用的存储地址)、再散列函数法、链地址法。HashMap采用的即是链地址法，也就是数组+链表的方式。 2.HashMap的实现原理HashMap的主干是一个Entry数组。Entry是HashMap的基本组成单元，每一个Entry包含一个key-value键值对。（其实所谓的Map就是保存了两个对象之间的映射关系的一种集合）。 //主干是一个Entry数组，初始值为空数组，长度一定是2的次幂 transient Entry&lt;K,V&gt;[] table = (Entry&lt;K,V&gt;[]) EMPty_TABLE;Entry是HashMap中的一个静态内部类。代码如下: static class Entry&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; { final K key; V value; //存储执向下一个Entry的引用，单链表结构 Entry&lt;K,V&gt; next; //对key的hashcode值进行hash运算后得到的值，存储在Entry，避免重复计算 int hash; //creats new entry Entry(int h, k K, V v, Entry&lt;K,V&gt; n) { value = v; next = n; key = k; hash = h; }总结一下：HashMap由数组+链表组成，Entry数组是HashMap的主体，链表用于解决哈希冲突。如果定位到的数组位置不含链表(当前entry的next指向null)，那么CRUD很快，O(1)，仅需一次寻址即可；如果定位到的数组包含链表，添加操作，复杂度O(n)，先遍历链表，存在即覆盖，否则新增；查找操作，仍需遍历链表，然后通过key对象的equals方法逐一对比查找。所以，HashMap中的链表出现越少，性能越好。 构造器HashMap的4个构造器size、threshold、loadFactor、modCount //实际存储key-value键值对的个数 transient int size; //阈值，当table == {}时，该值为初始容量(默认16) //当table被填充了，也就是为table分配内存空间后，threshold一般为capacity*loadFactory //HashMap在进行扩容时需要参考threshold int threshold; //负载因子，代表了table的填充度，默认是0.75 //负载因子存在的原因，还是为了减缓哈希冲突 //如果初始桶为16，等到满16个才扩容，某些桶可能就有不止一个元素了 //所以加载因子默认为0.75，也就是说大小为16的HashMap，到了第13个元素，就会扩容成32 final float loadFactor; //HashMap被改变的次数 //由于HashMap非线程安全，在对HashMap进行迭代时，如果其他线程的参与导致HashMap的结构发生了变化(put、remove等操作)，需要抛出异常ConcurrentModificationException transient int modeCount;示例代码: public HashMap(int initialCapacity, float loadFactor) { //此处对传入的初始容量进行校验，最大不能超过MAXIMUM_CAPACITY = 1&lt;&lt;30(230) if (initialCapacity &lt; 0) throw new IllegalArgumentException(&quot;Illegal initial capacity: &quot; + initialCapacity); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(&quot;Illegal load factor: &quot; + loadFactor); this.loadFactor = loadFactor; threshold = initialCapacity; //init方法在HashMap中没有实际实现，不过在其子类如 linkedHashMap中就会有对应实现 init(); } 从上面这段代码我们可以看出，在常规构造器中，没有为数组table分配内存空间（有一个入参为指定Map的构造器例外），而是在执行put操作的时候才真正构建table数组 putput操作的实现: public V put(K key, V value) { //如果table数组为空数组{}，进行数组填充（为table分配实际内存空间），入参为threshold， //此时threshold为initialCapacity 默认是1&lt;&lt;4(24=16) if (table == EMPTY_TABLE) { inflateTable(threshold); } //如果key为null，存储位置为table[0]或table[0]的冲突链上 if (key == null) return putForNullKey(value); int hash = hash(key);//对key的hashcode进一步计算，确保散列均匀 int i = indexFor(hash, table.length);//获取在table中的实际位置 for (Entry&lt;K,V&gt; e = table[i]; e != null; e = e.next) { //如果该对应数据已存在，执行覆盖操作。用新value替换旧value，并返回旧value Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) { V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; } } modCount++;//保证并发访问时，若HashMap内部结构发生变化，快速响应失败 addEntry(hash, key, value, i);//新增一个entry return null; } inflateTable这个方法用于为主干数组table在内存中分配存储空间，通过roundUpToPowerOf2(toSize)可以确保capacity为大于或等于toSize的最接近toSize的二次幂，比如toSize=13,则capacity=16;to_size=16,capacity=16;to_size=17,capacity=32。 private void inflateTable(int toSize) { //capacity一定是2的次幂 int capacity = roundUpToPowerOf2(toSize); //此处为threshold赋值，取capacity*loadFactor和MAXIMUM_CAPACITY+1的最小值， //capaticy一定不会超过MAXIMUM_CAPACITY，除非loadFactor大于1 threshold = (int) Math.min(capacity * loadFactor, MAXIMUM_CAPACITY + 1); table = new Entry[capacity]; initHashSeedAsNeeded(capacity); } roundUpToPowerOf2中的这段处理使得数组长度一定为2的次幂，Integer.highestOneBit是用来获取最左边的bit（其他bit位为0）所代表的数值 private static int roundUpToPowerOf2(int number) { // assert number &gt;= 0 : &quot;number must be non-negative&quot;; return number &gt;= MAXIMUM_CAPACITY ? MAXIMUM_CAPACITY : (number &gt; 1) ? Integer.highestOneBit((number - 1) &lt;&lt; 1) : 1; } hash函数: //这是一个神奇的函数，用了很多的异或，移位等运算 //对key的hashcode进一步进行计算以及二进制位的调整等来保证最终获取的存储位置尽量分布均匀 final int hash(Object k) { int h = hashSeed; if (0 != h &amp;&amp; k instanceof String) { return sun.misc.Hashing.stringHash32((String) k); } h ^= k.hashCode(); h ^= (h &gt;&gt;&gt; 20) ^ (h &gt;&gt;&gt; 12); return h ^ (h &gt;&gt;&gt; 7) ^ (h &gt;&gt;&gt; 4); } 以上hash函数计算出的值，通过indexFor进一步处理来获取实际的存储位置 //返回数组下标 static int indexFor(int h, int length) { return h &amp; (length-1); }h&amp;（length-1）保证获取的index一定在数组范围内，举个例子，默认容量16，length-1=15，h=18,转换成二进制计算为index=2。位运算对计算机来说，性能更高一些（HashMap中有大量位运算） 所以最终存储位置的确定流程是这样的： hashCode() hash() indexFor() key ----------&gt; hashcode ----------&gt; h ------------&gt; 存储下标 h&amp;(length-1)再来看看addEntry的实现： void addEntry(int hash, K key, V value, int bucketIndex) { if ((size &gt;= threshold) &amp;&amp; (null != table[bucketIndex])) { //当size超过临界阈值threshold，并且即将发生哈希冲突时进行扩容 resize(2 * table.length); hash = (null != key) ? hash(key) : 0; bucketIndex = indexFor(hash, table.length); } createEntry(hash, key, value, bucketIndex); } 通过以上代码能够得知，当发生哈希冲突并且size大于阈值的时候，需要进行数组扩容，扩容时，需要新建一个长度为之前数组2倍的新的数组，然后将当前的Entry数组中的元素全部传输过去，扩容后的新数组长度为之前的2倍，所以扩容相对来说是个耗资源的操作 3.为何HashMap的数组长度一定是2的次幂我们来继续看上面提到的resize方法: void resize(int newCapacity) { Entry[] oldTable = table; int oldCapacity = oldTable.length; if (oldCapacity == MAXIMUM_CAPACITY) { threshold = Integer.MAX_VALUE; return; } Entry[] newTable = new Entry[newCapacity]; transfer(newTable, initHashSeedAsNeeded(newCapacity)); table = newTable; threshold = (int)Math.min(newCapacity * loadFactor, MAXIMUM_CAPACITY + 1); } 如果数组进行扩容，数组长度发生变化，而存储位置 index = h&amp;(length-1),index也可能会发生变化，需要重新计算index，我们先来看看transfer这个方法: void transfer(Entry[] newTable, boolean rehash) { int newCapacity = newTable.length; //for循环中的代码，逐个遍历链表，重新计算索引位置，将老数组数据复制到新数组中去（数组不存储实际数据，所以仅仅是拷贝引用而已） for (Entry&lt;K,V&gt; e : table) { while(null != e) { Entry&lt;K,V&gt; next = e.next; if (rehash) { e.hash = null == e.key ? 0 : hash(e.key); } int i = indexFor(e.hash, newCapacity); //将当前entry的next链指向新的索引位置,newTable[i]有可能为空，有可能也是个entry链，如果是entry链，直接在链表头部插入。 e.next = newTable[i]; newTable[i] = e; e = next; } } } 这个方法将老数组中的数据逐个链表地遍历，扔到新的扩容后的数组中，我们的数组索引位置的计算是通过 对key值的hashcode进行hash扰乱运算后，再通过和 length-1进行位运算得到最终数组索引位置。 HashMap的数组长度一定保持2的次幂，比如16的二进制表示为 10000，那么length-1就是15，二进制为01111，同理扩容后的数组长度为32，二进制表示为100000，length-1为31，二进制表示为011111。从下图可以我们也能看到这样会保证低位全为1，而扩容后只有一位差异，也就是多出了最左位的1，这样在通过 h&amp;(length-1)的时候，只要h对应的最左边的那一个差异位为0，就能保证得到的新的数组索引和老数组索引一致(大大减少了之前已经散列良好的老数组的数据位置重新调换)，个人理解。 还有，数组长度保持2的次幂，length-1的低位都为1，会使得获得的数组索引index更加均匀 我们看到，上面的&amp;运算，高位是不会对结果产生影响的（hash函数采用各种位运算可能也是为了使得低位更加散列），我们只关注低位bit，如果低位全部为1，那么对于h低位部分来说，任何一位的变化都会对结果产生影响，也就是说，要得到index=21这个存储位置，h的低位只有这一种组合。这也是数组长度设计为必须为2的次幂的原因。 如果不是2的次幂，也就是低位不是全为1此时，要使得index=21，h的低位部分不再具有唯一性了，哈希冲突的几率会变的更大，同时，index对应的这个bit位无论如何不会等于1了，而对应的那些数组位置也就被白白浪费了。 getget方法: public V get(Object key) { //如果key为null,则直接去table[0]处去检索即可。 if (key == null) return getForNullKey(); Entry&lt;K,V&gt; entry = getEntry(key); return null == entry ? null : entry.getValue(); } get方法通过key值返回对应value，如果key为null，直接去table[0]处检索。 我们再看一下getEntry方法: final Entry&lt;K,V&gt; getEntry(Object key) { if (size == 0) { return null; } //通过key的hashcode值计算hash值 int hash = (key == null) ? 0 : hash(key); //indexFor (hash&amp;length-1) 获取最终数组索引，然后遍历链表，通过equals方法比对找出对应记录 for (Entry&lt;K,V&gt; e = table[indexFor(hash, table.length)]; e != null; e = e.next) { Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; } return null; } 可以看出，get方法的实现相对简单，key(hashcode)–&gt;hash–&gt;indexFor–&gt;最终索引位置，找到对应位置table[i]，再查看是否有链表，遍历链表，通过key的equals方法比对查找对应的记录。要注意的是，有人觉得上面在定位到数组位置之后然后遍历链表的时候，e.hash == hash这个判断没必要，仅通过equals判断就可以。其实不然，试想一下，如果传入的key对象重写了equals方法却没有重写hashCode，而恰巧此对象定位到这个数组位置，如果仅仅用equals判断可能是相等的，但其hashCode和当前对象不一致，这种情况，根据Object的hashCode的约定，不能返回当前对象，而应该返回null，后面的例子会做出进一步解释。 4.重写equals方法需同时重写hashCode方法先来看下如果重写equals而不重写hashcode会发生什么: public class MyTest { private static class Person{ int idCard; String name; public Person(int idCard, String name) { this.idCard = idCard; this.name = name; } @Override public boolean equals(Object o) { if (this == o) { return true; } if (o == null || getClass() != o.getClass()){ return false; } Person person = (Person) o; //两个对象是否等值，通过idCard来确定 return this.idCard == person.idCard; } } public static void main(String []args){ HashMap&lt;Person,String&gt; map = new HashMap&lt;Person, String&gt;(); Person person = new Person(1234,&quot;乔峰&quot;); //put到hashmap中去 map.put(person,&quot;天龙八部&quot;); //get取出，从逻辑上讲应该能输出“天龙八部” System.out.println(&quot;结果:&quot;+map.get(new Person(1234,&quot;萧峰&quot;))); } } 实际输出结果：null如果我们已经对HashMap的原理有了一定了解，这个结果就不难理解了。尽管我们在进行get和put操作的时候，使用的key从逻辑上讲是等值的（通过equals比较是相等的），但由于没有重写hashCode方法，所以put操作时，key(hashcode1)–&gt;hash–&gt;indexFor–&gt;最终索引位置 ，而通过key取出value的时候 key(hashcode1)–&gt;hash–&gt;indexFor–&gt;最终索引位置，由于hashcode1不等于hashcode2，导致没有定位到一个数组位置而返回逻辑上错误的值null(也有可能碰巧定位到一个数组位置，但是也会判断其entry的hash值是否相等，上面get方法中有提到) 所以，在重写equals的方法的时候，必须注意重写hashCode方法，同时还要保证通过equals判断相等的两个对象，调用hashCode方法要返回同样的整数值。而如果equals判断不相等的两个对象，其hashCode可以相同(只不过会发生哈希冲突，应尽量避免) 5.JDK1.8中HashMap的性能优化假如一个数组槽位上链上数据过多（即拉链过长的情况）导致性能下降该怎么办？ JDK1.8在JDK1.7的基础上针对增加了红黑树来进行优化。即当链表超过8时，链表就转换为红黑树，利用红黑树快速增删改查的特点提高HashMap的性能，其中会用到红黑树的插入、删除、查找等算法","categories":[{"name":"数据结构","slug":"数据结构","permalink":"https://topone233.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}],"tags":[{"name":"Java","slug":"java","permalink":"https://topone233.github.io/tags/java/"},{"name":"数据结构","slug":"数据结构","permalink":"https://topone233.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"HashMap","slug":"hashmap","permalink":"https://topone233.github.io/tags/hashmap/"}]},{"title":"九大常见数据结构","slug":"九大常见数据结构","date":"2020-07-10T09:07:59.386Z","updated":"2020-08-25T13:33:01.890Z","comments":true,"path":"2020/07/10/九大常见数据结构/","link":"","permalink":"https://topone233.github.io/2020/07/10/%E4%B9%9D%E5%A4%A7%E5%B8%B8%E8%A7%81%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/","excerpt":"","text":"参考：https://mp.weixin.qq.com/s/lnMvB3zgWZTmCfCvnNwTbA 数据结构想必大家都不会陌生，对于一个成熟的程序员而言，熟悉和掌握数据结构和算法也是基本功之一。数据结构本身其实不过是数据按照特点关系进行存储或者组织的集合，特殊的结构在不同的应用场景中往往会带来不一样的处理效率。 常用的数据结构可根据数据访问的特点分为线性结构和非线性结构。线性结构包括常见的链表、栈、队列等，非线性结构包括树、图等。数据结构种类繁多，本文将通过图解的方式对常用的数据结构进行理论上的介绍和讲解，以方便大家掌握常用数据结构的基本知识。 1 数组数组可以说是最基本最常见的数据结构。数组一般用来存储相同类型的数据，可通过数组名和下标进行数据的访问和更新。数组中元素的存储是按照先后顺序进行的，同时在内存中也是按照这个顺序进行连续存放。数组相邻元素之间的内存地址的间隔一般就是数组数据类型的大小。 2 链表链表相较于数组，除了数据域，还增加了指针域用于构建链式的存储数据。链表中每一个节点都包含此节点的数据和指向下一节点地址的指针。由于是通过指针进行下一个数据元素的查找和访问，使得链表的自由度更高。 这表现在对节点进行增加和删除时，只需要对上一节点的指针地址进行修改，而无需变动其它的节点。不过事物皆有两极，指针带来高自由度的同时，自然会牺牲数据查找的效率和多余空间的使用。 一般常见的是有头有尾的单链表，对指针域进行反向链接，还可以形成双向链表或者循环链表。 链表和数组对比链表和数组在实际的使用过程中需要根据自身的优劣势进行选择。链表和数组的异同点也是面试中高频的考察点之一。这里对单链表和数组的区别进行了对比和总结。 3 跳表从上面的对比中可以看出，链表虽然通过增加指针域提升了自由度，但是却导致数据的查询效率恶化。特别是当链表长度很长的时候，对数据的查询还得从头依次查询，这样的效率会更低。跳表的产生就是为了解决链表过长的问题，通过增加链表的多级索引来加快原始链表的查询效率。这样的方式可以让查询的时间复杂度从 O(n) 提升至 O(logn)。 跳表通过增加的多级索引能够实现高效的动态插入和删除，其效率和红黑树和平衡二叉树不相上下。目前 redis 和 levelDB 都有用到跳表。 从上图可以看出，索引级的指针域除了指向下一个索引位置的指针，还有一个 down 指针指向低一级的链表位置，这样才能实现跳跃查询的目的。 4 栈栈是一种比较简单的数据结构，常用一句话描述其特性，后进先出。栈本身是一种线性结构，但是在这个结构中只有一个口子允许数据的进出。这种模式可以参考腔肠动物… 即进食和排泄都用一个口… 栈的常用操作包括入栈 push 和出栈 pop，对应于数据的压入和压出。还有访问栈顶数据、判断栈是否为空和判断栈的大小等。由于栈后进先出的特性，常可以作为数据操作的临时容器，对数据的顺序进行调控，与其它数据结构相结合可获得许多灵活的处理。 5 队列队列是栈的兄弟结构，与栈的后进先出相对应，队列是一种先进先出的数据结构。顾名思义，队列的数据存储是如同排队一般，先存入的数据先被压出。常与栈一同配合，可发挥最大的实力。 6 树树作为一种树状的数据结构，其数据节点之间的关系也如大树一样，将有限个节点根据不同层次关系进行排列，从而形成数据与数据之间的父子关系。常见的数的表示形式更接近 “倒挂的树”，因为它将根朝上，叶朝下。 树是图的一种，树与图的区别在于：树是没有环的，而图是可以有环的。 树的数据存储在结点中，每个结点有零个或者多个子结点。没有父结点的结点在最顶端，成为根节点；没有非根结点有且只有一个父节点；每个非根节点又可以分为多个不相交的子树。 这意味着树是具备层次关系的，父子关系清晰，家庭血缘关系明朗；这也是树与图之间最主要的区别。 别看树好像很高级，其实可看作是链表的高配版。树的实现就是对链表的指针域进行了扩充，增加了多个地址指向子结点。同时将 “链表” 竖起来，从而凸显了结点之间的层次关系，更便于分析和理解。 树可以衍生出许多的结构，若将指针域设置为双指针，那么即可形成最常见的二叉树，即每个结点最多有两个子树的树结构。二叉树根据结点的排列和数量还可进一度划分为完全二叉树、满二叉树、平衡二叉树、红黑树等。 完全二叉树：除了最后一层结点，其它层的结点数都达到了最大值；同时最后一层的结点都是按照从左到右依次排布。 满二叉树：除了最后一层，其它层的结点都有两个子结点。 平衡二叉树平衡二叉树又被称为 AVL 树，它是一棵二叉排序树，且具有以下性质：它是一棵空树或它的左右两个子树的高度差的绝对值不超过 1，并且左右两个子树都是一棵平衡二叉树。 二叉排序树：是一棵空树，或者：若它的左子树不空，则左子树上所有结点的值均小于它的根结点的值；若它的右子树不空，则右子树上所有结点的值均大于它的根结点的值；它的左、右子树也分别为二叉排序树。 树的高度：结点层次的最大值 平衡因子：左子树高度 - 右子树高度 二叉排序树意味着二叉树中的数据是排好序的，顺序为左结点 &lt;根节点&lt;右结点，这表明二叉排序树的中序遍历结果是有序的。 （二叉树四种遍历方式[前序遍历、中序遍历、后序遍历、层序遍历] ） 平衡二叉树的产生是为了解决二叉排序树在插入时发生线性排列的现象。由于二叉排序树本身为有序，当插入一个有序程度十分高的序列时，生成的二叉排序树会持续在某个方向的字数上插入数据，导致最终的二叉排序树会退化为链表，从而使得二叉树的查询和插入效率恶化。 平衡二叉树的出现能够解决上述问题，但是在构造平衡二叉树时，却需要采用不同的调整方式，使得二叉树在插入数据后保持平衡。主要的四种调整方式有 LL（左旋）、RR（右旋）、LR（先左旋再右旋）、RL（先右旋再左旋）。这里先给大家介绍下简单的单旋转操作，左旋和右旋。LR 和 RL 本质上只是 LL 和 RR 的组合。 在插入一个结点后应该沿搜索路径将路径上的结点平衡因子进行修改，当平衡因子大于 1 时，就需要进行平衡化处理。从发生不平衡的结点起，沿刚才回溯的路径取直接下两层的结点，如果这三个结点在一条直线上，则采用单旋转进行平衡化，如果这三个结点位于一条折线上，则采用双旋转进行平衡化。 左旋：S 为当前需要左旋的结点，E 为当前结点的父节点。 左旋的操作可以用一句话简单表示：将当前结点 S 的左孩子旋转为当前结点父结点 E 的右孩子，同时将父结点 E 旋转为当前结点 S 的左孩子。 右旋：S 为当前需要左旋的结点，E 为当前结点的父节点。右单旋是左单旋的镜像旋转。 左旋的操作同样可以用一句话简单表示：将当前结点 S 的左孩子 E 的右孩子旋转为当前结点 S 的左孩子，同时将当前结点 S 旋转为左孩子 E 的右孩子 红黑树平衡二叉树（AVL）为了追求高度平衡，需要通过平衡处理使得左右子树的高度差必须小于等于 1。高度平衡带来的好处是能够提供更高的搜索效率，其最坏的查找时间复杂度都是 O(logN)。但是由于需要维持这份高度平衡，所付出的代价就是当对树种结点进行插入和删除时，需要经过多次旋转实现复衡。这导致 AVL 的插入和删除效率并不高。 为了解决这样的问题，能不能找一种结构能够兼顾搜索和插入删除的效率呢？这时候红黑树便申请出战了。 红黑树具有五个特性： 每个结点要么是红的要么是黑的。 根结点是黑的。 每个叶结点（叶结点即指树尾端 NIL 指针或 NULL 结点）都是黑的。 如果一个结点是红的，那么它的两个儿子都是黑的。 对于任意结点而言，其到叶结点树尾端 NIL 指针的每条路径都包含相同数目的黑结点。 红黑树通过将结点进行红黑着色，使得原本高度平衡的树结构被稍微打乱，平衡程度降低。红黑树不追求完全平衡，只要求达到部分平衡。这是一种折中的方案，大大提高了结点删除和插入的效率。C++ 中的 STL 就常用到红黑树作为底层的数据结构。 除了上面所提及的树结构，还有许多广泛应用在数据库、磁盘存储等场景下的树结构。比如 B 树、B + 树等。这里就先不介绍了诶，下次在讲述相关存储原理的时候将会着重介绍。（其实是因为懒） B树（B-tree）B树和平衡二叉树稍有不同的是B树属于多叉树又名平衡多路查找树（查找路径不只两个），数据库索引技术里大量使用者B树和B+树的数据结构。B树相对于平衡二叉树，每个节点包含的关键字增多了，特别是在B树应用到数据库中的时候，数据库充分利用了磁盘块的原理（磁盘数据存储是采用块的形式存储的，每个块的大小为4K，每次IO进行数据读取时，同一个磁盘块的数据可以一次性读取出来）把节点大小限制和充分使用在磁盘快大小范围；把树的节点关键字增多后树的层级比原来的二叉树少了，减少数据查找的次数和复杂度; 规则： 排序方式：所有节点关键字是按递增次序排列，并遵循左小右大原则； 子节点数：非叶节点的子节点数&gt;1，且&lt;=M ，且M&gt;=2，空树除外（注：M阶代表一个树节点最多有多少个查找路径，M=M路,当M=2则是2叉树,M=3则是3叉）； 关键字数：枝节点的关键字数量大于等于ceil(m/2)-1个且小于等于M-1个（注：ceil()是个朝正无穷方向取整的函数 如ceil(1.1)结果为2)； 所有叶子节点均在同一层、叶子节点除了包含了关键字和关键字记录的指针外也有指向其子节点的指针只不过其指针地址都为null对应下图最后一层节点的空格子; 查询： 如上图我要从上图中找到E字母，查找流程如下 获取根节点的关键字进行比较，当前根节点关键字为M，E&lt;M（26个字母顺序），所以往找到指向左边的子节点（二分法规则，左小右大，左边放小于当前节点值的子节点、右边放大于当前节点值的子节点）； 拿到关键字D和G，D&lt;E&lt;G 所以直接找到D和G中间的节点； 拿到E和F，因为E=E 所以直接返回关键字和指针信息（如果树结构里面没有包含所要查找的节点则返回null）； 插入： 节点拆分规则：当前是要组成一个5路查找树，那么此时m=5,关键字数必须&lt;=5-1（这里关键字数&gt;4就要进行节点拆分）； 排序规则：满足节点本身比左边节点大，比右边节点小的排序规则; 删除： 节点合并规则：当前是要组成一个5路查找树，那么此时m=5,关键字数必须大于等于ceil（5/2）（这里关键字数&lt;2就要进行节点合并）； 满足节点本身比左边节点大，比右边节点小的排序规则; 关键字数小于二时先从子节点取，子节点没有符合条件时就向向父节点取，取中间值往父节点放； B+树B+树是B树的一个升级版，相对于B树来说B+树更充分的利用了节点的空间，让查询速度更加稳定，其速度完全接近于二分法查找。查找的效率要比B树更高、更稳定。 规则： B+跟B树不同B+树的非叶子节点不保存关键字记录的指针，只进行数据索引，这样使得B+树每个非叶子节点所能保存的关键字大大增加； B+树叶子节点保存了父节点的所有关键字记录的指针，所有数据地址必须要到叶子节点才能获取到。所以每次数据查询的次数都一样； B+树叶子节点的关键字从小到大有序排列，左边结尾数据都会保存右边节点开始数据的指针。 非叶子节点的子节点数=关键字数（来源百度百科）（根据各种资料 这里有两种算法的实现方式，另一种为非叶节点的关键字数=子节点数-1（来源维基百科)，虽然他们数据排列结构不一样，但其原理还是一样的Mysql 的B+树是用第一种方式实现）; 特点： B+树的层级更少：相较于B树B+每个非叶子节点存储的关键字数更多，树的层级更少所以查询数据更快； B+树查询速度更稳定：B+所有关键字数据地址都存在叶子节点上，所以每次查找的次数都相同所以查询速度要比B树更稳定; B+树天然具备排序功能：B+树所有的叶子节点数据构成了一个有序链表，在查询大小区间的数据时候更方便，数据紧密性很高，缓存的命中率也会比B树高。 B+树全节点遍历更快：B+树遍历整棵树只需要遍历所有的叶子节点即可，，而不需要像B树一样需要对每一层进行遍历，这有利于数据库做全表扫描。 B树相对于B+树的优点是，如果经常访问的数据离根节点很近，而B树的非叶子节点本身存有关键字其数据的地址，所以这种数据检索的时候会要比B+树快。 7 堆了解完二叉树，再来理解堆就不是什么难事了。堆通常是一个可以被看做一棵树的数组对象。堆的具体实现一般不通过指针域，而是通过构建一个一维数组与二叉树的父子结点进行对应，因此堆总是一颗完全二叉树。 对于任意一个父节点的序号 n 来说（这里 n 从 0 算），它的子节点的序号一定是 2n+1，2n+2，因此可以直接用数组来表示一个堆。 不仅如此，堆还有一个性质：堆中某个节点的值总是不大于或不小于其父节点的值。将根节点最大的堆叫做最大堆或大根堆，根节点最小的堆叫做最小堆或小根堆。 堆常用来实现优先队列，在面试中经常考的问题都是与排序有关，比如堆排序、topK 问题等。由于堆的根节点是序列中最大或者最小值，因而可以在建堆以及重建堆的过程中，筛选出数据序列中的极值，从而达到排序或者挑选 topK 值的目的。 8 散列表散列表也叫哈希表，是一种通过键值对直接访问数据的机构。在初中，我们就学过一种能够将一个 x 值通过一个函数获得对应的一个 y 值的操作，叫做映射。散列表的实现原理正是映射的原理，通过设定的一个关键字和一个映射函数，就可以直接获得访问数据的地址，实现 O(1) 的数据访问效率。在映射的过程中，事先设定的函数就是一个映射表，也可以称作散列函数或者哈希函数。 散列表的实现最关键的就是散列函数的定义和选择。一般常用的有以下几种散列函数： 直接寻址法：取关键字或关键字的某个线性函数值为散列地址。 数字分析法：通过对数据的分析，发现数据中冲突较少的部分，并构造散列地址。例如同学们的学号，通常同一届学生的学号，其中前面的部分差别不太大，所以用后面的部分来构造散列地址。 平方取中**法**：当无法确定关键字里哪几位的分布相对比较均匀时，可以先求出关键字的平方值，然后按需要取平方值的中间几位作为散列地址。这是因为：计算平方之后的中间几位和关键字中的每一位都相关，所以不同的关键字会以较高的概率产生不同的散列地址。 取随机数法：使用一个随机函数，取关键字的随机值作为散列地址，这种方式通常用于关键字长度不同的场合。 除留取余法：取关键字被某个不大于散列表的表长 n 的数 m 除后所得的余数 p 为散列地址。这种方式也可以在用过其他方法后再使用。该函数对 m 的选择很重要，一般取素数或者直接用 n。 确定好散列函数之后，通过某个key值的确会得到一个唯一的value地址。但是却会出现一些特殊情况。即通过不同的key值可能会访问到同一个地址，这个现象称之为冲突。 冲突在发生之后，当在对不同的key值进行操作时会使得造成相同地址的数据发生覆盖或者丢失，是非常危险的。所以在设计散列表往往还需要采用冲突解决的办法。 常用的冲突处理方式有很多，常用的包括以下几种： 开放地址法（也叫开放寻址法）：实际上就是当需要存储值时，对 Key 哈希之后，发现这个地址已经有值了，这时该怎么办？不能放在这个地址，不然之前的映射会被覆盖。这时对计算出来的地址进行一个探测再哈希，比如往后移动一个地址，如果没人占用，就用这个地址。如果超过最大长度，则可以对总长度取余。这里移动的地址是产生冲突时的增列序量。 再哈希法：在产生冲突之后，使用关键字的其他部分继续计算地址，如果还是有冲突，则继续使用其他部分再计算地址。这种方式的缺点是时间增加了。 链地址法：链地址法其实就是对 Key 通过哈希之后落在同一个地址上的值，做一个链表。其实在很多高级语言的实现当中，也是使用这种方式处理冲突的。 公共溢出区：这种方式是建立一个公共溢出区，当地址存在冲突时，把新的地址放在公共溢出区里。 目前比较常用的冲突解决方法是链地址法，一般可以通过数组和链表的结合达到冲突数据缓存的目的。 左侧数组的每个成员包括一个指针，指向一个链表的头。每发生一个冲突的数据，就将该数据作为链表的节点链接到链表尾部。这样一来，就可以保证冲突的数据能够区分并顺利访问。 考虑到链表过长造成的问题，还可以使用红黑树替换链表进行冲突数据的处理操作，来提高散列表的查询稳定性。 9 图图相较于上文的几个结构可能接触的不多，但是在实际的应用场景中却经常出现。比方说交通中的线路图，常见的思维导图都可以看作是图的具体表现形式。 图结构一般包括顶点和边，顶点通常用圆圈来表示，边就是这些圆圈之间的连线。边还可以根据顶点之间的关系设置不同的权重，默认权重相同皆为 1。此外根据边的方向性，还可将图分为有向图和无向图。 图结构用抽象的图线来表示十分简单，顶点和边之间的关系非常清晰明了。但是在具体的代码实现中，为了将各个顶点和边的关系存储下来，却不是一件易事。 邻接矩阵目前常用的图存储方式为邻接矩阵，通过所有顶点的二维矩阵来存储两个顶点之间是否相连，或者存储两顶点间的边权重。 无向图的邻接矩阵是一个对称矩阵，是因为边不具有方向性，若能从此顶点能够到达彼顶点，那么彼顶点自然也能够达到此顶点。此外，由于顶点本身与本身相连没有意义，所以在邻接矩阵中对角线上皆为 0。 有向图由于边具有方向性，因此彼此顶点之间并不能相互达到，所以其邻接矩阵的对称性不再。 用邻接矩阵可以直接从二维关系中获得任意两个顶点的关系，可直接判断是否相连。但是在对矩阵进行存储时，却需要完整的一个二维数组。若图中顶点数过多，会导致二维数组的大小剧增，从而占用大量的内存空间。 而根据实际情况可以分析得，图中的顶点并不是任意两个顶点间都会相连，不是都需要对其边上权重进行存储。那么存储的邻接矩阵实际上会存在大量的 0。虽然可以通过稀疏表示等方式对稀疏性高的矩阵进行关键信息的存储，但是却增加了图存储的复杂性。 因此，为了解决上述问题，一种可以只存储相连顶点关系的邻接表应运而生。 邻接表在邻接表中，图的每一个顶点都是一个链表的头节点，其后连接着该顶点能够直接达到的相邻顶点。相较于无向图，有向图的情况更为复杂，因此这里采用有向图进行实例分析。 在邻接表中，每一个顶点都对应着一条链表，链表中存储的是顶点能够达到的相邻顶点。存储的顺序可以按照顶点的编号顺序进行。比如上图中对于顶点 B 来说，其通过有向边可以到达顶点 A 和顶点 E，那么其对应的邻接表中的顺序即 B-&gt;A-&gt;E，其它顶点亦如此。 通过邻接表可以获得从某个顶点出发能够到达的顶点，从而省去了对不相连顶点的存储空间。然而，这还不够。对于有向图而言，图中有效信息除了从顶点 “指出去” 的信息，还包括从别的顶点 “指进来” 的信息。这里的 “指出去” 和“指进来”可以用出度和入度来表示。 入度：有向图的某个顶点作为终点的次数和。 出度：有向图的某个顶点作为起点的次数和。 由此看出，在对有向图进行表示时，邻接表只能求出图的出度，而无法求出入度。这个问题很好解决，那就是增加一个表用来存储能够到达某个顶点的相邻顶点。这个表称作逆邻接表。 逆邻接表逆邻接表与邻接表结构类似，只不过图的顶点链接着能够到达该顶点的相邻顶点。也就是说，邻接表时顺着图中的箭头寻找相邻顶点，而逆邻接表时逆着图中的箭头寻找相邻顶点。 邻接表和逆邻接表的共同使用下，就能够把一个完整的有向图结构进行表示。可以发现，邻接表和逆邻接表实际上有一部分数据时重合的，因此可以将两个表合二为一，从而得到了所谓的十字链表。 十字链表十字链表似乎很简单，只需要通过相同的顶点分别链向以该顶点为终点和起点的相邻顶点即可。 但这并不是最优的表示方式。虽然这样的方式共用了中间的顶点存储空间，但是邻接表和逆邻接表的链表节点中重复出现的顶点并没有得到重复利用，反而是进行了再次存储。因此，上图的表示方式还可以进行进一步优化。 十字链表优化后，可通过扩展的顶点结构和边结构来进行正逆邻接表的存储：（下面的弧头可看作是边的箭头那端，弧尾可看作是边的圆点那端） data：用于存储该顶点中的数据； firstin 指针：用于连接以当前顶点为弧头的其他顶点构成的链表，即从别的顶点指进来的顶点； firstout 指针：用于连接以当前顶点为弧尾的其他顶点构成的链表，即从该顶点指出去的顶点； 边结构通过存储两个顶点来确定一条边，同时通过分别代表这两个顶点的指针来与相邻顶点进行链接： tailvex：用于存储作为弧尾的顶点的编号； headvex：用于存储作为弧头的顶点的编号； headlink 指针：用于链接下一个存储作为弧头的顶点的节点； taillink 指针：用于链接下一个存储作为弧尾的顶点的节点； 以上图为例子，对于顶点 A 而言，其作为起点能够到达顶点 E。因此在邻接表中顶点 A 要通过边AE（即边 04）指向顶点 E，顶点 A 的firstout指针需要指向边 04 的tailvex。同时，从 B 出发能够到达 A，所以在逆邻接表中顶点 A 要通过边AB（即边 10）指向 B，顶点 A 的firstin指针需要指向边 10 的弧头，即headlink指针。依次类推。 十字链表采用了一种看起来比较繁乱的方式对边的方向性进行了表示，能够在尽可能降低存储空间的情况下增加指针保留顶点之间的方向性。具体的操作可能一时间不好弄懂，建议多看几次上图，弄清指针指向的意义，明白正向和逆向邻接表的表示。 10 总结数据结构博大精深，没有高等数学的讳莫如深，也没有量子力学的玄乎其神，但是其在计算机科学的各个领域都具有强大的力量。本文试图采用图解的方式对九种数据结构进行理论上的介绍，但是其实这都是不够的。 即便是简单的数组、栈、队列等结构，在实际使用以及底层实现上都会有许多优化设计以及使用技巧，这意味着还需要真正把它们灵活的用起来，才能够算是真正意义上的熟悉和精通。但是本文可以作为常见数据结构的一个总结，当你对某些结构有些淡忘的时候，不妨重新回来看看。","categories":[{"name":"数据结构","slug":"数据结构","permalink":"https://topone233.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"https://topone233.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}]},{"title":"二叉树的四种遍历方式","slug":"二叉树的四种遍历方式","date":"2020-07-10T09:07:59.381Z","updated":"2020-08-25T13:32:11.899Z","comments":true,"path":"2020/07/10/二叉树的四种遍历方式/","link":"","permalink":"https://topone233.github.io/2020/07/10/%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E5%9B%9B%E7%A7%8D%E9%81%8D%E5%8E%86%E6%96%B9%E5%BC%8F/","excerpt":"","text":"原文地址 www.cnblogs.com 二叉树的四种遍历方式： 二叉树的遍历（traversing binary tree）是指从根结点出发，按照某种次序依次访问二叉树中所有的结点，使得每个结点被访问依次且仅被访问一次。四种遍历方式分别为：先序遍历、中序遍历、后序遍历、层序遍历。 树的相关术语：节点的度：一个节点含有的子树的个数称为该节点的度； 叶节点：度为0的节点； 树的度：一棵树中，最大的节点的度； 森林：由m（m&gt;=0）棵互不相交的树的集合 树的符号表现法：（1（2（4（5，6）），3） 解读：祖先1的子节点2（子节点4（叶节点5，6）），3。同层子树间用逗号隔开。 如何创建二叉树遍历之前，我们首先介绍一下，如何创建一个二叉树，在这里我们用的是先建左树在建右树的方法， 首先要声明结点 TreeNode 类，代码如下： public class TreeNode { public int data; public TreeNode leftChild; public TreeNode rightChild; public TreeNode(int data){ this.data = data; } } 再来创建一颗二叉树： /** * 构建二叉树 * @param list 输入序列 * @return */ public static TreeNode createBinaryTree(LinkedList&lt;Integer&gt; list){ TreeNode node = null; if(list == null || list.isEmpty()){ return null; } Integer data = list.removeFirst(); if(data!=null){ node = new TreeNode(data); node.leftChild = createBinaryTree(list); node.rightChild = createBinaryTree(list); } return node; } 接下来我们按照上面列的顺序一一讲解， 先序遍历首先来看先序遍历，所谓的先序遍历就是先访问根节点，在访问左节点，最后访问右节点， 如上图所示，前序遍历结果为：ABDFECGHI 实现代码如下： /** * 二叉树前序遍历 根-&gt; 左-&gt; 右 * @param node 二叉树节点 */ public static void preOrderTraveral(TreeNode node){ if(node == null){ return; } System.out.print(node.data+&quot; &quot;); preOrderTraveral(node.leftChild); preOrderTraveral(node.rightChild); } 中序遍历再者就是中序遍历，所谓的中序遍历就是先访问左节点，再访问根节点，最后访问右节点， 如上图所示，中序遍历结果为：DBEFAGHCI（G没有左子树，所以直接访问G，而不是访问H） 实现代码如下： /** * 二叉树中序遍历 左-&gt; 根-&gt; 右 * @param node 二叉树节点 */ public static void inOrderTraveral(TreeNode node){ if(node == null){ return; } inOrderTraveral(node.leftChild); System.out.print(node.data+&quot; &quot;); inOrderTraveral(node.rightChild); } 后序遍历最后就是后序遍历，所谓的后序遍历就是先访问左节点，再访问右节点，最后访问根节点。 如上图所示，前序遍历结果为：DEFBHGICA 实现代码如下： /** * 二叉树后序遍历 左-&gt; 右-&gt; 根 * @param node 二叉树节点 */ public static void postOrderTraveral(TreeNode node){ if(node == null){ return; } postOrderTraveral(node.leftChild); postOrderTraveral(node.rightChild); System.out.print(node.data+&quot; &quot;); } 非递归的前中后序遍历讲完上面三种非递归的方法，下面再给大家讲讲非递归是如何实现前中后序遍历的 非递归前序遍历还是一样，先看非递归前序遍历 首先申请一个新的栈，记为 stack； 声明一个结点 treeNode，让其指向 node 结点； 如果 treeNode 的不为空，将 treeNode 的值打印，并将 treeNode 入栈，然后让 treeNode 指向 treeNode 的右结点， 重复步骤 3，直到 treenode 为空； 然后出栈，让 treeNode 指向 treeNode 的右孩子 重复步骤 3，直到 stack 为空. 实现代码如下： public static void preOrderTraveralWithStack(TreeNode node){ Stack&lt;TreeNode&gt; stack = new Stack&lt;TreeNode&gt;(); TreeNode treeNode = node; while(treeNode!=null || !stack.isEmpty()){ //迭代访问节点的左孩子，并入栈 while(treeNode != null){ System.out.print(treeNode.data+&quot; &quot;); stack.push(treeNode); treeNode = treeNode.leftChild; } //如果节点没有左孩子，则弹出栈顶节点，访问节点右孩子 if(!stack.isEmpty()){ treeNode = stack.pop(); treeNode = treeNode.rightChild; } } } 非递归中序遍历中序遍历非递归，在此不过多叙述具体步骤了， 具体过程： 申请一个新栈，记为 stack，申请一个变量 cur，初始时令 treeNode 为头节点； 先把 treeNode 节点压入栈中，对以 treeNode 节点为头的整棵子树来说，依次把整棵树的左子树压入栈中，即不断令 treeNode=treeNode.leftChild，然后重复步骤 2； 不断重复步骤 2，直到发现 cur 为空，此时从 stack 中弹出一个节点记为 treeNode，打印 node 的值，并让 treeNode= treeNode.right，然后继续重复步骤 2； 当 stack 为空并且 cur 为空时结束。 public static void inOrderTraveralWithStack(TreeNode node){ Stack&lt;TreeNode&gt; stack = new Stack&lt;TreeNode&gt;(); TreeNode treeNode = node; while(treeNode!=null || !stack.isEmpty()){ while(treeNode != null){ stack.push(treeNode); treeNode = treeNode.leftChild; } if(!stack.isEmpty()){ treeNode = stack.pop(); System.out.print(treeNode.data+&quot; &quot;); treeNode = treeNode.rightChild; } } } 非递归后序遍历后序遍历这里较前两者实现复杂一点，我们需要一个标记为来记忆我们此时节点上一个节点，具体看代码注释 public static void postOrderTraveralWithStack(TreeNode node){ Stack&lt;TreeNode&gt; stack = new Stack&lt;TreeNode&gt;(); TreeNode treeNode = node; TreeNode lastVisit = null; //标记每次遍历最后一次访问的节点 while(treeNode!=null || !stack.isEmpty()){//节点不为空，结点入栈，并且指向下一个左孩子 while(treeNode!=null){ stack.push(treeNode); treeNode = treeNode.leftChild; } //栈不为空 if(!stack.isEmpty()){ //出栈 treeNode = stack.pop(); /** * 这块就是判断treeNode是否有右孩子， * 如果没有输出treeNode.data，让lastVisit指向treeNode，并让treeNode为空 * 如果有右孩子，将当前节点继续入栈，treeNode指向它的右孩子,继续重复循环 */ if(treeNode.rightChild == null || treeNode.rightChild == lastVisit) { System.out.print(treeNode.data + &quot; &quot;); lastVisit = treeNode; treeNode = null; }else{ stack.push(treeNode); treeNode = treeNode.rightChild; } } } } 层序遍历最后再介绍一下层序遍历 具体步骤如下： 首先申请一个新的队列，记为 queue； 将头结点 head 压入 queue 中； 每次从 queue 中出队，记为 node，然后打印 node 值，如果 node 左孩子不为空，则将左孩子入队；如果 node 的右孩子不为空，则将右孩子入队； 重复步骤 3，直到 queue 为空。 实现代码如下： public static void levelOrder(TreeNode root){ LinkedList&lt;TreeNode&gt; queue = new LinkedList&lt;&gt;(); queue.add(root); while(!queue.isEmpty()){ root = queue.pop(); System.out.print(root.data+&quot; &quot;); if(root.leftChild!=null) queue.add(root.leftChild); if(root.rightChild!=null) queue.add(root.rightChild); } }","categories":[{"name":"数据结构","slug":"数据结构","permalink":"https://topone233.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"https://topone233.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"二叉树","slug":"二叉树","permalink":"https://topone233.github.io/tags/%E4%BA%8C%E5%8F%89%E6%A0%91/"}]},{"title":"Hello World！（hexo配置记录）","slug":"Hello World！（hexo配置记录）","date":"2020-07-01T02:25:00.000Z","updated":"2020-08-25T13:29:17.818Z","comments":true,"path":"2020/07/01/Hello World！（hexo配置记录）/","link":"","permalink":"https://topone233.github.io/2020/07/01/Hello%20World%EF%BC%81%EF%BC%88hexo%E9%85%8D%E7%BD%AE%E8%AE%B0%E5%BD%95%EF%BC%89/","excerpt":"","text":"Hello World！（hexo配置记录）以前在网上冲浪的时候只是不经意间发现许多让人眼前一亮的blog，由此萌生了create my blog的想法。 目前的blog搭建： CSDN/博客园平台 但我个人不是很喜欢这种，首先是太丑了（没错，就是你，CSDN）。 其次依托于平台，虽然只需要创作就行，但是感觉不是属于自己的，没有归属感 独立blog 租云服务器、买域名，还要管理维护，个人感觉略微有些费事，精力有限，还是简单点好 hexo 依托于Github，也是我目前选择的，配置相对简单快捷，主题丰富 hexo配置步骤： 安装Git 安装Node.js 安装hexo 生成ssh并添加到GitHub 部署项目 上传到GitHub 修改主题 1.安装Git下载地址 安装步骤：双击下载的exe文件，一路next就行 2.安装Node.jsHexo是基于nodeJS环境的静态博客，npm是必备的 下载地址 安装步骤：下载好msi文件后，双击打开安装，也是一路next，不过在Custom Setup这一步记得选 Add to PATH ,这样你就不用自己去配置电脑上环境变量了 3.安装hexo 创建一个源文件夹，然后cd到该文件夹下 安装hexo： npm i -g hexo hexo -v 查看版本，检查是否安装成功 hexo init 初始化，初始化完成后可在文件夹下看到文件 这里要说下，npm install出现一直停留在”fetchMetadata: sill resolveWithNewModule find-cache-dir@”解决方法，更换成淘宝的源（反正我是解决了） //修改为淘宝源 npm config set registry https://registry.npm.taobao.org //配置后可通过下面方式来验证是否成功 npm config get registry //或 npm info express4.生成ssh并添加到GitHubSSH密钥可以防止其他人恶意部署文件到你的仓库 首先要有GitHub账号，没有的自行注册 创建一个仓库repository，名称为youname.github.io 在gitbash中，配置GitHub账号信息 //配置你的GitHub账号信息 git config --global user.name &quot;YourName&quot; git config --global user.email &quot;YourEmail&quot;创建ssh //创建ssh ssh-keygen -t rsa -C &quot;youremail@xx.com&quot;生成ssh，在gitbash中切换到文件目录cat读取 //读取ssh文件内容 cat id_rsa.pub 全部复制（包括开头的ssh-rsa，和尾部的email）到GitHub 配置ssh，title随便起 5.部署项目修改hexo的_config.yml文件配置信息（直接复制，只需要修改url即可） deploy: type: git repo: https://github.com/YourgithubName/YourgithubName.github.io.git branch: master回到gitbash，进入hexo目录 hexo clean hexo generate hexo server这时，在http://localhost:4000就可以看到默认页面 6.上传到GitHubnpm install hexo-deployer-git --save将写好的文章部署到GitHub服务器，执行命令 hexo clean hexo generate hexo deploy 第一次deploy要输入GitHubusername和password完成后https://yourgithubname.github.io，查看即可 7.修改主题hexo官网有推荐很多很多主题，自行选择","categories":[],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://topone233.github.io/tags/hexo/"}]}],"categories":[{"name":"Spring","slug":"spring","permalink":"https://topone233.github.io/categories/spring/"},{"name":"Java","slug":"java","permalink":"https://topone233.github.io/categories/java/"},{"name":"数据结构","slug":"数据结构","permalink":"https://topone233.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}],"tags":[{"name":"Java","slug":"java","permalink":"https://topone233.github.io/tags/java/"},{"name":"Spring","slug":"spring","permalink":"https://topone233.github.io/tags/spring/"},{"name":"CORS","slug":"cors","permalink":"https://topone233.github.io/tags/cors/"},{"name":"RESTful","slug":"restful","permalink":"https://topone233.github.io/tags/restful/"},{"name":"数据结构","slug":"数据结构","permalink":"https://topone233.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"排序算法","slug":"排序算法","permalink":"https://topone233.github.io/tags/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/"},{"name":"动态代理","slug":"动态代理","permalink":"https://topone233.github.io/tags/%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86/"},{"name":"面试","slug":"面试","permalink":"https://topone233.github.io/tags/%E9%9D%A2%E8%AF%95/"},{"name":"HashMap","slug":"hashmap","permalink":"https://topone233.github.io/tags/hashmap/"},{"name":"二叉树","slug":"二叉树","permalink":"https://topone233.github.io/tags/%E4%BA%8C%E5%8F%89%E6%A0%91/"},{"name":"hexo","slug":"hexo","permalink":"https://topone233.github.io/tags/hexo/"}]}